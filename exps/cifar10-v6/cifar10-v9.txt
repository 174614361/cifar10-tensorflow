nohup: ignoring input
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:02:00.0
Total memory: 11.90GiB
Free memory: 6.76GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0)
epoch: 0, train precision: 0.591178, train loss: 165.828884, valid precision: 0.606200, valid loss: 161.205688
epoch: 1, train precision: 0.669044, train loss: 135.146415, valid precision: 0.675600, valid loss: 131.782451
epoch: 2, train precision: 0.720422, train loss: 114.561645, valid precision: 0.720200, valid loss: 112.902497
epoch: 3, train precision: 0.755356, train loss: 100.353768, valid precision: 0.750600, valid loss: 101.482738
epoch: 4, train precision: 0.777222, train loss: 90.843918, valid precision: 0.758000, valid loss: 94.712639
epoch: 5, train precision: 0.791444, train loss: 84.317604, valid precision: 0.777800, valid loss: 89.135103
epoch: 6, train precision: 0.797133, train loss: 81.304261, valid precision: 0.772800, valid loss: 87.529231
epoch: 7, train precision: 0.822578, train loss: 72.947290, valid precision: 0.785000, valid loss: 81.347575
epoch: 8, train precision: 0.826489, train loss: 70.295006, valid precision: 0.797000, valid loss: 78.687832
epoch: 9, train precision: 0.835622, train loss: 66.318782, valid precision: 0.794200, valid loss: 76.428543
epoch: 10, train precision: 0.854022, train loss: 60.396441, valid precision: 0.815400, valid loss: 71.773138
epoch: 11, train precision: 0.857956, train loss: 58.831598, valid precision: 0.813800, valid loss: 71.597704
epoch: 12, train precision: 0.864667, train loss: 55.761705, valid precision: 0.814200, valid loss: 69.637164
epoch: 13, train precision: 0.866911, train loss: 54.403364, valid precision: 0.822800, valid loss: 69.360605
epoch: 14, train precision: 0.876756, train loss: 50.989423, valid precision: 0.822800, valid loss: 67.939261
epoch: 15, train precision: 0.884022, train loss: 48.713151, valid precision: 0.826800, valid loss: 65.319515
epoch: 16, train precision: 0.884867, train loss: 47.774813, valid precision: 0.826000, valid loss: 66.166112
epoch: 17, train precision: 0.889533, train loss: 46.193442, valid precision: 0.825400, valid loss: 65.369189
epoch: 18, train precision: 0.897289, train loss: 43.551277, valid precision: 0.831000, valid loss: 63.881966
epoch: 19, train precision: 0.898044, train loss: 43.139087, valid precision: 0.833000, valid loss: 63.537688
epoch: 20, train precision: 0.905467, train loss: 40.663555, valid precision: 0.835000, valid loss: 61.216253
epoch: 21, train precision: 0.907800, train loss: 39.505786, valid precision: 0.836200, valid loss: 61.721974
epoch: 22, train precision: 0.906578, train loss: 39.491206, valid precision: 0.837800, valid loss: 62.747715
epoch: 23, train precision: 0.917222, train loss: 36.128835, valid precision: 0.840400, valid loss: 60.573812
epoch: 24, train precision: 0.921333, train loss: 34.990896, valid precision: 0.841200, valid loss: 60.134585
epoch: 25, train precision: 0.926733, train loss: 33.170433, valid precision: 0.839400, valid loss: 60.054458
epoch: 26, train precision: 0.927556, train loss: 32.604929, valid precision: 0.845400, valid loss: 59.992546
epoch: 27, train precision: 0.927222, train loss: 32.823976, valid precision: 0.845600, valid loss: 59.280285
epoch: 28, train precision: 0.926467, train loss: 32.954716, valid precision: 0.844600, valid loss: 61.161928
epoch: 29, train precision: 0.932511, train loss: 30.864500, valid precision: 0.844200, valid loss: 59.275098
epoch: 30, train precision: 0.939467, train loss: 28.943248, valid precision: 0.847400, valid loss: 59.594354
epoch: 31, train precision: 0.940022, train loss: 28.176395, valid precision: 0.844600, valid loss: 58.931168
epoch: 32, train precision: 0.941400, train loss: 27.525993, valid precision: 0.845400, valid loss: 59.028950
epoch: 33, train precision: 0.944089, train loss: 26.964498, valid precision: 0.847000, valid loss: 58.322444
epoch: 34, train precision: 0.943733, train loss: 26.845550, valid precision: 0.846800, valid loss: 57.459771
epoch: 35, train precision: 0.940400, train loss: 27.129394, valid precision: 0.846000, valid loss: 60.390893
epoch: 36, train precision: 0.942911, train loss: 26.868337, valid precision: 0.850800, valid loss: 58.348904
epoch: 37, train precision: 0.946533, train loss: 25.479435, valid precision: 0.853600, valid loss: 56.834108
epoch: 38, train precision: 0.949622, train loss: 24.744142, valid precision: 0.848600, valid loss: 58.963585
epoch: 39, train precision: 0.952422, train loss: 23.809358, valid precision: 0.848200, valid loss: 59.844100
epoch: 40, train precision: 0.955311, train loss: 22.932919, valid precision: 0.850400, valid loss: 58.440894
epoch: 41, train precision: 0.960467, train loss: 21.337929, valid precision: 0.857200, valid loss: 57.181421
epoch: 42, train precision: 0.950533, train loss: 23.673590, valid precision: 0.854800, valid loss: 59.261665
epoch: 43, train precision: 0.960667, train loss: 20.737455, valid precision: 0.855400, valid loss: 56.751872
epoch: 44, train precision: 0.958822, train loss: 21.140747, valid precision: 0.854800, valid loss: 58.230679
epoch: 45, train precision: 0.959489, train loss: 21.021761, valid precision: 0.859200, valid loss: 58.535711
epoch: 46, train precision: 0.963600, train loss: 20.024628, valid precision: 0.852800, valid loss: 57.541292
epoch: 47, train precision: 0.962022, train loss: 20.435119, valid precision: 0.859400, valid loss: 57.695137
epoch: 48, train precision: 0.965778, train loss: 19.035810, valid precision: 0.861200, valid loss: 55.941233
epoch: 49, train precision: 0.963600, train loss: 19.367421, valid precision: 0.852400, valid loss: 59.245032
epoch: 50, train precision: 0.964178, train loss: 19.531398, valid precision: 0.850000, valid loss: 58.798205
epoch: 51, train precision: 0.967044, train loss: 18.450606, valid precision: 0.860000, valid loss: 58.777123
epoch: 52, train precision: 0.964200, train loss: 18.722816, valid precision: 0.852400, valid loss: 59.813544
epoch: 53, train precision: 0.968911, train loss: 17.885895, valid precision: 0.859200, valid loss: 56.891787
epoch: 54, train precision: 0.969156, train loss: 17.682798, valid precision: 0.860400, valid loss: 57.507274
epoch: 55, train precision: 0.970067, train loss: 17.286618, valid precision: 0.855600, valid loss: 58.325712
epoch: 56, train precision: 0.967622, train loss: 17.981791, valid precision: 0.856000, valid loss: 60.350696
epoch: 57, train precision: 0.972267, train loss: 16.636918, valid precision: 0.859200, valid loss: 58.676726
epoch: 58, train precision: 0.974400, train loss: 15.912341, valid precision: 0.861200, valid loss: 58.161881
epoch: 59, train precision: 0.969267, train loss: 17.470848, valid precision: 0.858200, valid loss: 60.635231
epoch: 60, train precision: 0.973578, train loss: 16.331793, valid precision: 0.863000, valid loss: 58.787089
epoch: 61, train precision: 0.974644, train loss: 15.536664, valid precision: 0.864600, valid loss: 57.588399
epoch: 62, train precision: 0.975133, train loss: 15.531726, valid precision: 0.860600, valid loss: 58.474692
epoch: 63, train precision: 0.974600, train loss: 15.649255, valid precision: 0.858000, valid loss: 59.397690
epoch: 64, train precision: 0.975756, train loss: 15.212613, valid precision: 0.860400, valid loss: 58.465771
epoch: 65, train precision: 0.976378, train loss: 14.913408, valid precision: 0.868000, valid loss: 58.662787
epoch: 66, train precision: 0.974556, train loss: 15.464260, valid precision: 0.858000, valid loss: 60.955828
epoch: 67, train precision: 0.975444, train loss: 15.129197, valid precision: 0.861800, valid loss: 59.949513
epoch: 68, train precision: 0.975267, train loss: 15.241869, valid precision: 0.855200, valid loss: 60.909102
epoch: 69, train precision: 0.980111, train loss: 13.843840, valid precision: 0.858800, valid loss: 59.915643
epoch: 70, train precision: 0.976756, train loss: 14.532312, valid precision: 0.862200, valid loss: 60.421458
epoch: 71, train precision: 0.977978, train loss: 14.613206, valid precision: 0.859200, valid loss: 61.836792
epoch: 72, train precision: 0.978156, train loss: 14.324861, valid precision: 0.858800, valid loss: 60.413816
epoch: 73, train precision: 0.981444, train loss: 13.274198, valid precision: 0.860200, valid loss: 59.366176
epoch: 74, train precision: 0.982578, train loss: 13.039623, valid precision: 0.859400, valid loss: 60.386046
epoch: 75, train precision: 0.981711, train loss: 13.376081, valid precision: 0.861200, valid loss: 60.687929
epoch: 76, train precision: 0.979244, train loss: 13.810324, valid precision: 0.864000, valid loss: 59.419970
epoch: 77, train precision: 0.981089, train loss: 13.210243, valid precision: 0.860400, valid loss: 60.707853
epoch: 78, train precision: 0.982533, train loss: 12.876025, valid precision: 0.862200, valid loss: 61.240564
epoch: 79, train precision: 0.981867, train loss: 12.868985, valid precision: 0.862800, valid loss: 59.988837
epoch: 80, train precision: 0.982044, train loss: 12.966192, valid precision: 0.862600, valid loss: 61.095251
epoch: 81, train precision: 0.982578, train loss: 12.900432, valid precision: 0.856600, valid loss: 62.525262
epoch: 82, train precision: 0.982911, train loss: 12.408767, valid precision: 0.858400, valid loss: 62.820794
epoch: 83, train precision: 0.984267, train loss: 12.423923, valid precision: 0.861600, valid loss: 61.946459
epoch: 84, train precision: 0.985089, train loss: 12.066582, valid precision: 0.862600, valid loss: 61.263543
epoch: 85, train precision: 0.983133, train loss: 12.601923, valid precision: 0.862800, valid loss: 60.489592
epoch: 86, train precision: 0.983467, train loss: 12.703939, valid precision: 0.861400, valid loss: 62.522731
epoch: 87, train precision: 0.982533, train loss: 12.793237, valid precision: 0.864200, valid loss: 61.712752
epoch: 88, train precision: 0.982933, train loss: 12.416409, valid precision: 0.856400, valid loss: 61.652053
epoch: 89, train precision: 0.986689, train loss: 11.534935, valid precision: 0.862400, valid loss: 61.314617
epoch: 90, train precision: 0.984333, train loss: 12.156990, valid precision: 0.861200, valid loss: 61.952321
epoch: 91, train precision: 0.984178, train loss: 11.979732, valid precision: 0.864200, valid loss: 61.234869
epoch: 92, train precision: 0.985867, train loss: 11.724656, valid precision: 0.863400, valid loss: 59.476403
epoch: 93, train precision: 0.985178, train loss: 11.771652, valid precision: 0.862200, valid loss: 60.729613
epoch: 94, train precision: 0.985022, train loss: 11.954820, valid precision: 0.868000, valid loss: 60.789696
epoch: 95, train precision: 0.986044, train loss: 11.623309, valid precision: 0.867800, valid loss: 61.468172
epoch: 96, train precision: 0.987689, train loss: 11.033113, valid precision: 0.860800, valid loss: 62.657137
epoch: 97, train precision: 0.985133, train loss: 11.894524, valid precision: 0.860600, valid loss: 62.833585
epoch: 98, train precision: 0.987844, train loss: 11.027808, valid precision: 0.864600, valid loss: 62.878452
epoch: 99, train precision: 0.986022, train loss: 11.633822, valid precision: 0.857400, valid loss: 63.274764
epoch: 100, train precision: 0.985711, train loss: 11.702849, valid precision: 0.865800, valid loss: 63.740196
epoch: 101, train precision: 0.988956, train loss: 10.714200, valid precision: 0.868000, valid loss: 61.757586
epoch: 102, train precision: 0.988178, train loss: 11.024666, valid precision: 0.862600, valid loss: 63.646260
epoch: 103, train precision: 0.986000, train loss: 11.643479, valid precision: 0.863000, valid loss: 64.539901
epoch: 104, train precision: 0.989022, train loss: 10.766688, valid precision: 0.862200, valid loss: 62.601537
epoch: 105, train precision: 0.988778, train loss: 10.867963, valid precision: 0.862600, valid loss: 63.094819
epoch: 106, train precision: 0.984422, train loss: 12.153474, valid precision: 0.858800, valid loss: 64.246959
epoch: 107, train precision: 0.986067, train loss: 11.314645, valid precision: 0.860200, valid loss: 65.404558
epoch: 108, train precision: 0.989422, train loss: 10.570312, valid precision: 0.867000, valid loss: 63.206364
epoch: 109, train precision: 0.987467, train loss: 10.977071, valid precision: 0.863000, valid loss: 65.575736
epoch: 110, train precision: 0.987467, train loss: 11.218355, valid precision: 0.860400, valid loss: 66.145490
epoch: 111, train precision: 0.989178, train loss: 10.624628, valid precision: 0.865600, valid loss: 64.129635
epoch: 112, train precision: 0.990022, train loss: 10.460222, valid precision: 0.861400, valid loss: 63.571479
epoch: 113, train precision: 0.987400, train loss: 11.267024, valid precision: 0.859600, valid loss: 66.146655
epoch: 114, train precision: 0.989356, train loss: 10.414169, valid precision: 0.865800, valid loss: 63.311561
epoch: 115, train precision: 0.990867, train loss: 10.149587, valid precision: 0.869600, valid loss: 63.294020
epoch: 116, train precision: 0.990933, train loss: 10.228789, valid precision: 0.866800, valid loss: 62.993406
epoch: 117, train precision: 0.989378, train loss: 10.591168, valid precision: 0.864200, valid loss: 67.295398
epoch: 118, train precision: 0.986533, train loss: 11.360761, valid precision: 0.856000, valid loss: 67.396058
epoch: 119, train precision: 0.987667, train loss: 10.968993, valid precision: 0.857000, valid loss: 69.023387
epoch: 120, train precision: 0.990156, train loss: 10.306437, valid precision: 0.862000, valid loss: 64.784777
epoch: 121, train precision: 0.990311, train loss: 10.363150, valid precision: 0.858000, valid loss: 67.083748
epoch: 122, train precision: 0.991178, train loss: 10.162112, valid precision: 0.860200, valid loss: 66.793837
epoch: 123, train precision: 0.988867, train loss: 10.812128, valid precision: 0.864600, valid loss: 65.652446
epoch: 124, train precision: 0.990467, train loss: 10.371267, valid precision: 0.870000, valid loss: 64.537499
epoch: 125, train precision: 0.989333, train loss: 10.543401, valid precision: 0.869000, valid loss: 64.804884
epoch: 126, train precision: 0.987644, train loss: 11.352658, valid precision: 0.862000, valid loss: 67.641259
epoch: 127, train precision: 0.991400, train loss: 10.052026, valid precision: 0.861800, valid loss: 66.030105
epoch: 128, train precision: 0.991378, train loss: 10.068241, valid precision: 0.862800, valid loss: 66.374464
epoch: 129, train precision: 0.989400, train loss: 10.554970, valid precision: 0.863200, valid loss: 68.103859
epoch: 130, train precision: 0.990356, train loss: 10.352117, valid precision: 0.863000, valid loss: 67.403826
epoch: 131, train precision: 0.988867, train loss: 10.820631, valid precision: 0.862000, valid loss: 68.256332
epoch: 132, train precision: 0.992133, train loss: 9.791583, valid precision: 0.862200, valid loss: 66.413616
epoch: 133, train precision: 0.990978, train loss: 10.143574, valid precision: 0.863600, valid loss: 66.087354
epoch: 134, train precision: 0.991333, train loss: 9.956899, valid precision: 0.864200, valid loss: 66.416772
epoch: 135, train precision: 0.991222, train loss: 10.085644, valid precision: 0.866800, valid loss: 66.414733
epoch: 136, train precision: 0.990733, train loss: 10.422606, valid precision: 0.866600, valid loss: 66.412372
epoch: 137, train precision: 0.990156, train loss: 10.505127, valid precision: 0.865000, valid loss: 67.482471
epoch: 138, train precision: 0.991800, train loss: 9.858231, valid precision: 0.868400, valid loss: 65.966193
epoch: 139, train precision: 0.992133, train loss: 9.813507, valid precision: 0.866000, valid loss: 66.268537
epoch: 140, train precision: 0.991622, train loss: 10.129480, valid precision: 0.861800, valid loss: 65.272405
epoch: 141, train precision: 0.992000, train loss: 9.969371, valid precision: 0.865200, valid loss: 66.492590
epoch: 142, train precision: 0.990222, train loss: 10.553532, valid precision: 0.864400, valid loss: 67.738185
epoch: 143, train precision: 0.989244, train loss: 10.671749, valid precision: 0.864400, valid loss: 65.417725
epoch: 144, train precision: 0.992222, train loss: 9.789461, valid precision: 0.869800, valid loss: 65.106232
epoch: 145, train precision: 0.991578, train loss: 10.283462, valid precision: 0.861400, valid loss: 67.665242
epoch: 146, train precision: 0.991489, train loss: 10.218300, valid precision: 0.861400, valid loss: 68.208900
epoch: 147, train precision: 0.992756, train loss: 9.906895, valid precision: 0.868200, valid loss: 66.753733
epoch: 148, train precision: 0.991578, train loss: 10.120929, valid precision: 0.861200, valid loss: 68.508060
epoch: 149, train precision: 0.992489, train loss: 9.820777, valid precision: 0.867200, valid loss: 66.190337
epoch: 150, train precision: 0.990000, train loss: 10.521383, valid precision: 0.864400, valid loss: 69.593194
epoch: 151, train precision: 0.992867, train loss: 9.759711, valid precision: 0.869000, valid loss: 66.830448
epoch: 152, train precision: 0.992689, train loss: 9.786209, valid precision: 0.868000, valid loss: 68.103181
epoch: 153, train precision: 0.991333, train loss: 10.353518, valid precision: 0.866600, valid loss: 70.117982
epoch: 154, train precision: 0.993644, train loss: 9.728384, valid precision: 0.868200, valid loss: 66.023401
epoch: 155, train precision: 0.990444, train loss: 10.593932, valid precision: 0.864400, valid loss: 69.268002
epoch: 156, train precision: 0.994711, train loss: 9.316825, valid precision: 0.866200, valid loss: 68.056865
epoch: 157, train precision: 0.993511, train loss: 9.791620, valid precision: 0.865400, valid loss: 68.080011
epoch: 158, train precision: 0.991844, train loss: 10.190661, valid precision: 0.866200, valid loss: 69.006582
epoch: 159, train precision: 0.993733, train loss: 9.520605, valid precision: 0.870400, valid loss: 68.666730
epoch: 160, train precision: 0.992911, train loss: 9.744329, valid precision: 0.868000, valid loss: 67.504839
epoch: 161, train precision: 0.993556, train loss: 9.775646, valid precision: 0.867200, valid loss: 68.058352
epoch: 162, train precision: 0.992978, train loss: 9.907670, valid precision: 0.866800, valid loss: 68.746110
epoch: 163, train precision: 0.993556, train loss: 9.743728, valid precision: 0.869400, valid loss: 68.963734
epoch: 164, train precision: 0.993400, train loss: 9.666282, valid precision: 0.867800, valid loss: 70.098330
epoch: 165, train precision: 0.993000, train loss: 9.947408, valid precision: 0.868800, valid loss: 69.269726
epoch: 166, train precision: 0.993556, train loss: 9.848696, valid precision: 0.868200, valid loss: 68.963399
epoch: 167, train precision: 0.992867, train loss: 9.970330, valid precision: 0.864800, valid loss: 69.881331
epoch: 168, train precision: 0.993911, train loss: 9.660493, valid precision: 0.866400, valid loss: 70.205120
epoch: 169, train precision: 0.992711, train loss: 9.889501, valid precision: 0.866000, valid loss: 69.954097
epoch: 170, train precision: 0.992556, train loss: 10.238198, valid precision: 0.864800, valid loss: 70.787234
epoch: 171, train precision: 0.993156, train loss: 9.917965, valid precision: 0.865000, valid loss: 71.364147
epoch: 172, train precision: 0.993089, train loss: 9.902966, valid precision: 0.865000, valid loss: 70.861220
epoch: 173, train precision: 0.994289, train loss: 9.545291, valid precision: 0.865800, valid loss: 70.541325
epoch: 174, train precision: 0.992778, train loss: 10.039960, valid precision: 0.861400, valid loss: 70.982107
epoch: 175, train precision: 0.993244, train loss: 10.018595, valid precision: 0.865200, valid loss: 69.756598
epoch: 176, train precision: 0.994956, train loss: 9.375658, valid precision: 0.866400, valid loss: 69.470098
epoch: 177, train precision: 0.992533, train loss: 10.162886, valid precision: 0.864800, valid loss: 69.874574
epoch: 178, train precision: 0.993356, train loss: 9.930798, valid precision: 0.867600, valid loss: 70.210605
epoch: 179, train precision: 0.992667, train loss: 10.287679, valid precision: 0.864400, valid loss: 70.482634
epoch: 180, train precision: 0.994267, train loss: 9.649721, valid precision: 0.871800, valid loss: 68.618105
epoch: 181, train precision: 0.995133, train loss: 9.436159, valid precision: 0.866400, valid loss: 69.319370
epoch: 182, train precision: 0.993311, train loss: 9.873885, valid precision: 0.862800, valid loss: 69.673897
epoch: 183, train precision: 0.995333, train loss: 9.342014, valid precision: 0.872200, valid loss: 68.809637
epoch: 184, train precision: 0.994511, train loss: 9.610397, valid precision: 0.867200, valid loss: 69.175812
epoch: 185, train precision: 0.994644, train loss: 9.612199, valid precision: 0.866800, valid loss: 70.348290
epoch: 186, train precision: 0.994600, train loss: 9.635504, valid precision: 0.870600, valid loss: 69.587301
epoch: 187, train precision: 0.994467, train loss: 9.727463, valid precision: 0.863800, valid loss: 71.845642
epoch: 188, train precision: 0.994644, train loss: 9.611770, valid precision: 0.868000, valid loss: 68.902307
epoch: 189, train precision: 0.993400, train loss: 9.928157, valid precision: 0.867800, valid loss: 70.470952
epoch: 190, train precision: 0.993156, train loss: 9.993766, valid precision: 0.869000, valid loss: 69.744053
epoch: 191, train precision: 0.993489, train loss: 10.010681, valid precision: 0.870200, valid loss: 69.595365
epoch: 192, train precision: 0.993556, train loss: 10.070124, valid precision: 0.869200, valid loss: 71.235690
epoch: 193, train precision: 0.994289, train loss: 9.780639, valid precision: 0.868800, valid loss: 70.294277
epoch: 194, train precision: 0.994444, train loss: 9.779977, valid precision: 0.870200, valid loss: 69.428692
epoch: 195, train precision: 0.993511, train loss: 9.972359, valid precision: 0.870200, valid loss: 69.730404
epoch: 196, train precision: 0.995511, train loss: 9.481954, valid precision: 0.869600, valid loss: 69.639859
epoch: 197, train precision: 0.992022, train loss: 10.674274, valid precision: 0.869200, valid loss: 71.113163
epoch: 198, train precision: 0.994400, train loss: 9.708426, valid precision: 0.870200, valid loss: 69.389599
epoch: 199, train precision: 0.994356, train loss: 9.913825, valid precision: 0.867000, valid loss: 71.921368
epoch: 200, train precision: 0.993844, train loss: 9.886135, valid precision: 0.867400, valid loss: 73.400418
epoch: 201, train precision: 0.995578, train loss: 9.556317, valid precision: 0.868400, valid loss: 73.994901
epoch: 202, train precision: 0.993578, train loss: 10.092439, valid precision: 0.868000, valid loss: 73.641364
epoch: 203, train precision: 0.992889, train loss: 10.285010, valid precision: 0.864800, valid loss: 74.098394
epoch: 204, train precision: 0.995311, train loss: 9.590873, valid precision: 0.869400, valid loss: 71.967046
epoch: 205, train precision: 0.995267, train loss: 9.569346, valid precision: 0.869400, valid loss: 70.332754
epoch: 206, train precision: 0.995444, train loss: 9.638826, valid precision: 0.867200, valid loss: 71.775144
epoch: 207, train precision: 0.994267, train loss: 9.959947, valid precision: 0.866600, valid loss: 73.955966
epoch: 208, train precision: 0.994844, train loss: 9.725673, valid precision: 0.871600, valid loss: 69.702729
epoch: 209, train precision: 0.992467, train loss: 10.629566, valid precision: 0.870200, valid loss: 71.676019
epoch: 210, train precision: 0.995000, train loss: 9.606880, valid precision: 0.865600, valid loss: 70.807749
epoch: 211, train precision: 0.994244, train loss: 10.002967, valid precision: 0.872200, valid loss: 74.123644
epoch: 212, train precision: 0.994978, train loss: 9.745451, valid precision: 0.869000, valid loss: 71.802255
epoch: 213, train precision: 0.992667, train loss: 10.510318, valid precision: 0.868600, valid loss: 72.110758
epoch: 214, train precision: 0.995844, train loss: 9.520258, valid precision: 0.870800, valid loss: 71.812161
epoch: 215, train precision: 0.995133, train loss: 9.691166, valid precision: 0.875000, valid loss: 71.345183
epoch: 216, train precision: 0.995400, train loss: 9.685442, valid precision: 0.872600, valid loss: 69.750348
epoch: 217, train precision: 0.996333, train loss: 9.358365, valid precision: 0.876600, valid loss: 70.768770
epoch: 218, train precision: 0.994178, train loss: 10.035686, valid precision: 0.869200, valid loss: 71.621638
epoch: 219, train precision: 0.995600, train loss: 9.622756, valid precision: 0.874800, valid loss: 68.556364
epoch: 220, train precision: 0.994978, train loss: 9.818915, valid precision: 0.876000, valid loss: 72.233155
epoch: 221, train precision: 0.995822, train loss: 9.609941, valid precision: 0.877000, valid loss: 70.643133
epoch: 222, train precision: 0.994578, train loss: 10.018562, valid precision: 0.873000, valid loss: 70.550446
epoch: 223, train precision: 0.994933, train loss: 9.864957, valid precision: 0.869200, valid loss: 72.055485
epoch: 224, train precision: 0.996244, train loss: 9.452718, valid precision: 0.870200, valid loss: 72.496715
epoch: 225, train precision: 0.994889, train loss: 9.813235, valid precision: 0.868200, valid loss: 72.591371
epoch: 226, train precision: 0.995778, train loss: 9.642933, valid precision: 0.870400, valid loss: 74.102127
epoch: 227, train precision: 0.995533, train loss: 9.708557, valid precision: 0.866600, valid loss: 73.541323
epoch: 228, train precision: 0.995267, train loss: 9.754864, valid precision: 0.872600, valid loss: 72.715965
epoch: 229, train precision: 0.995689, train loss: 9.676457, valid precision: 0.870200, valid loss: 72.467396
epoch: 230, train precision: 0.996222, train loss: 9.558685, valid precision: 0.868000, valid loss: 72.862723
epoch: 231, train precision: 0.994844, train loss: 9.920951, valid precision: 0.866200, valid loss: 73.251256
epoch: 232, train precision: 0.995622, train loss: 9.753715, valid precision: 0.866000, valid loss: 74.355175
epoch: 233, train precision: 0.995311, train loss: 9.862298, valid precision: 0.870400, valid loss: 74.633266
epoch: 234, train precision: 0.995644, train loss: 9.724824, valid precision: 0.870600, valid loss: 73.260215
epoch: 235, train precision: 0.996133, train loss: 9.693673, valid precision: 0.867200, valid loss: 73.574378
epoch: 236, train precision: 0.995244, train loss: 9.955754, valid precision: 0.870000, valid loss: 73.745822
epoch: 237, train precision: 0.996356, train loss: 9.590735, valid precision: 0.867400, valid loss: 73.062365
epoch: 238, train precision: 0.994933, train loss: 10.054047, valid precision: 0.868400, valid loss: 74.183343
epoch: 239, train precision: 0.995933, train loss: 9.683958, valid precision: 0.870200, valid loss: 74.541240
epoch: 240, train precision: 0.995267, train loss: 10.061006, valid precision: 0.866800, valid loss: 73.333013
epoch: 241, train precision: 0.995822, train loss: 9.703362, valid precision: 0.869200, valid loss: 74.591613
epoch: 242, train precision: 0.996267, train loss: 9.654171, valid precision: 0.869600, valid loss: 73.467390
epoch: 243, train precision: 0.995156, train loss: 9.911486, valid precision: 0.868600, valid loss: 73.584212
epoch: 244, train precision: 0.995689, train loss: 9.871126, valid precision: 0.868800, valid loss: 72.056547
epoch: 245, train precision: 0.994733, train loss: 10.079228, valid precision: 0.874800, valid loss: 73.668043
epoch: 246, train precision: 0.995978, train loss: 9.730667, valid precision: 0.870600, valid loss: 72.080854
epoch: 247, train precision: 0.996400, train loss: 9.742831, valid precision: 0.873200, valid loss: 73.143934
epoch: 248, train precision: 0.996400, train loss: 9.695034, valid precision: 0.865600, valid loss: 73.185735
epoch: 249, train precision: 0.996667, train loss: 9.614756, valid precision: 0.869200, valid loss: 72.260907
epoch: 250, train precision: 0.994933, train loss: 9.985953, valid precision: 0.870600, valid loss: 74.410512
epoch: 251, train precision: 0.996133, train loss: 9.794771, valid precision: 0.872000, valid loss: 72.069353
epoch: 252, train precision: 0.995933, train loss: 9.917212, valid precision: 0.871800, valid loss: 74.210913
epoch: 253, train precision: 0.996333, train loss: 9.673912, valid precision: 0.875400, valid loss: 72.725732
epoch: 254, train precision: 0.995778, train loss: 9.861231, valid precision: 0.872000, valid loss: 73.533240
epoch: 255, train precision: 0.996333, train loss: 9.719699, valid precision: 0.875600, valid loss: 70.972412
epoch: 256, train precision: 0.995756, train loss: 10.051567, valid precision: 0.871800, valid loss: 73.713423
epoch: 257, train precision: 0.997000, train loss: 9.609613, valid precision: 0.872200, valid loss: 71.217891
epoch: 258, train precision: 0.996156, train loss: 9.787788, valid precision: 0.868800, valid loss: 72.897754
epoch: 259, train precision: 0.996578, train loss: 9.721784, valid precision: 0.864600, valid loss: 73.446326
epoch: 260, train precision: 0.996689, train loss: 9.730227, valid precision: 0.870400, valid loss: 73.307547
epoch: 261, train precision: 0.996267, train loss: 9.778493, valid precision: 0.868600, valid loss: 74.371395
epoch: 262, train precision: 0.995622, train loss: 10.022762, valid precision: 0.867200, valid loss: 73.396093
epoch: 263, train precision: 0.996756, train loss: 9.638290, valid precision: 0.869000, valid loss: 73.866609
epoch: 264, train precision: 0.996956, train loss: 9.501828, valid precision: 0.870200, valid loss: 72.685952
epoch: 265, train precision: 0.996200, train loss: 9.803954, valid precision: 0.868800, valid loss: 75.571881
epoch: 266, train precision: 0.996200, train loss: 9.846643, valid precision: 0.871000, valid loss: 74.184328
epoch: 267, train precision: 0.997311, train loss: 9.514266, valid precision: 0.867600, valid loss: 74.763868
epoch: 268, train precision: 0.995756, train loss: 10.019506, valid precision: 0.868600, valid loss: 75.954361
epoch: 269, train precision: 0.996089, train loss: 10.036957, valid precision: 0.865000, valid loss: 74.564887
epoch: 270, train precision: 0.996778, train loss: 9.798646, valid precision: 0.872800, valid loss: 74.621251
epoch: 271, train precision: 0.995933, train loss: 9.999721, valid precision: 0.871200, valid loss: 75.143899
epoch: 272, train precision: 0.996711, train loss: 9.841981, valid precision: 0.872400, valid loss: 75.953738
epoch: 273, train precision: 0.996422, train loss: 10.029958, valid precision: 0.869400, valid loss: 75.947415
epoch: 274, train precision: 0.997356, train loss: 9.593933, valid precision: 0.871200, valid loss: 73.328075
epoch: 275, train precision: 0.996911, train loss: 9.740409, valid precision: 0.873400, valid loss: 72.753484
epoch: 276, train precision: 0.997244, train loss: 9.782902, valid precision: 0.871200, valid loss: 73.512179
epoch: 277, train precision: 0.996889, train loss: 9.714318, valid precision: 0.871600, valid loss: 75.649338
epoch: 278, train precision: 0.995511, train loss: 10.124668, valid precision: 0.868000, valid loss: 73.824176
epoch: 279, train precision: 0.996600, train loss: 9.918210, valid precision: 0.871000, valid loss: 74.253650
epoch: 280, train precision: 0.996644, train loss: 9.860607, valid precision: 0.870200, valid loss: 75.044236
epoch: 281, train precision: 0.996622, train loss: 9.788809, valid precision: 0.872000, valid loss: 74.161792
epoch: 282, train precision: 0.996778, train loss: 9.803379, valid precision: 0.870200, valid loss: 74.882289
epoch: 283, train precision: 0.996689, train loss: 9.836277, valid precision: 0.869400, valid loss: 75.245384
epoch: 284, train precision: 0.995600, train loss: 10.207493, valid precision: 0.868600, valid loss: 74.512674
epoch: 285, train precision: 0.996311, train loss: 10.025397, valid precision: 0.868800, valid loss: 75.374813
epoch: 286, train precision: 0.996667, train loss: 9.901039, valid precision: 0.870200, valid loss: 73.657357
epoch: 287, train precision: 0.997378, train loss: 9.625727, valid precision: 0.874000, valid loss: 73.726397
epoch: 288, train precision: 0.996733, train loss: 9.850672, valid precision: 0.873200, valid loss: 72.097233
epoch: 289, train precision: 0.997000, train loss: 9.834947, valid precision: 0.868400, valid loss: 73.288452
epoch: 290, train precision: 0.996444, train loss: 10.019311, valid precision: 0.870400, valid loss: 73.067259
epoch: 291, train precision: 0.996600, train loss: 9.888470, valid precision: 0.869200, valid loss: 74.073840
epoch: 292, train precision: 0.997156, train loss: 9.820462, valid precision: 0.873800, valid loss: 73.484159
epoch: 293, train precision: 0.996756, train loss: 9.930435, valid precision: 0.873600, valid loss: 75.970164
epoch: 294, train precision: 0.997000, train loss: 9.770175, valid precision: 0.874400, valid loss: 73.658965
epoch: 295, train precision: 0.996356, train loss: 9.996030, valid precision: 0.872000, valid loss: 74.281917
epoch: 296, train precision: 0.996578, train loss: 10.070362, valid precision: 0.870800, valid loss: 75.575193
epoch: 297, train precision: 0.996844, train loss: 9.965827, valid precision: 0.871800, valid loss: 74.632549
epoch: 298, train precision: 0.997267, train loss: 9.811218, valid precision: 0.871400, valid loss: 76.434469
epoch: 299, train precision: 0.997467, train loss: 9.755104, valid precision: 0.869200, valid loss: 76.516916
epoch: 300, train precision: 0.996244, train loss: 10.080723, valid precision: 0.869400, valid loss: 79.187782
epoch: 301, train precision: 0.996644, train loss: 10.002043, valid precision: 0.869800, valid loss: 76.523270
epoch: 302, train precision: 0.997111, train loss: 9.843416, valid precision: 0.873000, valid loss: 76.609045
epoch: 303, train precision: 0.996489, train loss: 10.099270, valid precision: 0.869200, valid loss: 75.885228
epoch: 304, train precision: 0.996622, train loss: 9.979773, valid precision: 0.873800, valid loss: 76.830471
epoch: 305, train precision: 0.996756, train loss: 9.987223, valid precision: 0.873400, valid loss: 75.220354
epoch: 306, train precision: 0.996756, train loss: 9.936217, valid precision: 0.871000, valid loss: 75.352219
epoch: 307, train precision: 0.997689, train loss: 9.775420, valid precision: 0.873200, valid loss: 74.957925
epoch: 308, train precision: 0.997022, train loss: 9.946515, valid precision: 0.871400, valid loss: 76.807771
epoch: 309, train precision: 0.996444, train loss: 10.067056, valid precision: 0.873400, valid loss: 77.133683
epoch: 310, train precision: 0.996778, train loss: 9.947137, valid precision: 0.873000, valid loss: 75.100330
epoch: 311, train precision: 0.997600, train loss: 9.796290, valid precision: 0.874600, valid loss: 73.843105
epoch: 312, train precision: 0.997022, train loss: 10.013644, valid precision: 0.874800, valid loss: 75.806448
epoch: 313, train precision: 0.996289, train loss: 10.231602, valid precision: 0.867400, valid loss: 75.307298
epoch: 314, train precision: 0.997067, train loss: 9.932124, valid precision: 0.872400, valid loss: 76.849642
epoch: 315, train precision: 0.997067, train loss: 9.924278, valid precision: 0.876400, valid loss: 74.732821
epoch: 316, train precision: 0.996622, train loss: 10.067778, valid precision: 0.871800, valid loss: 77.183519
epoch: 317, train precision: 0.997267, train loss: 9.973617, valid precision: 0.872600, valid loss: 76.215721
epoch: 318, train precision: 0.996889, train loss: 10.048272, valid precision: 0.867800, valid loss: 75.950159
epoch: 319, train precision: 0.997267, train loss: 9.973169, valid precision: 0.875400, valid loss: 74.737131
epoch: 320, train precision: 0.997356, train loss: 9.895780, valid precision: 0.875000, valid loss: 76.700486
epoch: 321, train precision: 0.996978, train loss: 10.066432, valid precision: 0.872200, valid loss: 79.070688
epoch: 322, train precision: 0.996822, train loss: 10.076811, valid precision: 0.872800, valid loss: 76.530283
epoch: 323, train precision: 0.996044, train loss: 10.418557, valid precision: 0.869800, valid loss: 77.174423
epoch: 324, train precision: 0.997400, train loss: 9.896428, valid precision: 0.876400, valid loss: 75.347320
epoch: 325, train precision: 0.997311, train loss: 9.933996, valid precision: 0.876200, valid loss: 74.447874
epoch: 326, train precision: 0.997622, train loss: 9.886145, valid precision: 0.874400, valid loss: 76.695311
epoch: 327, train precision: 0.997244, train loss: 9.963515, valid precision: 0.874200, valid loss: 74.079389
epoch: 328, train precision: 0.996733, train loss: 10.059322, valid precision: 0.870400, valid loss: 75.714343
epoch: 329, train precision: 0.996533, train loss: 10.211811, valid precision: 0.866200, valid loss: 76.764614
epoch: 330, train precision: 0.997533, train loss: 9.956969, valid precision: 0.868600, valid loss: 76.456776
epoch: 331, train precision: 0.996556, train loss: 10.326957, valid precision: 0.870600, valid loss: 77.225929
epoch: 332, train precision: 0.996956, train loss: 10.087749, valid precision: 0.872400, valid loss: 75.233529
epoch: 333, train precision: 0.997578, train loss: 10.030923, valid precision: 0.869200, valid loss: 76.949859
epoch: 334, train precision: 0.997156, train loss: 10.055221, valid precision: 0.869400, valid loss: 76.514791
epoch: 335, train precision: 0.997444, train loss: 10.018613, valid precision: 0.870800, valid loss: 76.606432
epoch: 336, train precision: 0.996889, train loss: 10.118278, valid precision: 0.875800, valid loss: 76.319477
epoch: 337, train precision: 0.997356, train loss: 10.030331, valid precision: 0.876800, valid loss: 75.615338
epoch: 338, train precision: 0.996889, train loss: 10.167193, valid precision: 0.874400, valid loss: 76.332575
epoch: 339, train precision: 0.996889, train loss: 10.172121, valid precision: 0.873600, valid loss: 75.938260
epoch: 340, train precision: 0.997111, train loss: 10.078803, valid precision: 0.870000, valid loss: 75.931607
epoch: 341, train precision: 0.997089, train loss: 10.141527, valid precision: 0.868400, valid loss: 77.156489
epoch: 342, train precision: 0.996444, train loss: 10.355240, valid precision: 0.869400, valid loss: 78.488507
epoch: 343, train precision: 0.997356, train loss: 10.103897, valid precision: 0.872600, valid loss: 76.967722
epoch: 344, train precision: 0.996800, train loss: 10.170021, valid precision: 0.875200, valid loss: 76.697557
epoch: 345, train precision: 0.996356, train loss: 10.323941, valid precision: 0.871600, valid loss: 76.688429
epoch: 346, train precision: 0.997022, train loss: 10.230192, valid precision: 0.877400, valid loss: 76.749093
epoch: 347, train precision: 0.996867, train loss: 10.176712, valid precision: 0.873000, valid loss: 77.937324
epoch: 348, train precision: 0.997467, train loss: 9.934631, valid precision: 0.871800, valid loss: 77.675552
epoch: 349, train precision: 0.997511, train loss: 10.030231, valid precision: 0.873000, valid loss: 75.872408
epoch: 350, train precision: 0.997578, train loss: 10.035708, valid precision: 0.876200, valid loss: 76.172129
epoch: 351, train precision: 0.997556, train loss: 10.089898, valid precision: 0.867200, valid loss: 80.824279
epoch: 352, train precision: 0.996778, train loss: 10.344156, valid precision: 0.867800, valid loss: 78.500916
epoch: 353, train precision: 0.997400, train loss: 10.181224, valid precision: 0.873200, valid loss: 76.618716
epoch: 354, train precision: 0.997400, train loss: 10.107436, valid precision: 0.871200, valid loss: 76.484528
epoch: 355, train precision: 0.997822, train loss: 9.911306, valid precision: 0.873200, valid loss: 76.514302
epoch: 356, train precision: 0.997822, train loss: 9.940092, valid precision: 0.873400, valid loss: 77.991902
epoch: 357, train precision: 0.996956, train loss: 10.143710, valid precision: 0.873600, valid loss: 77.288281
epoch: 358, train precision: 0.997111, train loss: 10.233611, valid precision: 0.872200, valid loss: 77.383054
epoch: 359, train precision: 0.997267, train loss: 10.095811, valid precision: 0.874400, valid loss: 76.624972
epoch: 360, train precision: 0.997400, train loss: 10.169806, valid precision: 0.873600, valid loss: 75.629030
epoch: 361, train precision: 0.997333, train loss: 10.090662, valid precision: 0.874400, valid loss: 75.620620
epoch: 362, train precision: 0.997311, train loss: 10.143984, valid precision: 0.872200, valid loss: 77.476357
epoch: 363, train precision: 0.997178, train loss: 10.120649, valid precision: 0.865400, valid loss: 78.244596
epoch: 364, train precision: 0.997178, train loss: 10.224868, valid precision: 0.871200, valid loss: 79.103909
epoch: 365, train precision: 0.997333, train loss: 10.231327, valid precision: 0.873200, valid loss: 76.823832
epoch: 366, train precision: 0.997822, train loss: 10.064665, valid precision: 0.872800, valid loss: 77.796975
epoch: 367, train precision: 0.996822, train loss: 10.311122, valid precision: 0.871000, valid loss: 78.990886
epoch: 368, train precision: 0.997289, train loss: 10.256824, valid precision: 0.872600, valid loss: 77.123550
epoch: 369, train precision: 0.996778, train loss: 10.260231, valid precision: 0.871800, valid loss: 78.143207
epoch: 370, train precision: 0.996933, train loss: 10.265261, valid precision: 0.869800, valid loss: 77.227433
epoch: 371, train precision: 0.997156, train loss: 10.254657, valid precision: 0.874000, valid loss: 78.870966
epoch: 372, train precision: 0.997067, train loss: 10.287540, valid precision: 0.872400, valid loss: 80.096685
epoch: 373, train precision: 0.996022, train loss: 10.563899, valid precision: 0.871600, valid loss: 79.087130
epoch: 374, train precision: 0.997467, train loss: 10.108026, valid precision: 0.874800, valid loss: 77.613042
epoch: 375, train precision: 0.997378, train loss: 10.182544, valid precision: 0.875200, valid loss: 77.357053
epoch: 376, train precision: 0.997356, train loss: 10.188560, valid precision: 0.878200, valid loss: 77.459775
epoch: 377, train precision: 0.997578, train loss: 10.056714, valid precision: 0.878800, valid loss: 76.578618
epoch: 378, train precision: 0.997311, train loss: 10.236459, valid precision: 0.878000, valid loss: 75.852451
epoch: 379, train precision: 0.997311, train loss: 10.242343, valid precision: 0.876800, valid loss: 75.708145
epoch: 380, train precision: 0.997644, train loss: 10.145633, valid precision: 0.878400, valid loss: 76.653192
epoch: 381, train precision: 0.997311, train loss: 10.177291, valid precision: 0.873200, valid loss: 77.509322
epoch: 382, train precision: 0.997267, train loss: 10.244904, valid precision: 0.875800, valid loss: 77.915530
epoch: 383, train precision: 0.997533, train loss: 10.133065, valid precision: 0.875200, valid loss: 77.717393
epoch: 384, train precision: 0.997111, train loss: 10.309235, valid precision: 0.877200, valid loss: 77.064326
epoch: 385, train precision: 0.997711, train loss: 10.112305, valid precision: 0.874800, valid loss: 77.184770
epoch: 386, train precision: 0.997444, train loss: 10.233497, valid precision: 0.874000, valid loss: 76.196352
epoch: 387, train precision: 0.997200, train loss: 10.250140, valid precision: 0.875400, valid loss: 75.956845
epoch: 388, train precision: 0.996844, train loss: 10.424653, valid precision: 0.873800, valid loss: 76.165630
epoch: 389, train precision: 0.997533, train loss: 10.185094, valid precision: 0.876000, valid loss: 75.762145
epoch: 390, train precision: 0.997267, train loss: 10.275828, valid precision: 0.876800, valid loss: 76.460181
epoch: 391, train precision: 0.997400, train loss: 10.219183, valid precision: 0.874400, valid loss: 78.167190
epoch: 392, train precision: 0.997467, train loss: 10.297920, valid precision: 0.874200, valid loss: 78.150227
epoch: 393, train precision: 0.997622, train loss: 10.272341, valid precision: 0.867600, valid loss: 79.361111
epoch: 394, train precision: 0.997378, train loss: 10.223964, valid precision: 0.876400, valid loss: 75.796364
epoch: 395, train precision: 0.997578, train loss: 10.207252, valid precision: 0.878800, valid loss: 74.374905
epoch: 396, train precision: 0.997489, train loss: 10.249005, valid precision: 0.873600, valid loss: 75.751543
epoch: 397, train precision: 0.996822, train loss: 10.365860, valid precision: 0.879200, valid loss: 75.709814
epoch: 398, train precision: 0.997556, train loss: 10.223302, valid precision: 0.878200, valid loss: 74.959881
epoch: 399, train precision: 0.997400, train loss: 10.340873, valid precision: 0.876200, valid loss: 76.266547
epoch: 400, train precision: 0.997133, train loss: 10.421071, valid precision: 0.872800, valid loss: 79.023898
epoch: 401, train precision: 0.996978, train loss: 10.479081, valid precision: 0.875000, valid loss: 76.238937
epoch: 402, train precision: 0.996978, train loss: 10.408428, valid precision: 0.874600, valid loss: 78.342461
epoch: 403, train precision: 0.997067, train loss: 10.410214, valid precision: 0.873400, valid loss: 77.324106
epoch: 404, train precision: 0.997533, train loss: 10.336347, valid precision: 0.879400, valid loss: 74.063702
epoch: 405, train precision: 0.997822, train loss: 10.200552, valid precision: 0.878400, valid loss: 72.804324
epoch: 406, train precision: 0.997444, train loss: 10.328897, valid precision: 0.876200, valid loss: 74.832061
epoch: 407, train precision: 0.997867, train loss: 10.234228, valid precision: 0.872400, valid loss: 74.906022
epoch: 408, train precision: 0.997022, train loss: 10.372089, valid precision: 0.870800, valid loss: 78.693281
epoch: 409, train precision: 0.997289, train loss: 10.368906, valid precision: 0.877000, valid loss: 76.611357
epoch: 410, train precision: 0.998200, train loss: 10.145382, valid precision: 0.877400, valid loss: 74.800435
epoch: 411, train precision: 0.997000, train loss: 10.546544, valid precision: 0.877200, valid loss: 77.102657
epoch: 412, train precision: 0.997444, train loss: 10.354325, valid precision: 0.879200, valid loss: 75.202929
epoch: 413, train precision: 0.997644, train loss: 10.368182, valid precision: 0.874800, valid loss: 74.716866
epoch: 414, train precision: 0.997644, train loss: 10.346513, valid precision: 0.875200, valid loss: 76.854421
epoch: 415, train precision: 0.998222, train loss: 10.096574, valid precision: 0.875200, valid loss: 75.205184
epoch: 416, train precision: 0.997756, train loss: 10.257975, valid precision: 0.877600, valid loss: 75.807660
epoch: 417, train precision: 0.997356, train loss: 10.315258, valid precision: 0.875200, valid loss: 77.012560
epoch: 418, train precision: 0.997533, train loss: 10.327572, valid precision: 0.872600, valid loss: 78.326198
epoch: 419, train precision: 0.997444, train loss: 10.313439, valid precision: 0.877000, valid loss: 76.318403
epoch: 420, train precision: 0.998089, train loss: 10.131642, valid precision: 0.875600, valid loss: 76.850321
epoch: 421, train precision: 0.997867, train loss: 10.163145, valid precision: 0.875200, valid loss: 78.706144
epoch: 422, train precision: 0.997089, train loss: 10.501147, valid precision: 0.873000, valid loss: 79.053290
epoch: 423, train precision: 0.997889, train loss: 10.343303, valid precision: 0.877600, valid loss: 76.456516
epoch: 424, train precision: 0.997733, train loss: 10.302417, valid precision: 0.874600, valid loss: 76.416348
epoch: 425, train precision: 0.997289, train loss: 10.376687, valid precision: 0.875200, valid loss: 78.260627
epoch: 426, train precision: 0.998022, train loss: 10.209101, valid precision: 0.873400, valid loss: 79.520941
epoch: 427, train precision: 0.997644, train loss: 10.265908, valid precision: 0.875000, valid loss: 79.228588
epoch: 428, train precision: 0.997689, train loss: 10.317225, valid precision: 0.879200, valid loss: 78.351355
epoch: 429, train precision: 0.997889, train loss: 10.357569, valid precision: 0.871800, valid loss: 80.394289
epoch: 430, train precision: 0.997111, train loss: 10.533112, valid precision: 0.872600, valid loss: 77.817229
epoch: 431, train precision: 0.998000, train loss: 10.259495, valid precision: 0.877200, valid loss: 76.874334
epoch: 432, train precision: 0.997289, train loss: 10.396847, valid precision: 0.875600, valid loss: 78.017703
epoch: 433, train precision: 0.997622, train loss: 10.299741, valid precision: 0.877400, valid loss: 78.299132
epoch: 434, train precision: 0.997244, train loss: 10.387038, valid precision: 0.878400, valid loss: 77.147189
epoch: 435, train precision: 0.996267, train loss: 10.681774, valid precision: 0.876800, valid loss: 79.187674
epoch: 436, train precision: 0.997956, train loss: 10.214020, valid precision: 0.877400, valid loss: 77.249917
epoch: 437, train precision: 0.997867, train loss: 10.268011, valid precision: 0.876800, valid loss: 79.343098
epoch: 438, train precision: 0.997267, train loss: 10.454899, valid precision: 0.879000, valid loss: 79.341494
epoch: 439, train precision: 0.997978, train loss: 10.217881, valid precision: 0.879400, valid loss: 78.113104
epoch: 440, train precision: 0.997533, train loss: 10.307727, valid precision: 0.873200, valid loss: 79.401608
epoch: 441, train precision: 0.997756, train loss: 10.244620, valid precision: 0.875400, valid loss: 79.204253
epoch: 442, train precision: 0.997311, train loss: 10.463925, valid precision: 0.879400, valid loss: 78.787568
epoch: 443, train precision: 0.998044, train loss: 10.216731, valid precision: 0.876000, valid loss: 77.616650
epoch: 444, train precision: 0.997844, train loss: 10.328802, valid precision: 0.877600, valid loss: 79.826085
epoch: 445, train precision: 0.997822, train loss: 10.318118, valid precision: 0.871600, valid loss: 79.684313
epoch: 446, train precision: 0.997800, train loss: 10.374483, valid precision: 0.876400, valid loss: 80.368120
epoch: 447, train precision: 0.997756, train loss: 10.351707, valid precision: 0.875000, valid loss: 78.087341
epoch: 448, train precision: 0.998200, train loss: 10.189103, valid precision: 0.874800, valid loss: 77.885268
epoch: 449, train precision: 0.997422, train loss: 10.412265, valid precision: 0.878200, valid loss: 78.237557
epoch: 450, train precision: 0.997333, train loss: 10.517682, valid precision: 0.874800, valid loss: 80.087490
epoch: 451, train precision: 0.997933, train loss: 10.366787, valid precision: 0.875600, valid loss: 79.062750
epoch: 452, train precision: 0.996667, train loss: 10.648753, valid precision: 0.870200, valid loss: 82.091671
epoch: 453, train precision: 0.997911, train loss: 10.308756, valid precision: 0.874200, valid loss: 78.233613
epoch: 454, train precision: 0.996933, train loss: 10.625531, valid precision: 0.876000, valid loss: 80.720432
epoch: 455, train precision: 0.997889, train loss: 10.305244, valid precision: 0.875000, valid loss: 79.771504
epoch: 456, train precision: 0.998000, train loss: 10.328907, valid precision: 0.871600, valid loss: 81.116628
epoch: 457, train precision: 0.998156, train loss: 10.216945, valid precision: 0.875400, valid loss: 79.427691
epoch: 458, train precision: 0.997889, train loss: 10.347212, valid precision: 0.873400, valid loss: 80.403238
epoch: 459, train precision: 0.998311, train loss: 10.269843, valid precision: 0.876000, valid loss: 80.079094
epoch: 460, train precision: 0.997889, train loss: 10.417026, valid precision: 0.873600, valid loss: 81.047877
epoch: 461, train precision: 0.997800, train loss: 10.418391, valid precision: 0.873400, valid loss: 80.352568
epoch: 462, train precision: 0.997689, train loss: 10.446562, valid precision: 0.879400, valid loss: 78.598681
epoch: 463, train precision: 0.997600, train loss: 10.440560, valid precision: 0.873000, valid loss: 78.624743
epoch: 464, train precision: 0.997578, train loss: 10.397823, valid precision: 0.875400, valid loss: 80.673715
epoch: 465, train precision: 0.998000, train loss: 10.399878, valid precision: 0.872400, valid loss: 79.437245
epoch: 466, train precision: 0.998133, train loss: 10.304169, valid precision: 0.873600, valid loss: 80.262399
epoch: 467, train precision: 0.997200, train loss: 10.569488, valid precision: 0.872200, valid loss: 81.533461
epoch: 468, train precision: 0.998422, train loss: 10.189419, valid precision: 0.873000, valid loss: 82.068285
epoch: 469, train precision: 0.997489, train loss: 10.375326, valid precision: 0.870600, valid loss: 81.493850
epoch: 470, train precision: 0.997956, train loss: 10.349581, valid precision: 0.876800, valid loss: 79.455670
epoch: 471, train precision: 0.997867, train loss: 10.270540, valid precision: 0.876200, valid loss: 79.448318
epoch: 472, train precision: 0.998133, train loss: 10.323536, valid precision: 0.877200, valid loss: 78.934197
epoch: 473, train precision: 0.998156, train loss: 10.370842, valid precision: 0.873600, valid loss: 79.635392
epoch: 474, train precision: 0.997733, train loss: 10.441691, valid precision: 0.873400, valid loss: 81.048411
epoch: 475, train precision: 0.997778, train loss: 10.425351, valid precision: 0.870800, valid loss: 82.407175
epoch: 476, train precision: 0.997956, train loss: 10.420968, valid precision: 0.872400, valid loss: 81.779786
epoch: 477, train precision: 0.998000, train loss: 10.390138, valid precision: 0.879000, valid loss: 81.762128
epoch: 478, train precision: 0.997933, train loss: 10.380249, valid precision: 0.873400, valid loss: 81.103533
epoch: 479, train precision: 0.997689, train loss: 10.429975, valid precision: 0.872200, valid loss: 81.391819
epoch: 480, train precision: 0.997356, train loss: 10.571370, valid precision: 0.872000, valid loss: 82.038395
epoch: 481, train precision: 0.997600, train loss: 10.504047, valid precision: 0.875600, valid loss: 80.693985
epoch: 482, train precision: 0.998156, train loss: 10.304746, valid precision: 0.873000, valid loss: 82.073558
epoch: 483, train precision: 0.998378, train loss: 10.289184, valid precision: 0.878600, valid loss: 79.671487
epoch: 484, train precision: 0.997689, train loss: 10.522208, valid precision: 0.869800, valid loss: 80.715730
epoch: 485, train precision: 0.997800, train loss: 10.424668, valid precision: 0.875400, valid loss: 79.215719
epoch: 486, train precision: 0.998311, train loss: 10.317479, valid precision: 0.871400, valid loss: 82.304362
epoch: 487, train precision: 0.998356, train loss: 10.405053, valid precision: 0.874000, valid loss: 82.948424
epoch: 488, train precision: 0.997822, train loss: 10.497199, valid precision: 0.874400, valid loss: 80.796171
epoch: 489, train precision: 0.998467, train loss: 10.210484, valid precision: 0.876400, valid loss: 82.190699
epoch: 490, train precision: 0.997689, train loss: 10.473212, valid precision: 0.873600, valid loss: 80.342422
epoch: 491, train precision: 0.998111, train loss: 10.375687, valid precision: 0.875800, valid loss: 81.391722
epoch: 492, train precision: 0.997311, train loss: 10.639115, valid precision: 0.877800, valid loss: 81.269772
epoch: 493, train precision: 0.996733, train loss: 10.863035, valid precision: 0.873200, valid loss: 82.874673
epoch: 494, train precision: 0.998378, train loss: 10.306860, valid precision: 0.879800, valid loss: 79.131885
epoch: 495, train precision: 0.998289, train loss: 10.354220, valid precision: 0.877200, valid loss: 78.582237
epoch: 496, train precision: 0.998022, train loss: 10.395278, valid precision: 0.878400, valid loss: 80.346078
epoch: 497, train precision: 0.998000, train loss: 10.412787, valid precision: 0.877600, valid loss: 81.739855
epoch: 498, train precision: 0.998422, train loss: 10.336863, valid precision: 0.874600, valid loss: 81.241094
epoch: 499, train precision: 0.998089, train loss: 10.361553, valid precision: 0.876200, valid loss: 80.681702
epoch: 500, train precision: 0.998178, train loss: 10.332802, valid precision: 0.876200, valid loss: 78.424797
epoch: 501, train precision: 0.998222, train loss: 10.328560, valid precision: 0.876600, valid loss: 80.811555
epoch: 502, train precision: 0.997556, train loss: 10.548785, valid precision: 0.873800, valid loss: 81.334276
epoch: 503, train precision: 0.997933, train loss: 10.484240, valid precision: 0.872800, valid loss: 84.237260
epoch: 504, train precision: 0.998444, train loss: 10.306561, valid precision: 0.874200, valid loss: 80.665087
epoch: 505, train precision: 0.997978, train loss: 10.393282, valid precision: 0.875800, valid loss: 82.074012
epoch: 506, train precision: 0.997778, train loss: 10.603197, valid precision: 0.877000, valid loss: 80.534437
epoch: 507, train precision: 0.998156, train loss: 10.424560, valid precision: 0.874000, valid loss: 81.006246
epoch: 508, train precision: 0.998533, train loss: 10.209530, valid precision: 0.876600, valid loss: 81.665705
epoch: 509, train precision: 0.997756, train loss: 10.523750, valid precision: 0.875800, valid loss: 81.041542
epoch: 510, train precision: 0.997156, train loss: 10.662796, valid precision: 0.872400, valid loss: 80.173157
epoch: 511, train precision: 0.997822, train loss: 10.482304, valid precision: 0.878800, valid loss: 78.493557
epoch: 512, train precision: 0.998356, train loss: 10.341967, valid precision: 0.875800, valid loss: 79.202895
epoch: 513, train precision: 0.998600, train loss: 10.283299, valid precision: 0.878000, valid loss: 80.467664
epoch: 514, train precision: 0.998067, train loss: 10.541851, valid precision: 0.875200, valid loss: 82.231927
epoch: 515, train precision: 0.998333, train loss: 10.393214, valid precision: 0.876800, valid loss: 79.255517
epoch: 516, train precision: 0.998089, train loss: 10.454116, valid precision: 0.876000, valid loss: 81.527570
epoch: 517, train precision: 0.998133, train loss: 10.395387, valid precision: 0.880000, valid loss: 81.115453
epoch: 518, train precision: 0.997156, train loss: 10.712519, valid precision: 0.874800, valid loss: 80.902548
epoch: 519, train precision: 0.998044, train loss: 10.507330, valid precision: 0.881200, valid loss: 79.119381
epoch: 520, train precision: 0.997889, train loss: 10.392815, valid precision: 0.876800, valid loss: 82.515352
epoch: 521, train precision: 0.998156, train loss: 10.449128, valid precision: 0.872200, valid loss: 82.300019
epoch: 522, train precision: 0.997600, train loss: 10.597629, valid precision: 0.875200, valid loss: 80.511204
epoch: 523, train precision: 0.997933, train loss: 10.524768, valid precision: 0.872600, valid loss: 81.183816
epoch: 524, train precision: 0.998311, train loss: 10.463095, valid precision: 0.876800, valid loss: 81.213876
epoch: 525, train precision: 0.997911, train loss: 10.506561, valid precision: 0.877000, valid loss: 83.108262
epoch: 526, train precision: 0.998356, train loss: 10.384842, valid precision: 0.875200, valid loss: 80.434371
epoch: 527, train precision: 0.998422, train loss: 10.390743, valid precision: 0.874600, valid loss: 79.932169
epoch: 528, train precision: 0.998200, train loss: 10.447089, valid precision: 0.875200, valid loss: 82.926625
epoch: 529, train precision: 0.998533, train loss: 10.273085, valid precision: 0.874800, valid loss: 81.660104
epoch: 530, train precision: 0.998333, train loss: 10.401804, valid precision: 0.876600, valid loss: 78.740684
epoch: 531, train precision: 0.998089, train loss: 10.463351, valid precision: 0.878200, valid loss: 81.866938
epoch: 532, train precision: 0.997511, train loss: 10.638498, valid precision: 0.877800, valid loss: 81.391841
epoch: 533, train precision: 0.998200, train loss: 10.498043, valid precision: 0.875200, valid loss: 82.030461
epoch: 534, train precision: 0.998578, train loss: 10.338603, valid precision: 0.880800, valid loss: 79.119109
epoch: 535, train precision: 0.998044, train loss: 10.483260, valid precision: 0.878200, valid loss: 81.866832
epoch: 536, train precision: 0.998000, train loss: 10.529485, valid precision: 0.879000, valid loss: 78.091079
epoch: 537, train precision: 0.998000, train loss: 10.482936, valid precision: 0.876400, valid loss: 81.621100
epoch: 538, train precision: 0.997400, train loss: 10.655837, valid precision: 0.876200, valid loss: 83.395657
epoch: 539, train precision: 0.998422, train loss: 10.398007, valid precision: 0.876000, valid loss: 80.587524
epoch: 540, train precision: 0.998556, train loss: 10.400026, valid precision: 0.874200, valid loss: 80.760703
epoch: 541, train precision: 0.998533, train loss: 10.342998, valid precision: 0.876800, valid loss: 82.106244
epoch: 542, train precision: 0.998000, train loss: 10.603418, valid precision: 0.874600, valid loss: 81.383712
epoch: 543, train precision: 0.998111, train loss: 10.498530, valid precision: 0.874200, valid loss: 82.276372
epoch: 544, train precision: 0.998667, train loss: 10.353466, valid precision: 0.876600, valid loss: 82.851958
epoch: 545, train precision: 0.997511, train loss: 10.686742, valid precision: 0.876000, valid loss: 82.001963
epoch: 546, train precision: 0.998311, train loss: 10.428780, valid precision: 0.879000, valid loss: 81.473665
epoch: 547, train precision: 0.997978, train loss: 10.455116, valid precision: 0.874800, valid loss: 81.764089
epoch: 548, train precision: 0.997911, train loss: 10.600118, valid precision: 0.873800, valid loss: 81.778780
epoch: 549, train precision: 0.997689, train loss: 10.585900, valid precision: 0.878200, valid loss: 82.017867
epoch: 550, train precision: 0.998111, train loss: 10.460610, valid precision: 0.875800, valid loss: 83.091481
epoch: 551, train precision: 0.998244, train loss: 10.476965, valid precision: 0.873600, valid loss: 83.603658
epoch: 552, train precision: 0.997533, train loss: 10.628222, valid precision: 0.876600, valid loss: 83.187456
epoch: 553, train precision: 0.998600, train loss: 10.389386, valid precision: 0.877200, valid loss: 82.848065
epoch: 554, train precision: 0.998178, train loss: 10.441037, valid precision: 0.871800, valid loss: 86.576987
epoch: 555, train precision: 0.997578, train loss: 10.606124, valid precision: 0.873600, valid loss: 84.881186
epoch: 556, train precision: 0.997733, train loss: 10.618627, valid precision: 0.879000, valid loss: 83.778455
epoch: 557, train precision: 0.998400, train loss: 10.459953, valid precision: 0.878000, valid loss: 81.210294
epoch: 558, train precision: 0.998267, train loss: 10.422752, valid precision: 0.881400, valid loss: 83.062486
epoch: 559, train precision: 0.998200, train loss: 10.457921, valid precision: 0.879400, valid loss: 82.305592
epoch: 560, train precision: 0.998289, train loss: 10.446558, valid precision: 0.875600, valid loss: 83.686375
epoch: 561, train precision: 0.997822, train loss: 10.587216, valid precision: 0.875800, valid loss: 83.150553
epoch: 562, train precision: 0.998489, train loss: 10.355474, valid precision: 0.875400, valid loss: 81.666770
epoch: 563, train precision: 0.997711, train loss: 10.601636, valid precision: 0.873000, valid loss: 83.546341
epoch: 564, train precision: 0.997956, train loss: 10.539157, valid precision: 0.873400, valid loss: 83.302287
epoch: 565, train precision: 0.998267, train loss: 10.416160, valid precision: 0.875200, valid loss: 84.085209
epoch: 566, train precision: 0.997267, train loss: 10.740986, valid precision: 0.871000, valid loss: 82.508194
epoch: 567, train precision: 0.997644, train loss: 10.683732, valid precision: 0.872800, valid loss: 83.809690
epoch: 568, train precision: 0.997911, train loss: 10.589121, valid precision: 0.872800, valid loss: 84.314193
epoch: 569, train precision: 0.998178, train loss: 10.562488, valid precision: 0.877400, valid loss: 81.148205
epoch: 570, train precision: 0.998489, train loss: 10.370036, valid precision: 0.877800, valid loss: 80.613154
epoch: 571, train precision: 0.998467, train loss: 10.423660, valid precision: 0.880400, valid loss: 80.457770
epoch: 572, train precision: 0.998133, train loss: 10.632176, valid precision: 0.878000, valid loss: 79.036180
epoch: 573, train precision: 0.996933, train loss: 10.876163, valid precision: 0.869200, valid loss: 82.676779
epoch: 574, train precision: 0.998111, train loss: 10.543398, valid precision: 0.879000, valid loss: 80.235155
epoch: 575, train precision: 0.997956, train loss: 10.593548, valid precision: 0.874600, valid loss: 80.130525
epoch: 576, train precision: 0.997822, train loss: 10.600909, valid precision: 0.875600, valid loss: 80.749196
epoch: 577, train precision: 0.997956, train loss: 10.523302, valid precision: 0.877800, valid loss: 81.583770
epoch: 578, train precision: 0.998067, train loss: 10.590514, valid precision: 0.880200, valid loss: 82.106220
epoch: 579, train precision: 0.998067, train loss: 10.569833, valid precision: 0.877600, valid loss: 81.292676
epoch: 580, train precision: 0.998089, train loss: 10.510932, valid precision: 0.878800, valid loss: 81.123712
epoch: 581, train precision: 0.998644, train loss: 10.408813, valid precision: 0.872600, valid loss: 83.206886
epoch: 582, train precision: 0.998200, train loss: 10.487028, valid precision: 0.880600, valid loss: 80.761866
epoch: 583, train precision: 0.997600, train loss: 10.721235, valid precision: 0.875800, valid loss: 82.334590
epoch: 584, train precision: 0.998111, train loss: 10.619821, valid precision: 0.879600, valid loss: 79.092461
epoch: 585, train precision: 0.997933, train loss: 10.746360, valid precision: 0.874000, valid loss: 84.349610
epoch: 586, train precision: 0.998489, train loss: 10.483767, valid precision: 0.880800, valid loss: 79.816624
epoch: 587, train precision: 0.998622, train loss: 10.448696, valid precision: 0.879600, valid loss: 78.863668
epoch: 588, train precision: 0.998067, train loss: 10.557525, valid precision: 0.878600, valid loss: 80.550486
epoch: 589, train precision: 0.998222, train loss: 10.560429, valid precision: 0.873600, valid loss: 83.665862
epoch: 590, train precision: 0.998556, train loss: 10.410575, valid precision: 0.877400, valid loss: 80.694240
epoch: 591, train precision: 0.998089, train loss: 10.555307, valid precision: 0.872000, valid loss: 82.222132
epoch: 592, train precision: 0.998000, train loss: 10.629613, valid precision: 0.871800, valid loss: 81.644940
epoch: 593, train precision: 0.998244, train loss: 10.565947, valid precision: 0.875400, valid loss: 79.955745
epoch: 594, train precision: 0.998422, train loss: 10.450686, valid precision: 0.874600, valid loss: 80.924126
epoch: 595, train precision: 0.998422, train loss: 10.448679, valid precision: 0.875600, valid loss: 81.859253
epoch: 596, train precision: 0.998111, train loss: 10.573391, valid precision: 0.876000, valid loss: 81.226393
epoch: 597, train precision: 0.998533, train loss: 10.413862, valid precision: 0.875200, valid loss: 81.714245
epoch: 598, train precision: 0.998200, train loss: 10.535669, valid precision: 0.876000, valid loss: 82.588681
epoch: 599, train precision: 0.998311, train loss: 10.543845, valid precision: 0.874000, valid loss: 82.812600
epoch: 600, train precision: 0.998778, train loss: 10.368815, valid precision: 0.877600, valid loss: 80.682094
epoch: 601, train precision: 0.998133, train loss: 10.651425, valid precision: 0.878000, valid loss: 80.221601
epoch: 602, train precision: 0.997533, train loss: 10.740206, valid precision: 0.879600, valid loss: 81.691050
epoch: 603, train precision: 0.998311, train loss: 10.474466, valid precision: 0.877400, valid loss: 80.689399
epoch: 604, train precision: 0.997978, train loss: 10.609315, valid precision: 0.875400, valid loss: 82.033757
epoch: 605, train precision: 0.998178, train loss: 10.613586, valid precision: 0.874400, valid loss: 79.280444
epoch: 606, train precision: 0.998311, train loss: 10.522654, valid precision: 0.874800, valid loss: 79.743165
epoch: 607, train precision: 0.998333, train loss: 10.534900, valid precision: 0.880000, valid loss: 78.708518
epoch: 608, train precision: 0.998089, train loss: 10.636704, valid precision: 0.877800, valid loss: 80.179306
epoch: 609, train precision: 0.998200, train loss: 10.555012, valid precision: 0.875800, valid loss: 81.497498
epoch: 610, train precision: 0.998489, train loss: 10.451614, valid precision: 0.875400, valid loss: 82.185689
epoch: 611, train precision: 0.998111, train loss: 10.579065, valid precision: 0.874600, valid loss: 80.759428
epoch: 612, train precision: 0.997933, train loss: 10.753214, valid precision: 0.875800, valid loss: 81.523286
epoch: 613, train precision: 0.998489, train loss: 10.529061, valid precision: 0.878000, valid loss: 80.994143
epoch: 614, train precision: 0.997867, train loss: 10.683341, valid precision: 0.873800, valid loss: 81.391854
epoch: 615, train precision: 0.997622, train loss: 10.786208, valid precision: 0.876800, valid loss: 80.625751
epoch: 616, train precision: 0.998156, train loss: 10.594757, valid precision: 0.873600, valid loss: 80.395071
epoch: 617, train precision: 0.998644, train loss: 10.482105, valid precision: 0.880600, valid loss: 82.088635
epoch: 618, train precision: 0.998422, train loss: 10.522516, valid precision: 0.879200, valid loss: 79.058658
epoch: 619, train precision: 0.997822, train loss: 10.669472, valid precision: 0.878200, valid loss: 79.462303
epoch: 620, train precision: 0.998400, train loss: 10.524250, valid precision: 0.874800, valid loss: 80.954241
epoch: 621, train precision: 0.998067, train loss: 10.598133, valid precision: 0.878800, valid loss: 82.994171
epoch: 622, train precision: 0.998467, train loss: 10.489371, valid precision: 0.879000, valid loss: 78.307637
epoch: 623, train precision: 0.998356, train loss: 10.512708, valid precision: 0.877400, valid loss: 81.656520
epoch: 624, train precision: 0.998533, train loss: 10.523625, valid precision: 0.876600, valid loss: 82.119938
epoch: 625, train precision: 0.998178, train loss: 10.609651, valid precision: 0.874400, valid loss: 79.530879
epoch: 626, train precision: 0.997267, train loss: 10.930404, valid precision: 0.873600, valid loss: 82.693750
epoch: 627, train precision: 0.997400, train loss: 10.855862, valid precision: 0.875800, valid loss: 84.445056
epoch: 628, train precision: 0.998089, train loss: 10.667784, valid precision: 0.875200, valid loss: 84.167027
epoch: 629, train precision: 0.997933, train loss: 10.595167, valid precision: 0.874800, valid loss: 82.489929
epoch: 630, train precision: 0.998244, train loss: 10.622066, valid precision: 0.876200, valid loss: 82.736834
epoch: 631, train precision: 0.998467, train loss: 10.502125, valid precision: 0.874200, valid loss: 81.350984
epoch: 632, train precision: 0.997956, train loss: 10.659951, valid precision: 0.876400, valid loss: 80.139455
epoch: 633, train precision: 0.998489, train loss: 10.500578, valid precision: 0.876800, valid loss: 80.922033
epoch: 634, train precision: 0.998000, train loss: 10.624689, valid precision: 0.877600, valid loss: 81.964828
epoch: 635, train precision: 0.997822, train loss: 10.692965, valid precision: 0.877400, valid loss: 82.029172
epoch: 636, train precision: 0.998089, train loss: 10.687244, valid precision: 0.879800, valid loss: 80.988446
epoch: 637, train precision: 0.997756, train loss: 10.763317, valid precision: 0.878000, valid loss: 82.279525
epoch: 638, train precision: 0.997978, train loss: 10.617309, valid precision: 0.879000, valid loss: 82.018423
epoch: 639, train precision: 0.998244, train loss: 10.633252, valid precision: 0.878200, valid loss: 80.756610
epoch: 640, train precision: 0.998000, train loss: 10.681347, valid precision: 0.875000, valid loss: 80.576579
epoch: 641, train precision: 0.998356, train loss: 10.516928, valid precision: 0.877000, valid loss: 81.076257
epoch: 642, train precision: 0.998733, train loss: 10.511365, valid precision: 0.876200, valid loss: 79.606301
epoch: 643, train precision: 0.998244, train loss: 10.583873, valid precision: 0.879600, valid loss: 80.194171
epoch: 644, train precision: 0.998044, train loss: 10.686173, valid precision: 0.877200, valid loss: 81.269065
epoch: 645, train precision: 0.998489, train loss: 10.437040, valid precision: 0.876600, valid loss: 81.612485
epoch: 646, train precision: 0.997156, train loss: 10.907640, valid precision: 0.871400, valid loss: 82.622160
epoch: 647, train precision: 0.998156, train loss: 10.638429, valid precision: 0.877600, valid loss: 80.332544
epoch: 648, train precision: 0.998844, train loss: 10.496812, valid precision: 0.882400, valid loss: 79.165909
epoch: 649, train precision: 0.998689, train loss: 10.544578, valid precision: 0.879800, valid loss: 79.836445
epoch: 650, train precision: 0.998067, train loss: 10.712979, valid precision: 0.881400, valid loss: 78.560598
epoch: 651, train precision: 0.998200, train loss: 10.544599, valid precision: 0.876800, valid loss: 79.722629
epoch: 652, train precision: 0.998378, train loss: 10.601642, valid precision: 0.880600, valid loss: 77.890337
epoch: 653, train precision: 0.998667, train loss: 10.441888, valid precision: 0.879800, valid loss: 79.420821
epoch: 654, train precision: 0.998178, train loss: 10.613504, valid precision: 0.875800, valid loss: 79.565586
epoch: 655, train precision: 0.998800, train loss: 10.522053, valid precision: 0.879800, valid loss: 78.580452
epoch: 656, train precision: 0.998489, train loss: 10.535245, valid precision: 0.883200, valid loss: 80.541771
epoch: 657, train precision: 0.998778, train loss: 10.513786, valid precision: 0.880000, valid loss: 78.453987
epoch: 658, train precision: 0.998356, train loss: 10.590694, valid precision: 0.873400, valid loss: 79.466658
epoch: 659, train precision: 0.998067, train loss: 10.626420, valid precision: 0.877200, valid loss: 80.623265
epoch: 660, train precision: 0.998378, train loss: 10.555144, valid precision: 0.878400, valid loss: 79.352966
epoch: 661, train precision: 0.998267, train loss: 10.612226, valid precision: 0.874400, valid loss: 82.944497
epoch: 662, train precision: 0.998267, train loss: 10.615546, valid precision: 0.877800, valid loss: 79.049296
epoch: 663, train precision: 0.998222, train loss: 10.597238, valid precision: 0.878600, valid loss: 78.388898
epoch: 664, train precision: 0.997978, train loss: 10.705600, valid precision: 0.875800, valid loss: 79.790616
epoch: 665, train precision: 0.998533, train loss: 10.484913, valid precision: 0.882400, valid loss: 79.516840
epoch: 666, train precision: 0.998400, train loss: 10.568595, valid precision: 0.877800, valid loss: 79.086198
epoch: 667, train precision: 0.998311, train loss: 10.648963, valid precision: 0.878200, valid loss: 80.599840
epoch: 668, train precision: 0.998267, train loss: 10.565524, valid precision: 0.876000, valid loss: 80.279190
epoch: 669, train precision: 0.998956, train loss: 10.508054, valid precision: 0.882400, valid loss: 79.838769
epoch: 670, train precision: 0.998400, train loss: 10.610357, valid precision: 0.878400, valid loss: 81.143413
epoch: 671, train precision: 0.998244, train loss: 10.652704, valid precision: 0.878400, valid loss: 80.506159
epoch: 672, train precision: 0.997711, train loss: 10.803878, valid precision: 0.879800, valid loss: 80.327828
epoch: 673, train precision: 0.999089, train loss: 10.386324, valid precision: 0.879400, valid loss: 79.492845
epoch: 674, train precision: 0.998467, train loss: 10.503944, valid precision: 0.876800, valid loss: 80.593990
epoch: 675, train precision: 0.998756, train loss: 10.576511, valid precision: 0.874600, valid loss: 82.104817
epoch: 676, train precision: 0.997978, train loss: 10.834231, valid precision: 0.874600, valid loss: 84.325197
epoch: 677, train precision: 0.998000, train loss: 10.764091, valid precision: 0.877000, valid loss: 82.913941
epoch: 678, train precision: 0.998289, train loss: 10.589033, valid precision: 0.877600, valid loss: 80.710914
epoch: 679, train precision: 0.998578, train loss: 10.586139, valid precision: 0.879200, valid loss: 80.056751
epoch: 680, train precision: 0.998644, train loss: 10.498598, valid precision: 0.878200, valid loss: 78.446405
epoch: 681, train precision: 0.997800, train loss: 10.794777, valid precision: 0.872400, valid loss: 83.137589
epoch: 682, train precision: 0.998222, train loss: 10.586452, valid precision: 0.872800, valid loss: 80.494686
epoch: 683, train precision: 0.998578, train loss: 10.580568, valid precision: 0.877400, valid loss: 79.731503
epoch: 684, train precision: 0.998244, train loss: 10.664272, valid precision: 0.877800, valid loss: 80.656557
epoch: 685, train precision: 0.998378, train loss: 10.645140, valid precision: 0.883400, valid loss: 79.788272
epoch: 686, train precision: 0.998244, train loss: 10.633518, valid precision: 0.877400, valid loss: 81.674824
epoch: 687, train precision: 0.998822, train loss: 10.471717, valid precision: 0.879400, valid loss: 79.944328
epoch: 688, train precision: 0.998422, train loss: 10.504120, valid precision: 0.876400, valid loss: 80.944925
epoch: 689, train precision: 0.998089, train loss: 10.711690, valid precision: 0.880600, valid loss: 81.452960
epoch: 690, train precision: 0.998467, train loss: 10.628993, valid precision: 0.879800, valid loss: 80.260053
epoch: 691, train precision: 0.998378, train loss: 10.637189, valid precision: 0.879400, valid loss: 82.903934
epoch: 692, train precision: 0.998267, train loss: 10.685649, valid precision: 0.876400, valid loss: 80.755503
epoch: 693, train precision: 0.998578, train loss: 10.475765, valid precision: 0.875800, valid loss: 82.157674
epoch: 694, train precision: 0.998756, train loss: 10.537556, valid precision: 0.879000, valid loss: 80.527252
epoch: 695, train precision: 0.998289, train loss: 10.648963, valid precision: 0.876600, valid loss: 81.180220
epoch: 696, train precision: 0.998111, train loss: 10.774007, valid precision: 0.878000, valid loss: 81.741043
epoch: 697, train precision: 0.998289, train loss: 10.594383, valid precision: 0.881400, valid loss: 81.119905
epoch: 698, train precision: 0.998311, train loss: 10.614931, valid precision: 0.883200, valid loss: 81.005077
epoch: 699, train precision: 0.998356, train loss: 10.749437, valid precision: 0.879400, valid loss: 79.689453
epoch: 700, train precision: 0.998511, train loss: 10.624765, valid precision: 0.876600, valid loss: 79.772440
epoch: 701, train precision: 0.997756, train loss: 10.821858, valid precision: 0.879000, valid loss: 79.893263
epoch: 702, train precision: 0.998511, train loss: 10.596796, valid precision: 0.877800, valid loss: 79.017015
epoch: 703, train precision: 0.998467, train loss: 10.579890, valid precision: 0.879600, valid loss: 81.206831
epoch: 704, train precision: 0.998467, train loss: 10.632604, valid precision: 0.873600, valid loss: 81.499974
epoch: 705, train precision: 0.998267, train loss: 10.758947, valid precision: 0.876200, valid loss: 84.416673
epoch: 706, train precision: 0.998422, train loss: 10.625483, valid precision: 0.876200, valid loss: 81.081311
epoch: 707, train precision: 0.998844, train loss: 10.476583, valid precision: 0.879600, valid loss: 79.003431
epoch: 708, train precision: 0.998333, train loss: 10.627024, valid precision: 0.877200, valid loss: 81.195685
epoch: 709, train precision: 0.998667, train loss: 10.605685, valid precision: 0.876600, valid loss: 77.909641
epoch: 710, train precision: 0.998267, train loss: 10.626367, valid precision: 0.878600, valid loss: 80.206417
epoch: 711, train precision: 0.998444, train loss: 10.587979, valid precision: 0.875000, valid loss: 79.986616
epoch: 712, train precision: 0.998400, train loss: 10.605172, valid precision: 0.874800, valid loss: 80.073482
epoch: 713, train precision: 0.998489, train loss: 10.579003, valid precision: 0.877400, valid loss: 81.334759
epoch: 714, train precision: 0.998556, train loss: 10.655914, valid precision: 0.876200, valid loss: 82.218004
epoch: 715, train precision: 0.998533, train loss: 10.597980, valid precision: 0.876000, valid loss: 80.900957
epoch: 716, train precision: 0.998400, train loss: 10.701146, valid precision: 0.872800, valid loss: 82.717694
epoch: 717, train precision: 0.998689, train loss: 10.537672, valid precision: 0.876000, valid loss: 80.852746
epoch: 718, train precision: 0.998489, train loss: 10.538263, valid precision: 0.876400, valid loss: 80.699036
epoch: 719, train precision: 0.998089, train loss: 10.718790, valid precision: 0.878800, valid loss: 80.589771
epoch: 720, train precision: 0.998711, train loss: 10.580004, valid precision: 0.875400, valid loss: 81.187374
epoch: 721, train precision: 0.998667, train loss: 10.617709, valid precision: 0.877200, valid loss: 81.362826
epoch: 722, train precision: 0.998600, train loss: 10.547477, valid precision: 0.876000, valid loss: 82.850695
epoch: 723, train precision: 0.998622, train loss: 10.530615, valid precision: 0.880000, valid loss: 80.835384
epoch: 724, train precision: 0.998378, train loss: 10.641384, valid precision: 0.881000, valid loss: 79.340844
epoch: 725, train precision: 0.998289, train loss: 10.642509, valid precision: 0.878400, valid loss: 82.170732
epoch: 726, train precision: 0.998244, train loss: 10.619141, valid precision: 0.875800, valid loss: 82.630427
epoch: 727, train precision: 0.998556, train loss: 10.524386, valid precision: 0.877600, valid loss: 81.709451
epoch: 728, train precision: 0.998556, train loss: 10.593918, valid precision: 0.879400, valid loss: 80.536236
epoch: 729, train precision: 0.997978, train loss: 10.725270, valid precision: 0.872400, valid loss: 81.959781
epoch: 730, train precision: 0.998800, train loss: 10.516384, valid precision: 0.878200, valid loss: 82.091399
epoch: 731, train precision: 0.998578, train loss: 10.653280, valid precision: 0.876600, valid loss: 80.546357
epoch: 732, train precision: 0.998511, train loss: 10.645046, valid precision: 0.877200, valid loss: 82.047064
epoch: 733, train precision: 0.998800, train loss: 10.554928, valid precision: 0.881000, valid loss: 80.063511
epoch: 734, train precision: 0.998244, train loss: 10.695431, valid precision: 0.877800, valid loss: 80.253490
epoch: 735, train precision: 0.998889, train loss: 10.493846, valid precision: 0.878200, valid loss: 81.691370
epoch: 736, train precision: 0.998911, train loss: 10.459288, valid precision: 0.878000, valid loss: 80.532910
epoch: 737, train precision: 0.998733, train loss: 10.580747, valid precision: 0.877400, valid loss: 80.221092
epoch: 738, train precision: 0.998689, train loss: 10.536194, valid precision: 0.881800, valid loss: 81.723604
epoch: 739, train precision: 0.998267, train loss: 10.632783, valid precision: 0.878400, valid loss: 81.312139
epoch: 740, train precision: 0.998089, train loss: 10.633028, valid precision: 0.878000, valid loss: 83.683727
epoch: 741, train precision: 0.998022, train loss: 10.751023, valid precision: 0.878200, valid loss: 81.172647
epoch: 742, train precision: 0.998200, train loss: 10.761812, valid precision: 0.875600, valid loss: 81.398544
epoch: 743, train precision: 0.998533, train loss: 10.568530, valid precision: 0.877200, valid loss: 83.794451
epoch: 744, train precision: 0.998244, train loss: 10.636968, valid precision: 0.875600, valid loss: 86.316345
epoch: 745, train precision: 0.998689, train loss: 10.535172, valid precision: 0.876800, valid loss: 82.377818
epoch: 746, train precision: 0.997756, train loss: 10.778192, valid precision: 0.874800, valid loss: 84.415693
epoch: 747, train precision: 0.998489, train loss: 10.619652, valid precision: 0.878400, valid loss: 82.990637
epoch: 748, train precision: 0.998600, train loss: 10.626534, valid precision: 0.877200, valid loss: 83.934426
epoch: 749, train precision: 0.997489, train loss: 10.919729, valid precision: 0.870800, valid loss: 83.495828
epoch: 750, train precision: 0.998689, train loss: 10.498708, valid precision: 0.877400, valid loss: 81.598293
epoch: 751, train precision: 0.998556, train loss: 10.597809, valid precision: 0.876000, valid loss: 81.207622
epoch: 752, train precision: 0.998533, train loss: 10.552644, valid precision: 0.878400, valid loss: 84.530439
epoch: 753, train precision: 0.998378, train loss: 10.725615, valid precision: 0.874600, valid loss: 83.497170
epoch: 754, train precision: 0.997933, train loss: 10.798797, valid precision: 0.878800, valid loss: 81.774371
epoch: 755, train precision: 0.997933, train loss: 10.801045, valid precision: 0.875200, valid loss: 82.418943
epoch: 756, train precision: 0.998311, train loss: 10.701281, valid precision: 0.876400, valid loss: 81.894864
epoch: 757, train precision: 0.998800, train loss: 10.537270, valid precision: 0.878000, valid loss: 83.182177
epoch: 758, train precision: 0.998844, train loss: 10.522466, valid precision: 0.875800, valid loss: 84.319212
epoch: 759, train precision: 0.998556, train loss: 10.650152, valid precision: 0.873200, valid loss: 85.459993
epoch: 760, train precision: 0.998911, train loss: 10.513612, valid precision: 0.876600, valid loss: 84.303588
epoch: 761, train precision: 0.998356, train loss: 10.583989, valid precision: 0.876600, valid loss: 85.027568
epoch: 762, train precision: 0.998467, train loss: 10.672627, valid precision: 0.875000, valid loss: 84.205487
epoch: 763, train precision: 0.998667, train loss: 10.613110, valid precision: 0.880200, valid loss: 81.638912
epoch: 764, train precision: 0.998022, train loss: 10.748801, valid precision: 0.878000, valid loss: 83.335155
epoch: 765, train precision: 0.998600, train loss: 10.619505, valid precision: 0.873400, valid loss: 83.548616
epoch: 766, train precision: 0.998800, train loss: 10.521633, valid precision: 0.884200, valid loss: 81.401272
epoch: 767, train precision: 0.998600, train loss: 10.499317, valid precision: 0.878200, valid loss: 82.543696
epoch: 768, train precision: 0.998244, train loss: 10.734628, valid precision: 0.879400, valid loss: 83.213212
epoch: 769, train precision: 0.998667, train loss: 10.702718, valid precision: 0.881800, valid loss: 79.051708
epoch: 770, train precision: 0.998467, train loss: 10.604268, valid precision: 0.879800, valid loss: 78.768787
epoch: 771, train precision: 0.998644, train loss: 10.620189, valid precision: 0.875200, valid loss: 79.817538
epoch: 772, train precision: 0.998533, train loss: 10.693285, valid precision: 0.877400, valid loss: 80.956976
epoch: 773, train precision: 0.998644, train loss: 10.581141, valid precision: 0.874600, valid loss: 83.709067
epoch: 774, train precision: 0.998289, train loss: 10.678609, valid precision: 0.879600, valid loss: 81.337899
epoch: 775, train precision: 0.998689, train loss: 10.576228, valid precision: 0.882600, valid loss: 80.600901
epoch: 776, train precision: 0.998578, train loss: 10.573369, valid precision: 0.884000, valid loss: 78.830471
epoch: 777, train precision: 0.998689, train loss: 10.592413, valid precision: 0.876400, valid loss: 80.420366
epoch: 778, train precision: 0.997956, train loss: 10.777202, valid precision: 0.879800, valid loss: 81.222250
epoch: 779, train precision: 0.998600, train loss: 10.567442, valid precision: 0.878800, valid loss: 80.130136
epoch: 780, train precision: 0.998511, train loss: 10.536972, valid precision: 0.879400, valid loss: 81.230740
epoch: 781, train precision: 0.998044, train loss: 10.824835, valid precision: 0.875600, valid loss: 80.491741
epoch: 782, train precision: 0.998444, train loss: 10.662802, valid precision: 0.878600, valid loss: 79.971209
epoch: 783, train precision: 0.998533, train loss: 10.718752, valid precision: 0.876800, valid loss: 82.374577
epoch: 784, train precision: 0.998644, train loss: 10.558252, valid precision: 0.879000, valid loss: 82.789557
epoch: 785, train precision: 0.998867, train loss: 10.556857, valid precision: 0.878000, valid loss: 81.130008
epoch: 786, train precision: 0.998644, train loss: 10.639146, valid precision: 0.875800, valid loss: 81.385465
epoch: 787, train precision: 0.998022, train loss: 10.726988, valid precision: 0.876200, valid loss: 81.906335
epoch: 788, train precision: 0.998267, train loss: 10.761230, valid precision: 0.878400, valid loss: 82.383901
epoch: 789, train precision: 0.998644, train loss: 10.580751, valid precision: 0.876400, valid loss: 82.576762
epoch: 790, train precision: 0.998644, train loss: 10.645002, valid precision: 0.880400, valid loss: 82.820676
epoch: 791, train precision: 0.998222, train loss: 10.729075, valid precision: 0.878000, valid loss: 83.258964
epoch: 792, train precision: 0.998889, train loss: 10.481366, valid precision: 0.878600, valid loss: 82.428553
epoch: 793, train precision: 0.998356, train loss: 10.688022, valid precision: 0.873200, valid loss: 83.493931
epoch: 794, train precision: 0.998111, train loss: 10.713980, valid precision: 0.872200, valid loss: 84.637268
epoch: 795, train precision: 0.998311, train loss: 10.636362, valid precision: 0.878600, valid loss: 81.400360
epoch: 796, train precision: 0.997956, train loss: 10.797404, valid precision: 0.874000, valid loss: 83.027990
epoch: 797, train precision: 0.998556, train loss: 10.662161, valid precision: 0.880000, valid loss: 80.126722
epoch: 798, train precision: 0.998622, train loss: 10.581997, valid precision: 0.877400, valid loss: 80.829567
epoch: 799, train precision: 0.998467, train loss: 10.632526, valid precision: 0.874400, valid loss: 81.922038
epoch: 800, train precision: 0.997933, train loss: 10.915706, valid precision: 0.875200, valid loss: 83.611799
epoch: 801, train precision: 0.998800, train loss: 10.583300, valid precision: 0.879600, valid loss: 82.255075
epoch: 802, train precision: 0.998644, train loss: 10.526272, valid precision: 0.877200, valid loss: 82.797543
epoch: 803, train precision: 0.998044, train loss: 10.781332, valid precision: 0.876400, valid loss: 83.262005
epoch: 804, train precision: 0.998600, train loss: 10.643944, valid precision: 0.881000, valid loss: 78.617151
epoch: 805, train precision: 0.998178, train loss: 10.668004, valid precision: 0.876800, valid loss: 82.188727
epoch: 806, train precision: 0.998578, train loss: 10.710240, valid precision: 0.877000, valid loss: 83.507420
epoch: 807, train precision: 0.997978, train loss: 10.794621, valid precision: 0.872800, valid loss: 84.688918
epoch: 808, train precision: 0.998156, train loss: 10.756858, valid precision: 0.871800, valid loss: 82.871798
epoch: 809, train precision: 0.998222, train loss: 10.718675, valid precision: 0.874800, valid loss: 82.572269
epoch: 810, train precision: 0.998733, train loss: 10.539121, valid precision: 0.874800, valid loss: 81.245443
epoch: 811, train precision: 0.998511, train loss: 10.765076, valid precision: 0.877200, valid loss: 83.204001
epoch: 812, train precision: 0.999156, train loss: 10.457816, valid precision: 0.876600, valid loss: 82.431741
epoch: 813, train precision: 0.997978, train loss: 10.860935, valid precision: 0.876400, valid loss: 81.596138
epoch: 814, train precision: 0.998156, train loss: 10.826642, valid precision: 0.871600, valid loss: 84.462984
epoch: 815, train precision: 0.998600, train loss: 10.637316, valid precision: 0.881400, valid loss: 83.155024
epoch: 816, train precision: 0.998244, train loss: 10.679343, valid precision: 0.877800, valid loss: 81.384598
epoch: 817, train precision: 0.998400, train loss: 10.688904, valid precision: 0.876600, valid loss: 80.533326
epoch: 818, train precision: 0.997956, train loss: 10.888061, valid precision: 0.876600, valid loss: 82.795037
epoch: 819, train precision: 0.998400, train loss: 10.671645, valid precision: 0.877000, valid loss: 80.634273
epoch: 820, train precision: 0.998600, train loss: 10.646731, valid precision: 0.878800, valid loss: 81.898156
epoch: 821, train precision: 0.998956, train loss: 10.514978, valid precision: 0.876600, valid loss: 81.888125
epoch: 822, train precision: 0.998511, train loss: 10.619989, valid precision: 0.881200, valid loss: 80.471019
epoch: 823, train precision: 0.998511, train loss: 10.644441, valid precision: 0.878400, valid loss: 79.679900
epoch: 824, train precision: 0.998400, train loss: 10.729181, valid precision: 0.877800, valid loss: 81.888210
epoch: 825, train precision: 0.998600, train loss: 10.630808, valid precision: 0.879400, valid loss: 83.327362
epoch: 826, train precision: 0.998289, train loss: 10.694808, valid precision: 0.882800, valid loss: 80.577059
epoch: 827, train precision: 0.998867, train loss: 10.635334, valid precision: 0.878200, valid loss: 81.572028
epoch: 828, train precision: 0.998733, train loss: 10.593840, valid precision: 0.879400, valid loss: 81.060771
epoch: 829, train precision: 0.998978, train loss: 10.599205, valid precision: 0.878000, valid loss: 82.129202
epoch: 830, train precision: 0.998867, train loss: 10.555942, valid precision: 0.874600, valid loss: 82.384250
epoch: 831, train precision: 0.998244, train loss: 10.817406, valid precision: 0.872000, valid loss: 84.975770
epoch: 832, train precision: 0.998467, train loss: 10.664391, valid precision: 0.875000, valid loss: 80.257243
epoch: 833, train precision: 0.998911, train loss: 10.573087, valid precision: 0.876400, valid loss: 81.041426
epoch: 834, train precision: 0.998711, train loss: 10.573782, valid precision: 0.879000, valid loss: 83.359164
epoch: 835, train precision: 0.998511, train loss: 10.732869, valid precision: 0.874200, valid loss: 84.812200
epoch: 836, train precision: 0.998533, train loss: 10.676590, valid precision: 0.872800, valid loss: 82.848541
epoch: 837, train precision: 0.998933, train loss: 10.549039, valid precision: 0.877600, valid loss: 81.595736
epoch: 838, train precision: 0.998422, train loss: 10.723242, valid precision: 0.874400, valid loss: 83.552892
epoch: 839, train precision: 0.998800, train loss: 10.602568, valid precision: 0.878600, valid loss: 83.007390
epoch: 840, train precision: 0.998733, train loss: 10.572064, valid precision: 0.877400, valid loss: 84.909322
epoch: 841, train precision: 0.998200, train loss: 10.737749, valid precision: 0.871600, valid loss: 85.335073
epoch: 842, train precision: 0.998622, train loss: 10.683752, valid precision: 0.879600, valid loss: 84.222288
epoch: 843, train precision: 0.998778, train loss: 10.588028, valid precision: 0.874600, valid loss: 80.574845
epoch: 844, train precision: 0.998711, train loss: 10.629470, valid precision: 0.878000, valid loss: 82.682516
epoch: 845, train precision: 0.998978, train loss: 10.516370, valid precision: 0.875000, valid loss: 84.425942
epoch: 846, train precision: 0.998689, train loss: 10.678597, valid precision: 0.878400, valid loss: 83.171801
epoch: 847, train precision: 0.998244, train loss: 10.782007, valid precision: 0.874600, valid loss: 84.170336
epoch: 848, train precision: 0.998467, train loss: 10.682654, valid precision: 0.875400, valid loss: 82.101693
epoch: 849, train precision: 0.998711, train loss: 10.663337, valid precision: 0.872800, valid loss: 82.518942
epoch: 850, train precision: 0.998467, train loss: 10.751556, valid precision: 0.871600, valid loss: 85.074417
epoch: 851, train precision: 0.998622, train loss: 10.653215, valid precision: 0.876600, valid loss: 83.965060
epoch: 852, train precision: 0.998867, train loss: 10.543799, valid precision: 0.877400, valid loss: 82.833622
epoch: 853, train precision: 0.998400, train loss: 10.688346, valid precision: 0.873600, valid loss: 84.515939
epoch: 854, train precision: 0.998467, train loss: 10.720105, valid precision: 0.875400, valid loss: 84.397183
epoch: 855, train precision: 0.998467, train loss: 10.688987, valid precision: 0.874200, valid loss: 83.129115
epoch: 856, train precision: 0.998800, train loss: 10.609248, valid precision: 0.872000, valid loss: 83.432149
epoch: 857, train precision: 0.998378, train loss: 10.772628, valid precision: 0.875400, valid loss: 82.992865
epoch: 858, train precision: 0.998556, train loss: 10.688186, valid precision: 0.875600, valid loss: 82.330995
epoch: 859, train precision: 0.998778, train loss: 10.652117, valid precision: 0.878800, valid loss: 81.128550
epoch: 860, train precision: 0.998556, train loss: 10.714601, valid precision: 0.876000, valid loss: 82.091963
epoch: 861, train precision: 0.998378, train loss: 10.708358, valid precision: 0.875400, valid loss: 81.630316
epoch: 862, train precision: 0.998778, train loss: 10.533799, valid precision: 0.876800, valid loss: 82.030561
epoch: 863, train precision: 0.998733, train loss: 10.628170, valid precision: 0.873000, valid loss: 82.711990
epoch: 864, train precision: 0.998578, train loss: 10.661362, valid precision: 0.877000, valid loss: 81.038806
epoch: 865, train precision: 0.998778, train loss: 10.578805, valid precision: 0.882600, valid loss: 79.257870
epoch: 866, train precision: 0.998711, train loss: 10.673232, valid precision: 0.880400, valid loss: 80.608153
epoch: 867, train precision: 0.998000, train loss: 10.832032, valid precision: 0.874600, valid loss: 82.827248
epoch: 868, train precision: 0.998311, train loss: 10.838747, valid precision: 0.876600, valid loss: 81.832813
epoch: 869, train precision: 0.998756, train loss: 10.667822, valid precision: 0.873800, valid loss: 83.698375
epoch: 870, train precision: 0.998756, train loss: 10.663154, valid precision: 0.874800, valid loss: 82.204542
epoch: 871, train precision: 0.998511, train loss: 10.680201, valid precision: 0.876000, valid loss: 81.629125
epoch: 872, train precision: 0.998444, train loss: 10.696362, valid precision: 0.874200, valid loss: 83.698960
epoch: 873, train precision: 0.998800, train loss: 10.631976, valid precision: 0.878200, valid loss: 84.801099
epoch: 874, train precision: 0.998378, train loss: 10.734767, valid precision: 0.874200, valid loss: 82.521856
epoch: 875, train precision: 0.998311, train loss: 10.776139, valid precision: 0.875200, valid loss: 82.280644
epoch: 876, train precision: 0.998733, train loss: 10.666887, valid precision: 0.879400, valid loss: 81.645351
epoch: 877, train precision: 0.998844, train loss: 10.586160, valid precision: 0.881600, valid loss: 80.758457
epoch: 878, train precision: 0.999000, train loss: 10.607545, valid precision: 0.875200, valid loss: 81.785026
epoch: 879, train precision: 0.998578, train loss: 10.653583, valid precision: 0.880000, valid loss: 82.217842
epoch: 880, train precision: 0.998356, train loss: 10.732704, valid precision: 0.883200, valid loss: 82.581484
epoch: 881, train precision: 0.998311, train loss: 10.702813, valid precision: 0.883200, valid loss: 82.483659
epoch: 882, train precision: 0.998267, train loss: 10.738615, valid precision: 0.876800, valid loss: 83.875923
epoch: 883, train precision: 0.998044, train loss: 10.858000, valid precision: 0.874800, valid loss: 87.215054
epoch: 884, train precision: 0.998800, train loss: 10.596947, valid precision: 0.877800, valid loss: 83.695542
epoch: 885, train precision: 0.998444, train loss: 10.743118, valid precision: 0.881000, valid loss: 83.586114
epoch: 886, train precision: 0.998756, train loss: 10.614954, valid precision: 0.878600, valid loss: 82.454468
epoch: 887, train precision: 0.998711, train loss: 10.563308, valid precision: 0.881200, valid loss: 81.220489
epoch: 888, train precision: 0.998400, train loss: 10.663885, valid precision: 0.880600, valid loss: 81.131048
epoch: 889, train precision: 0.998711, train loss: 10.600325, valid precision: 0.879200, valid loss: 80.773236
epoch: 890, train precision: 0.998467, train loss: 10.753105, valid precision: 0.881000, valid loss: 80.056551
epoch: 891, train precision: 0.998956, train loss: 10.613243, valid precision: 0.880000, valid loss: 79.987411
epoch: 892, train precision: 0.998956, train loss: 10.572899, valid precision: 0.879400, valid loss: 78.991689
epoch: 893, train precision: 0.998044, train loss: 10.810974, valid precision: 0.877200, valid loss: 80.745068
epoch: 894, train precision: 0.998689, train loss: 10.616143, valid precision: 0.883600, valid loss: 79.985301
epoch: 895, train precision: 0.998978, train loss: 10.665374, valid precision: 0.882200, valid loss: 80.325529
epoch: 896, train precision: 0.998911, train loss: 10.628221, valid precision: 0.883200, valid loss: 79.732775
epoch: 897, train precision: 0.999022, train loss: 10.556537, valid precision: 0.883000, valid loss: 78.659449
epoch: 898, train precision: 0.998822, train loss: 10.632929, valid precision: 0.881400, valid loss: 81.445285
epoch: 899, train precision: 0.998156, train loss: 10.888403, valid precision: 0.876600, valid loss: 81.926103
epoch: 900, train precision: 0.998600, train loss: 10.691074, valid precision: 0.878200, valid loss: 79.794153
epoch: 901, train precision: 0.998822, train loss: 10.637852, valid precision: 0.879800, valid loss: 82.084429
epoch: 902, train precision: 0.998911, train loss: 10.616090, valid precision: 0.880000, valid loss: 79.804455
epoch: 903, train precision: 0.998978, train loss: 10.515160, valid precision: 0.880000, valid loss: 81.751027
epoch: 904, train precision: 0.998667, train loss: 10.688871, valid precision: 0.881800, valid loss: 83.668191
epoch: 905, train precision: 0.998556, train loss: 10.665472, valid precision: 0.876200, valid loss: 81.636503
epoch: 906, train precision: 0.998689, train loss: 10.690411, valid precision: 0.880600, valid loss: 80.236586
epoch: 907, train precision: 0.999067, train loss: 10.535388, valid precision: 0.883200, valid loss: 80.761613
epoch: 908, train precision: 0.998378, train loss: 10.742850, valid precision: 0.880400, valid loss: 82.692226
epoch: 909, train precision: 0.998289, train loss: 10.738027, valid precision: 0.876600, valid loss: 83.284103
epoch: 910, train precision: 0.998800, train loss: 10.607687, valid precision: 0.881600, valid loss: 81.058627
epoch: 911, train precision: 0.998244, train loss: 10.705388, valid precision: 0.880600, valid loss: 80.467121
epoch: 912, train precision: 0.999244, train loss: 10.544757, valid precision: 0.881400, valid loss: 80.421197
epoch: 913, train precision: 0.998200, train loss: 10.801604, valid precision: 0.877400, valid loss: 83.114247
epoch: 914, train precision: 0.998578, train loss: 10.682931, valid precision: 0.877400, valid loss: 82.863203
epoch: 915, train precision: 0.998444, train loss: 10.690225, valid precision: 0.877200, valid loss: 82.370663
epoch: 916, train precision: 0.998733, train loss: 10.604143, valid precision: 0.877200, valid loss: 82.318007
epoch: 917, train precision: 0.998711, train loss: 10.623841, valid precision: 0.874600, valid loss: 85.652184
epoch: 918, train precision: 0.998600, train loss: 10.702195, valid precision: 0.879800, valid loss: 83.404598
epoch: 919, train precision: 0.998467, train loss: 10.714159, valid precision: 0.878800, valid loss: 82.909489
epoch: 920, train precision: 0.998911, train loss: 10.585043, valid precision: 0.879800, valid loss: 82.688851
epoch: 921, train precision: 0.999089, train loss: 10.499465, valid precision: 0.880600, valid loss: 83.564957
epoch: 922, train precision: 0.998333, train loss: 10.667632, valid precision: 0.880600, valid loss: 83.195988
epoch: 923, train precision: 0.998378, train loss: 10.728185, valid precision: 0.878000, valid loss: 84.418037
epoch: 924, train precision: 0.998733, train loss: 10.621327, valid precision: 0.878000, valid loss: 84.366928
epoch: 925, train precision: 0.999067, train loss: 10.498721, valid precision: 0.880600, valid loss: 81.402024
epoch: 926, train precision: 0.998556, train loss: 10.664233, valid precision: 0.880200, valid loss: 84.516791
epoch: 927, train precision: 0.998711, train loss: 10.628897, valid precision: 0.878000, valid loss: 83.949041
epoch: 928, train precision: 0.998822, train loss: 10.605481, valid precision: 0.879800, valid loss: 81.738642
epoch: 929, train precision: 0.998800, train loss: 10.626913, valid precision: 0.876400, valid loss: 83.070056
epoch: 930, train precision: 0.998622, train loss: 10.723896, valid precision: 0.879400, valid loss: 83.429516
epoch: 931, train precision: 0.998711, train loss: 10.622402, valid precision: 0.878800, valid loss: 82.433436
epoch: 932, train precision: 0.998622, train loss: 10.784595, valid precision: 0.871400, valid loss: 84.337289
epoch: 933, train precision: 0.998422, train loss: 10.754671, valid precision: 0.881200, valid loss: 82.926024
epoch: 934, train precision: 0.998644, train loss: 10.668729, valid precision: 0.876000, valid loss: 84.639149
epoch: 935, train precision: 0.997933, train loss: 10.886644, valid precision: 0.876000, valid loss: 83.458843
epoch: 936, train precision: 0.998644, train loss: 10.635576, valid precision: 0.877600, valid loss: 83.052373
epoch: 937, train precision: 0.998889, train loss: 10.564895, valid precision: 0.878200, valid loss: 83.827827
epoch: 938, train precision: 0.998711, train loss: 10.634497, valid precision: 0.876200, valid loss: 85.047542
epoch: 939, train precision: 0.998622, train loss: 10.715475, valid precision: 0.877400, valid loss: 84.789377
epoch: 940, train precision: 0.998400, train loss: 10.753886, valid precision: 0.880000, valid loss: 83.256305
epoch: 941, train precision: 0.998622, train loss: 10.649701, valid precision: 0.879000, valid loss: 85.184922
epoch: 942, train precision: 0.999022, train loss: 10.548674, valid precision: 0.881200, valid loss: 83.548681
epoch: 943, train precision: 0.998822, train loss: 10.609613, valid precision: 0.876200, valid loss: 82.517485
epoch: 944, train precision: 0.998622, train loss: 10.596671, valid precision: 0.877200, valid loss: 82.978555
epoch: 945, train precision: 0.998778, train loss: 10.590807, valid precision: 0.877600, valid loss: 83.640074
epoch: 946, train precision: 0.998689, train loss: 10.604362, valid precision: 0.875200, valid loss: 82.736075
epoch: 947, train precision: 0.998667, train loss: 10.592884, valid precision: 0.878400, valid loss: 83.420084
epoch: 948, train precision: 0.999089, train loss: 10.528558, valid precision: 0.881000, valid loss: 84.668016
epoch: 949, train precision: 0.998444, train loss: 10.730691, valid precision: 0.876800, valid loss: 84.465476
epoch: 950, train precision: 0.998778, train loss: 10.621258, valid precision: 0.876400, valid loss: 84.506234
epoch: 951, train precision: 0.998333, train loss: 10.734295, valid precision: 0.873400, valid loss: 86.907722
epoch: 952, train precision: 0.998711, train loss: 10.650146, valid precision: 0.879400, valid loss: 82.745422
epoch: 953, train precision: 0.998622, train loss: 10.646100, valid precision: 0.877000, valid loss: 85.376057
epoch: 954, train precision: 0.998822, train loss: 10.645571, valid precision: 0.879200, valid loss: 83.877970
epoch: 955, train precision: 0.998667, train loss: 10.724418, valid precision: 0.874200, valid loss: 83.585412
epoch: 956, train precision: 0.998733, train loss: 10.631406, valid precision: 0.877800, valid loss: 85.962368
epoch: 957, train precision: 0.999200, train loss: 10.533590, valid precision: 0.881000, valid loss: 83.613388
epoch: 958, train precision: 0.998644, train loss: 10.623974, valid precision: 0.881200, valid loss: 82.516493
epoch: 959, train precision: 0.997778, train loss: 10.982388, valid precision: 0.876400, valid loss: 85.215689
epoch: 960, train precision: 0.998556, train loss: 10.693395, valid precision: 0.876600, valid loss: 82.129437
epoch: 961, train precision: 0.998311, train loss: 10.794577, valid precision: 0.880400, valid loss: 79.746877
epoch: 962, train precision: 0.998889, train loss: 10.592624, valid precision: 0.878600, valid loss: 81.254676
epoch: 963, train precision: 0.998400, train loss: 10.746525, valid precision: 0.878000, valid loss: 82.295426
epoch: 964, train precision: 0.999022, train loss: 10.573131, valid precision: 0.878000, valid loss: 83.579435
epoch: 965, train precision: 0.998667, train loss: 10.647650, valid precision: 0.879800, valid loss: 82.173444
epoch: 966, train precision: 0.998111, train loss: 10.861550, valid precision: 0.877400, valid loss: 82.776489
epoch: 967, train precision: 0.998844, train loss: 10.668523, valid precision: 0.877400, valid loss: 84.762452
epoch: 968, train precision: 0.998911, train loss: 10.561810, valid precision: 0.878000, valid loss: 83.642586
epoch: 969, train precision: 0.999267, train loss: 10.471850, valid precision: 0.875000, valid loss: 84.119773
epoch: 970, train precision: 0.998556, train loss: 10.678996, valid precision: 0.877400, valid loss: 84.723447
epoch: 971, train precision: 0.998533, train loss: 10.730347, valid precision: 0.873400, valid loss: 85.065009
epoch: 972, train precision: 0.998622, train loss: 10.694594, valid precision: 0.875800, valid loss: 85.213389
epoch: 973, train precision: 0.998578, train loss: 10.721407, valid precision: 0.874800, valid loss: 83.668951
epoch: 974, train precision: 0.998467, train loss: 10.641650, valid precision: 0.881600, valid loss: 81.996511
epoch: 975, train precision: 0.998378, train loss: 10.748333, valid precision: 0.877000, valid loss: 84.292136
epoch: 976, train precision: 0.998511, train loss: 10.715074, valid precision: 0.875600, valid loss: 82.703669
epoch: 977, train precision: 0.998800, train loss: 10.609702, valid precision: 0.878000, valid loss: 81.898557
epoch: 978, train precision: 0.998667, train loss: 10.632334, valid precision: 0.875800, valid loss: 83.709780
epoch: 979, train precision: 0.998644, train loss: 10.703000, valid precision: 0.877800, valid loss: 81.927146
epoch: 980, train precision: 0.998978, train loss: 10.502048, valid precision: 0.877000, valid loss: 84.804388
epoch: 981, train precision: 0.998511, train loss: 10.682780, valid precision: 0.874000, valid loss: 85.124060
epoch: 982, train precision: 0.998844, train loss: 10.582207, valid precision: 0.875600, valid loss: 84.184616
epoch: 983, train precision: 0.998622, train loss: 10.690080, valid precision: 0.877600, valid loss: 85.548572
epoch: 984, train precision: 0.998222, train loss: 10.838456, valid precision: 0.876800, valid loss: 85.433031
epoch: 985, train precision: 0.999044, train loss: 10.586336, valid precision: 0.877400, valid loss: 82.985251
epoch: 986, train precision: 0.998378, train loss: 10.742161, valid precision: 0.877600, valid loss: 83.572003
epoch: 987, train precision: 0.998689, train loss: 10.649915, valid precision: 0.877800, valid loss: 83.956743
epoch: 988, train precision: 0.998711, train loss: 10.668246, valid precision: 0.876400, valid loss: 84.406896
epoch: 989, train precision: 0.998533, train loss: 10.668272, valid precision: 0.879400, valid loss: 83.597779
epoch: 990, train precision: 0.998067, train loss: 10.849951, valid precision: 0.874600, valid loss: 85.008317
epoch: 991, train precision: 0.998667, train loss: 10.699254, valid precision: 0.875000, valid loss: 85.410646
epoch: 992, train precision: 0.998956, train loss: 10.598989, valid precision: 0.878200, valid loss: 83.551820
epoch: 993, train precision: 0.998422, train loss: 10.711779, valid precision: 0.880400, valid loss: 83.386866
epoch: 994, train precision: 0.998778, train loss: 10.604065, valid precision: 0.879400, valid loss: 81.645483
epoch: 995, train precision: 0.998867, train loss: 10.657731, valid precision: 0.876600, valid loss: 84.158778
epoch: 996, train precision: 0.998533, train loss: 10.790742, valid precision: 0.878400, valid loss: 84.019669
epoch: 997, train precision: 0.998311, train loss: 10.797882, valid precision: 0.877200, valid loss: 84.939169
epoch: 998, train precision: 0.998933, train loss: 10.602785, valid precision: 0.879800, valid loss: 86.208073
epoch: 999, train precision: 0.998844, train loss: 10.651377, valid precision: 0.880200, valid loss: 85.348029
epoch: 1000, train precision: 0.998267, train loss: 10.764545, valid precision: 0.878600, valid loss: 85.772606
epoch: 1001, train precision: 0.998267, train loss: 10.863165, valid precision: 0.878600, valid loss: 82.998939
epoch: 1002, train precision: 0.998511, train loss: 10.690872, valid precision: 0.880000, valid loss: 82.926233
epoch: 1003, train precision: 0.998222, train loss: 10.839521, valid precision: 0.882000, valid loss: 84.970767
epoch: 1004, train precision: 0.998844, train loss: 10.585134, valid precision: 0.878600, valid loss: 82.343090
epoch: 1005, train precision: 0.998400, train loss: 10.774814, valid precision: 0.878400, valid loss: 84.534487
epoch: 1006, train precision: 0.999356, train loss: 10.449798, valid precision: 0.882200, valid loss: 81.914176
epoch: 1007, train precision: 0.998711, train loss: 10.618288, valid precision: 0.878400, valid loss: 84.937240
epoch: 1008, train precision: 0.998711, train loss: 10.642878, valid precision: 0.878400, valid loss: 82.224193
epoch: 1009, train precision: 0.998667, train loss: 10.621803, valid precision: 0.880800, valid loss: 81.607693
epoch: 1010, train precision: 0.998933, train loss: 10.652582, valid precision: 0.877200, valid loss: 83.181728
epoch: 1011, train precision: 0.998267, train loss: 10.832982, valid precision: 0.880200, valid loss: 85.384115
epoch: 1012, train precision: 0.998889, train loss: 10.646973, valid precision: 0.874200, valid loss: 85.974675
epoch: 1013, train precision: 0.998489, train loss: 10.690317, valid precision: 0.878200, valid loss: 84.389063
epoch: 1014, train precision: 0.998733, train loss: 10.674346, valid precision: 0.875600, valid loss: 84.032601
epoch: 1015, train precision: 0.998978, train loss: 10.583343, valid precision: 0.880000, valid loss: 82.939227
epoch: 1016, train precision: 0.998489, train loss: 10.727251, valid precision: 0.881000, valid loss: 82.939068
epoch: 1017, train precision: 0.998733, train loss: 10.686059, valid precision: 0.879800, valid loss: 83.622434
epoch: 1018, train precision: 0.998533, train loss: 10.666632, valid precision: 0.878400, valid loss: 85.354977
epoch: 1019, train precision: 0.998689, train loss: 10.637792, valid precision: 0.877200, valid loss: 84.019780
epoch: 1020, train precision: 0.998356, train loss: 10.722229, valid precision: 0.879400, valid loss: 84.366524
epoch: 1021, train precision: 0.999067, train loss: 10.643568, valid precision: 0.879000, valid loss: 85.034252
epoch: 1022, train precision: 0.999089, train loss: 10.517166, valid precision: 0.881000, valid loss: 82.160012
epoch: 1023, train precision: 0.998867, train loss: 10.614775, valid precision: 0.881000, valid loss: 83.500915
epoch: 1024, train precision: 0.998444, train loss: 10.742567, valid precision: 0.879000, valid loss: 85.604314
epoch: 1025, train precision: 0.998644, train loss: 10.694771, valid precision: 0.879200, valid loss: 84.940487
epoch: 1026, train precision: 0.998400, train loss: 10.726576, valid precision: 0.879000, valid loss: 86.599004
epoch: 1027, train precision: 0.998644, train loss: 10.707801, valid precision: 0.880800, valid loss: 83.828327
epoch: 1028, train precision: 0.998978, train loss: 10.544642, valid precision: 0.882800, valid loss: 81.582381
epoch: 1029, train precision: 0.998378, train loss: 10.781159, valid precision: 0.880200, valid loss: 83.293882
epoch: 1030, train precision: 0.998844, train loss: 10.631698, valid precision: 0.879000, valid loss: 83.837306
epoch: 1031, train precision: 0.998533, train loss: 10.706148, valid precision: 0.879600, valid loss: 83.453300
epoch: 1032, train precision: 0.998822, train loss: 10.590611, valid precision: 0.879600, valid loss: 81.940711
epoch: 1033, train precision: 0.999022, train loss: 10.555873, valid precision: 0.876400, valid loss: 83.710188
epoch: 1034, train precision: 0.998356, train loss: 10.739075, valid precision: 0.881600, valid loss: 82.745482
epoch: 1035, train precision: 0.998267, train loss: 10.781227, valid precision: 0.873400, valid loss: 84.043809
epoch: 1036, train precision: 0.999156, train loss: 10.586936, valid precision: 0.875200, valid loss: 83.609327
epoch: 1037, train precision: 0.998378, train loss: 10.713806, valid precision: 0.877200, valid loss: 84.497249
epoch: 1038, train precision: 0.998733, train loss: 10.636141, valid precision: 0.879600, valid loss: 82.954622
epoch: 1039, train precision: 0.998644, train loss: 10.634797, valid precision: 0.874000, valid loss: 84.409813
epoch: 1040, train precision: 0.998667, train loss: 10.633046, valid precision: 0.878000, valid loss: 83.604020
epoch: 1041, train precision: 0.998844, train loss: 10.604107, valid precision: 0.876600, valid loss: 86.058797
epoch: 1042, train precision: 0.999133, train loss: 10.541733, valid precision: 0.875800, valid loss: 86.664187
epoch: 1043, train precision: 0.998822, train loss: 10.629156, valid precision: 0.878600, valid loss: 83.010736
epoch: 1044, train precision: 0.998822, train loss: 10.718017, valid precision: 0.878800, valid loss: 84.122829
epoch: 1045, train precision: 0.998800, train loss: 10.629588, valid precision: 0.877600, valid loss: 84.986674
epoch: 1046, train precision: 0.999089, train loss: 10.527618, valid precision: 0.880400, valid loss: 85.071497
epoch: 1047, train precision: 0.998822, train loss: 10.660538, valid precision: 0.874800, valid loss: 85.627685
epoch: 1048, train precision: 0.998733, train loss: 10.670018, valid precision: 0.874200, valid loss: 85.614356
epoch: 1049, train precision: 0.998378, train loss: 10.706276, valid precision: 0.873000, valid loss: 86.444626
epoch: 1050, train precision: 0.998733, train loss: 10.667002, valid precision: 0.872000, valid loss: 86.538222
epoch: 1051, train precision: 0.999089, train loss: 10.549576, valid precision: 0.874000, valid loss: 85.243107
epoch: 1052, train precision: 0.998600, train loss: 10.724310, valid precision: 0.874400, valid loss: 85.239857
epoch: 1053, train precision: 0.998800, train loss: 10.602703, valid precision: 0.874600, valid loss: 86.238304
epoch: 1054, train precision: 0.998733, train loss: 10.673014, valid precision: 0.875400, valid loss: 83.864597
epoch: 1055, train precision: 0.998889, train loss: 10.550881, valid precision: 0.869400, valid loss: 88.364109
epoch: 1056, train precision: 0.998822, train loss: 10.641502, valid precision: 0.874600, valid loss: 85.348707
epoch: 1057, train precision: 0.998533, train loss: 10.680720, valid precision: 0.875000, valid loss: 84.169208
epoch: 1058, train precision: 0.999000, train loss: 10.622091, valid precision: 0.873600, valid loss: 83.950584
epoch: 1059, train precision: 0.998889, train loss: 10.614879, valid precision: 0.877000, valid loss: 84.579413
epoch: 1060, train precision: 0.998533, train loss: 10.698411, valid precision: 0.872800, valid loss: 85.557790
epoch: 1061, train precision: 0.998822, train loss: 10.607390, valid precision: 0.873800, valid loss: 84.856733
epoch: 1062, train precision: 0.998889, train loss: 10.625798, valid precision: 0.871000, valid loss: 87.136585
epoch: 1063, train precision: 0.998800, train loss: 10.602152, valid precision: 0.874600, valid loss: 85.195889
epoch: 1064, train precision: 0.999022, train loss: 10.549994, valid precision: 0.877400, valid loss: 85.428709
epoch: 1065, train precision: 0.999000, train loss: 10.632685, valid precision: 0.874800, valid loss: 83.735586
epoch: 1066, train precision: 0.998533, train loss: 10.655175, valid precision: 0.874800, valid loss: 84.441616
epoch: 1067, train precision: 0.998778, train loss: 10.620676, valid precision: 0.875200, valid loss: 85.790390
epoch: 1068, train precision: 0.998622, train loss: 10.668325, valid precision: 0.871400, valid loss: 86.781146
epoch: 1069, train precision: 0.999022, train loss: 10.572051, valid precision: 0.878000, valid loss: 82.228172
epoch: 1070, train precision: 0.998733, train loss: 10.600511, valid precision: 0.875800, valid loss: 84.530037
epoch: 1071, train precision: 0.998756, train loss: 10.665121, valid precision: 0.874400, valid loss: 85.132373
epoch: 1072, train precision: 0.998800, train loss: 10.622705, valid precision: 0.872000, valid loss: 84.935097
epoch: 1073, train precision: 0.998178, train loss: 10.833006, valid precision: 0.874400, valid loss: 86.490187
epoch: 1074, train precision: 0.998400, train loss: 10.654186, valid precision: 0.878400, valid loss: 85.893785
epoch: 1075, train precision: 0.998356, train loss: 10.738369, valid precision: 0.875600, valid loss: 83.445103
epoch: 1076, train precision: 0.998556, train loss: 10.736449, valid precision: 0.872200, valid loss: 86.553796
epoch: 1077, train precision: 0.998533, train loss: 10.747048, valid precision: 0.878000, valid loss: 85.265677
epoch: 1078, train precision: 0.998800, train loss: 10.604605, valid precision: 0.879200, valid loss: 84.695166
epoch: 1079, train precision: 0.998444, train loss: 10.732466, valid precision: 0.877000, valid loss: 86.645031
epoch: 1080, train precision: 0.998956, train loss: 10.597636, valid precision: 0.878600, valid loss: 83.702403
epoch: 1081, train precision: 0.998622, train loss: 10.736881, valid precision: 0.875800, valid loss: 86.366859
epoch: 1082, train precision: 0.999067, train loss: 10.600908, valid precision: 0.882600, valid loss: 84.536123
epoch: 1083, train precision: 0.999067, train loss: 10.616779, valid precision: 0.875600, valid loss: 85.737429
epoch: 1084, train precision: 0.998489, train loss: 10.704255, valid precision: 0.877200, valid loss: 86.221805
epoch: 1085, train precision: 0.998867, train loss: 10.681632, valid precision: 0.876400, valid loss: 85.345605
epoch: 1086, train precision: 0.999244, train loss: 10.564982, valid precision: 0.873400, valid loss: 85.422259
epoch: 1087, train precision: 0.998978, train loss: 10.611960, valid precision: 0.879600, valid loss: 83.123472
epoch: 1088, train precision: 0.998422, train loss: 10.819572, valid precision: 0.878800, valid loss: 86.373751
epoch: 1089, train precision: 0.998356, train loss: 10.871643, valid precision: 0.871200, valid loss: 86.655548
epoch: 1090, train precision: 0.998978, train loss: 10.595228, valid precision: 0.877600, valid loss: 83.907264
epoch: 1091, train precision: 0.998644, train loss: 10.691952, valid precision: 0.877000, valid loss: 84.374645
epoch: 1092, train precision: 0.998911, train loss: 10.667257, valid precision: 0.877400, valid loss: 84.146204
epoch: 1093, train precision: 0.998622, train loss: 10.737216, valid precision: 0.876800, valid loss: 85.742222
epoch: 1094, train precision: 0.998489, train loss: 10.750841, valid precision: 0.876800, valid loss: 84.207493
epoch: 1095, train precision: 0.998733, train loss: 10.664167, valid precision: 0.878600, valid loss: 81.790251
epoch: 1096, train precision: 0.998733, train loss: 10.692477, valid precision: 0.878400, valid loss: 84.732687
epoch: 1097, train precision: 0.998667, train loss: 10.664697, valid precision: 0.875400, valid loss: 84.703295
epoch: 1098, train precision: 0.998378, train loss: 10.742510, valid precision: 0.877200, valid loss: 84.637449
epoch: 1099, train precision: 0.998778, train loss: 10.649240, valid precision: 0.878400, valid loss: 81.916644
epoch: 1100, train precision: 0.998933, train loss: 10.626793, valid precision: 0.878200, valid loss: 80.629418
epoch: 1101, train precision: 0.998889, train loss: 10.580508, valid precision: 0.881400, valid loss: 81.904270
epoch: 1102, train precision: 0.998889, train loss: 10.617531, valid precision: 0.877200, valid loss: 81.297458
epoch: 1103, train precision: 0.999000, train loss: 10.596982, valid precision: 0.876400, valid loss: 82.833240
epoch: 1104, train precision: 0.998889, train loss: 10.623348, valid precision: 0.876400, valid loss: 82.222594
epoch: 1105, train precision: 0.998689, train loss: 10.657906, valid precision: 0.881400, valid loss: 84.403402
epoch: 1106, train precision: 0.998356, train loss: 10.715285, valid precision: 0.881200, valid loss: 82.501019
epoch: 1107, train precision: 0.998444, train loss: 10.754830, valid precision: 0.878000, valid loss: 82.346877
epoch: 1108, train precision: 0.998956, train loss: 10.660122, valid precision: 0.880400, valid loss: 84.194855
epoch: 1109, train precision: 0.998356, train loss: 10.792319, valid precision: 0.874600, valid loss: 85.520783
epoch: 1110, train precision: 0.998600, train loss: 10.702517, valid precision: 0.877800, valid loss: 84.384715
epoch: 1111, train precision: 0.998600, train loss: 10.695394, valid precision: 0.876000, valid loss: 85.691443
epoch: 1112, train precision: 0.998733, train loss: 10.608537, valid precision: 0.876800, valid loss: 84.493107
epoch: 1113, train precision: 0.998889, train loss: 10.643630, valid precision: 0.878600, valid loss: 83.762742
epoch: 1114, train precision: 0.998889, train loss: 10.679241, valid precision: 0.877600, valid loss: 84.650534
epoch: 1115, train precision: 0.998356, train loss: 10.745768, valid precision: 0.879400, valid loss: 84.552730
epoch: 1116, train precision: 0.999044, train loss: 10.585536, valid precision: 0.881400, valid loss: 82.748656
epoch: 1117, train precision: 0.998933, train loss: 10.595762, valid precision: 0.880800, valid loss: 82.289665
epoch: 1118, train precision: 0.998800, train loss: 10.673815, valid precision: 0.878600, valid loss: 83.327281
epoch: 1119, train precision: 0.998844, train loss: 10.625223, valid precision: 0.879400, valid loss: 82.067889
epoch: 1120, train precision: 0.999089, train loss: 10.581553, valid precision: 0.877800, valid loss: 82.216768
epoch: 1121, train precision: 0.998778, train loss: 10.634255, valid precision: 0.881400, valid loss: 82.595745
epoch: 1122, train precision: 0.998822, train loss: 10.644199, valid precision: 0.880200, valid loss: 81.866429
epoch: 1123, train precision: 0.999000, train loss: 10.636689, valid precision: 0.883000, valid loss: 81.434463
epoch: 1124, train precision: 0.998756, train loss: 10.591438, valid precision: 0.879600, valid loss: 82.509102
epoch: 1125, train precision: 0.998667, train loss: 10.684678, valid precision: 0.878400, valid loss: 83.508207
epoch: 1126, train precision: 0.998889, train loss: 10.551720, valid precision: 0.883800, valid loss: 81.468254
epoch: 1127, train precision: 0.998556, train loss: 10.690060, valid precision: 0.878000, valid loss: 82.240642
epoch: 1128, train precision: 0.998622, train loss: 10.717620, valid precision: 0.876600, valid loss: 83.396193
epoch: 1129, train precision: 0.999022, train loss: 10.568806, valid precision: 0.877000, valid loss: 82.484168
epoch: 1130, train precision: 0.999022, train loss: 10.651858, valid precision: 0.878800, valid loss: 83.016195
epoch: 1131, train precision: 0.998467, train loss: 10.746973, valid precision: 0.880800, valid loss: 83.065662
epoch: 1132, train precision: 0.999000, train loss: 10.592200, valid precision: 0.877800, valid loss: 84.118797
epoch: 1133, train precision: 0.998911, train loss: 10.575826, valid precision: 0.880600, valid loss: 82.238318
epoch: 1134, train precision: 0.998667, train loss: 10.722570, valid precision: 0.879600, valid loss: 81.308438
epoch: 1135, train precision: 0.998422, train loss: 10.846341, valid precision: 0.878600, valid loss: 82.926358
epoch: 1136, train precision: 0.998889, train loss: 10.655660, valid precision: 0.879200, valid loss: 81.417388
epoch: 1137, train precision: 0.998956, train loss: 10.572227, valid precision: 0.880600, valid loss: 81.687536
epoch: 1138, train precision: 0.998222, train loss: 10.866401, valid precision: 0.876400, valid loss: 83.399003
epoch: 1139, train precision: 0.998822, train loss: 10.651629, valid precision: 0.879800, valid loss: 83.798512
epoch: 1140, train precision: 0.998867, train loss: 10.658569, valid precision: 0.878000, valid loss: 82.200387
epoch: 1141, train precision: 0.998822, train loss: 10.692914, valid precision: 0.881600, valid loss: 82.156591
epoch: 1142, train precision: 0.998933, train loss: 10.656773, valid precision: 0.881800, valid loss: 81.342582
epoch: 1143, train precision: 0.999000, train loss: 10.600573, valid precision: 0.881000, valid loss: 82.422394
epoch: 1144, train precision: 0.998778, train loss: 10.688494, valid precision: 0.882000, valid loss: 85.137116
epoch: 1145, train precision: 0.999089, train loss: 10.539195, valid precision: 0.879800, valid loss: 83.455566
epoch: 1146, train precision: 0.998911, train loss: 10.693174, valid precision: 0.879800, valid loss: 83.745323
epoch: 1147, train precision: 0.998733, train loss: 10.777865, valid precision: 0.880800, valid loss: 83.441004
epoch: 1148, train precision: 0.999244, train loss: 10.566401, valid precision: 0.886000, valid loss: 83.125671
epoch: 1149, train precision: 0.998444, train loss: 10.768926, valid precision: 0.880800, valid loss: 84.168822
epoch: 1150, train precision: 0.998422, train loss: 10.751240, valid precision: 0.875400, valid loss: 84.089633
epoch: 1151, train precision: 0.998822, train loss: 10.593670, valid precision: 0.877800, valid loss: 84.751748
epoch: 1152, train precision: 0.998822, train loss: 10.674408, valid precision: 0.878800, valid loss: 87.153276
epoch: 1153, train precision: 0.998244, train loss: 10.919874, valid precision: 0.881400, valid loss: 86.287757
epoch: 1154, train precision: 0.999133, train loss: 10.654281, valid precision: 0.883800, valid loss: 82.787444
epoch: 1155, train precision: 0.998667, train loss: 10.680573, valid precision: 0.879200, valid loss: 83.213130
epoch: 1156, train precision: 0.998600, train loss: 10.776639, valid precision: 0.878200, valid loss: 83.251938
epoch: 1157, train precision: 0.998978, train loss: 10.662161, valid precision: 0.882000, valid loss: 81.637386
epoch: 1158, train precision: 0.998978, train loss: 10.592116, valid precision: 0.878600, valid loss: 81.992785
epoch: 1159, train precision: 0.997822, train loss: 10.901029, valid precision: 0.878600, valid loss: 83.553447
epoch: 1160, train precision: 0.998556, train loss: 10.694403, valid precision: 0.878600, valid loss: 82.020600
epoch: 1161, train precision: 0.998244, train loss: 10.835188, valid precision: 0.880000, valid loss: 80.909105
epoch: 1162, train precision: 0.999044, train loss: 10.634590, valid precision: 0.881600, valid loss: 82.094627
epoch: 1163, train precision: 0.998600, train loss: 10.678235, valid precision: 0.881800, valid loss: 83.115482
epoch: 1164, train precision: 0.998689, train loss: 10.805259, valid precision: 0.878200, valid loss: 83.028533
epoch: 1165, train precision: 0.998200, train loss: 10.804049, valid precision: 0.880200, valid loss: 84.001028
epoch: 1166, train precision: 0.998356, train loss: 10.895074, valid precision: 0.879600, valid loss: 84.809986
epoch: 1167, train precision: 0.998556, train loss: 10.679869, valid precision: 0.881800, valid loss: 84.516412
epoch: 1168, train precision: 0.998800, train loss: 10.721147, valid precision: 0.885000, valid loss: 82.236628
epoch: 1169, train precision: 0.998733, train loss: 10.691711, valid precision: 0.881400, valid loss: 84.402395
epoch: 1170, train precision: 0.998733, train loss: 10.706093, valid precision: 0.876600, valid loss: 83.658226
epoch: 1171, train precision: 0.998844, train loss: 10.635664, valid precision: 0.878800, valid loss: 82.538727
epoch: 1172, train precision: 0.999022, train loss: 10.639828, valid precision: 0.880000, valid loss: 83.580979
epoch: 1173, train precision: 0.998378, train loss: 10.823944, valid precision: 0.878400, valid loss: 85.389105
epoch: 1174, train precision: 0.998644, train loss: 10.661425, valid precision: 0.876800, valid loss: 84.479832
epoch: 1175, train precision: 0.998689, train loss: 10.767016, valid precision: 0.877600, valid loss: 83.203485
epoch: 1176, train precision: 0.999044, train loss: 10.619141, valid precision: 0.877400, valid loss: 83.381403
epoch: 1177, train precision: 0.998933, train loss: 10.616365, valid precision: 0.878800, valid loss: 83.582086
epoch: 1178, train precision: 0.998644, train loss: 10.669930, valid precision: 0.875800, valid loss: 83.969000
epoch: 1179, train precision: 0.998489, train loss: 10.673469, valid precision: 0.875400, valid loss: 85.932275
epoch: 1180, train precision: 0.998600, train loss: 10.712052, valid precision: 0.876400, valid loss: 85.508442
epoch: 1181, train precision: 0.998444, train loss: 10.760982, valid precision: 0.875800, valid loss: 87.403156
epoch: 1182, train precision: 0.998711, train loss: 10.738435, valid precision: 0.873000, valid loss: 85.084704
epoch: 1183, train precision: 0.999067, train loss: 10.588743, valid precision: 0.881800, valid loss: 85.598862
epoch: 1184, train precision: 0.999022, train loss: 10.585048, valid precision: 0.878600, valid loss: 85.947893
epoch: 1185, train precision: 0.998533, train loss: 10.710225, valid precision: 0.878200, valid loss: 84.095424
epoch: 1186, train precision: 0.999200, train loss: 10.534357, valid precision: 0.876600, valid loss: 87.713429
epoch: 1187, train precision: 0.999000, train loss: 10.589061, valid precision: 0.878000, valid loss: 83.265441
epoch: 1188, train precision: 0.998533, train loss: 10.804145, valid precision: 0.878200, valid loss: 86.440408
epoch: 1189, train precision: 0.999156, train loss: 10.533799, valid precision: 0.880600, valid loss: 81.979221
epoch: 1190, train precision: 0.998778, train loss: 10.704808, valid precision: 0.881200, valid loss: 84.294190
epoch: 1191, train precision: 0.999178, train loss: 10.550192, valid precision: 0.880600, valid loss: 81.815323
epoch: 1192, train precision: 0.998889, train loss: 10.581348, valid precision: 0.879000, valid loss: 82.950189
epoch: 1193, train precision: 0.998756, train loss: 10.613107, valid precision: 0.877400, valid loss: 85.797828
epoch: 1194, train precision: 0.999156, train loss: 10.569086, valid precision: 0.878600, valid loss: 82.127762
epoch: 1195, train precision: 0.998667, train loss: 10.666706, valid precision: 0.875800, valid loss: 86.357587
epoch: 1196, train precision: 0.999000, train loss: 10.636982, valid precision: 0.879400, valid loss: 82.533800
epoch: 1197, train precision: 0.998422, train loss: 10.686010, valid precision: 0.878200, valid loss: 83.354443
epoch: 1198, train precision: 0.999133, train loss: 10.604111, valid precision: 0.880600, valid loss: 84.025758
epoch: 1199, train precision: 0.999000, train loss: 10.613319, valid precision: 0.879600, valid loss: 83.482637
epoch: 1200, train precision: 0.998667, train loss: 10.699816, valid precision: 0.879600, valid loss: 83.287819
epoch: 1201, train precision: 0.998822, train loss: 10.654682, valid precision: 0.877600, valid loss: 85.178396
epoch: 1202, train precision: 0.998911, train loss: 10.644026, valid precision: 0.880600, valid loss: 82.589782
epoch: 1203, train precision: 0.998422, train loss: 10.812166, valid precision: 0.878800, valid loss: 85.841693
epoch: 1204, train precision: 0.998867, train loss: 10.651297, valid precision: 0.881200, valid loss: 83.922128
epoch: 1205, train precision: 0.998711, train loss: 10.712117, valid precision: 0.878200, valid loss: 84.687388
epoch: 1206, train precision: 0.999111, train loss: 10.552106, valid precision: 0.880000, valid loss: 85.823415
epoch: 1207, train precision: 0.998533, train loss: 10.747399, valid precision: 0.878400, valid loss: 87.119828
epoch: 1208, train precision: 0.998711, train loss: 10.703800, valid precision: 0.873000, valid loss: 88.038430
epoch: 1209, train precision: 0.998756, train loss: 10.688514, valid precision: 0.877400, valid loss: 85.874079
epoch: 1210, train precision: 0.998844, train loss: 10.675791, valid precision: 0.879600, valid loss: 84.962492
epoch: 1211, train precision: 0.998622, train loss: 10.742547, valid precision: 0.875000, valid loss: 87.394273
epoch: 1212, train precision: 0.998844, train loss: 10.658680, valid precision: 0.878400, valid loss: 85.143701
epoch: 1213, train precision: 0.999244, train loss: 10.532481, valid precision: 0.882800, valid loss: 84.442099
epoch: 1214, train precision: 0.998733, train loss: 10.702380, valid precision: 0.880400, valid loss: 83.872517
epoch: 1215, train precision: 0.999067, train loss: 10.617971, valid precision: 0.880800, valid loss: 87.458011
epoch: 1216, train precision: 0.998933, train loss: 10.605866, valid precision: 0.878800, valid loss: 86.531066
epoch: 1217, train precision: 0.998867, train loss: 10.679973, valid precision: 0.879200, valid loss: 85.498975
epoch: 1218, train precision: 0.998578, train loss: 10.762325, valid precision: 0.881800, valid loss: 85.497114
epoch: 1219, train precision: 0.998644, train loss: 10.699209, valid precision: 0.881400, valid loss: 83.999794
epoch: 1220, train precision: 0.998911, train loss: 10.650170, valid precision: 0.881400, valid loss: 84.124133
epoch: 1221, train precision: 0.998911, train loss: 10.633616, valid precision: 0.877600, valid loss: 84.654337
epoch: 1222, train precision: 0.998511, train loss: 10.774509, valid precision: 0.883000, valid loss: 81.773352
epoch: 1223, train precision: 0.999022, train loss: 10.668957, valid precision: 0.874400, valid loss: 84.378077
epoch: 1224, train precision: 0.998867, train loss: 10.703908, valid precision: 0.879000, valid loss: 84.099475
epoch: 1225, train precision: 0.998889, train loss: 10.692415, valid precision: 0.881200, valid loss: 84.596405
epoch: 1226, train precision: 0.998933, train loss: 10.655786, valid precision: 0.879400, valid loss: 82.792854
epoch: 1227, train precision: 0.998911, train loss: 10.650067, valid precision: 0.879400, valid loss: 82.541277
epoch: 1228, train precision: 0.998444, train loss: 10.840659, valid precision: 0.880200, valid loss: 84.199004
epoch: 1229, train precision: 0.998978, train loss: 10.570372, valid precision: 0.884600, valid loss: 85.431002
epoch: 1230, train precision: 0.998333, train loss: 10.839332, valid precision: 0.877600, valid loss: 85.524100
epoch: 1231, train precision: 0.998978, train loss: 10.576448, valid precision: 0.880400, valid loss: 84.676106
epoch: 1232, train precision: 0.999000, train loss: 10.596810, valid precision: 0.882400, valid loss: 82.602858
epoch: 1233, train precision: 0.998756, train loss: 10.725536, valid precision: 0.880200, valid loss: 85.329573
epoch: 1234, train precision: 0.998667, train loss: 10.689600, valid precision: 0.879600, valid loss: 84.367715
epoch: 1235, train precision: 0.999044, train loss: 10.625668, valid precision: 0.877000, valid loss: 84.143682
epoch: 1236, train precision: 0.998867, train loss: 10.684149, valid precision: 0.874000, valid loss: 85.587432
epoch: 1237, train precision: 0.998289, train loss: 10.821926, valid precision: 0.877200, valid loss: 84.838374
epoch: 1238, train precision: 0.998844, train loss: 10.686334, valid precision: 0.880600, valid loss: 83.822733
epoch: 1239, train precision: 0.998800, train loss: 10.692544, valid precision: 0.878200, valid loss: 84.448010
epoch: 1240, train precision: 0.998400, train loss: 10.782948, valid precision: 0.878600, valid loss: 84.281829
epoch: 1241, train precision: 0.998467, train loss: 10.736901, valid precision: 0.879200, valid loss: 83.324202
epoch: 1242, train precision: 0.998689, train loss: 10.695867, valid precision: 0.878200, valid loss: 84.253421
epoch: 1243, train precision: 0.998622, train loss: 10.710589, valid precision: 0.879200, valid loss: 84.719781
epoch: 1244, train precision: 0.998756, train loss: 10.704615, valid precision: 0.877600, valid loss: 85.672500
epoch: 1245, train precision: 0.998844, train loss: 10.654191, valid precision: 0.880600, valid loss: 83.994092
epoch: 1246, train precision: 0.998511, train loss: 10.741446, valid precision: 0.875800, valid loss: 85.771143
epoch: 1247, train precision: 0.998511, train loss: 10.691647, valid precision: 0.879400, valid loss: 84.888720
epoch: 1248, train precision: 0.998822, train loss: 10.631616, valid precision: 0.877200, valid loss: 84.805436
epoch: 1249, train precision: 0.998733, train loss: 10.713323, valid precision: 0.878000, valid loss: 87.279173
epoch: 1250, train precision: 0.998244, train loss: 10.857165, valid precision: 0.874000, valid loss: 85.127163
epoch: 1251, train precision: 0.999089, train loss: 10.626590, valid precision: 0.880400, valid loss: 84.096957
epoch: 1252, train precision: 0.998889, train loss: 10.595436, valid precision: 0.878400, valid loss: 85.780872
epoch: 1253, train precision: 0.999022, train loss: 10.575556, valid precision: 0.876400, valid loss: 86.612454
epoch: 1254, train precision: 0.998644, train loss: 10.710039, valid precision: 0.877000, valid loss: 87.927688
epoch: 1255, train precision: 0.998933, train loss: 10.632489, valid precision: 0.880200, valid loss: 83.873847
epoch: 1256, train precision: 0.998644, train loss: 10.678394, valid precision: 0.872600, valid loss: 85.896298
epoch: 1257, train precision: 0.998689, train loss: 10.652868, valid precision: 0.882600, valid loss: 85.860538
epoch: 1258, train precision: 0.998689, train loss: 10.665125, valid precision: 0.875600, valid loss: 85.335248
epoch: 1259, train precision: 0.998511, train loss: 10.751819, valid precision: 0.879800, valid loss: 83.750828
epoch: 1260, train precision: 0.998622, train loss: 10.676568, valid precision: 0.875200, valid loss: 85.576267
epoch: 1261, train precision: 0.998600, train loss: 10.715300, valid precision: 0.878000, valid loss: 84.098297
epoch: 1262, train precision: 0.998800, train loss: 10.702065, valid precision: 0.874400, valid loss: 85.776670
epoch: 1263, train precision: 0.998667, train loss: 10.667361, valid precision: 0.874800, valid loss: 86.856334
epoch: 1264, train precision: 0.998889, train loss: 10.694249, valid precision: 0.876000, valid loss: 86.278847
epoch: 1265, train precision: 0.998933, train loss: 10.612865, valid precision: 0.876200, valid loss: 84.110336
epoch: 1266, train precision: 0.998889, train loss: 10.598184, valid precision: 0.878000, valid loss: 85.921731
epoch: 1267, train precision: 0.998956, train loss: 10.650282, valid precision: 0.876800, valid loss: 84.183692
epoch: 1268, train precision: 0.998733, train loss: 10.693962, valid precision: 0.878800, valid loss: 86.877168
epoch: 1269, train precision: 0.998689, train loss: 10.658524, valid precision: 0.877600, valid loss: 84.889835
epoch: 1270, train precision: 0.998889, train loss: 10.593337, valid precision: 0.876400, valid loss: 84.557198
epoch: 1271, train precision: 0.998889, train loss: 10.649025, valid precision: 0.875400, valid loss: 86.049552
epoch: 1272, train precision: 0.998844, train loss: 10.632879, valid precision: 0.875200, valid loss: 86.791911
epoch: 1273, train precision: 0.998600, train loss: 10.731375, valid precision: 0.875800, valid loss: 86.996122
epoch: 1274, train precision: 0.998978, train loss: 10.598939, valid precision: 0.875200, valid loss: 87.548327
epoch: 1275, train precision: 0.998511, train loss: 10.746332, valid precision: 0.873800, valid loss: 87.054316
epoch: 1276, train precision: 0.998622, train loss: 10.683613, valid precision: 0.880200, valid loss: 84.882564
epoch: 1277, train precision: 0.998622, train loss: 10.623631, valid precision: 0.877400, valid loss: 85.688941
epoch: 1278, train precision: 0.999000, train loss: 10.605016, valid precision: 0.878200, valid loss: 87.117342
epoch: 1279, train precision: 0.998778, train loss: 10.633715, valid precision: 0.878400, valid loss: 84.895772
epoch: 1280, train precision: 0.998889, train loss: 10.596762, valid precision: 0.876200, valid loss: 87.046592
epoch: 1281, train precision: 0.998600, train loss: 10.717048, valid precision: 0.877800, valid loss: 87.405825
epoch: 1282, train precision: 0.998933, train loss: 10.611819, valid precision: 0.877600, valid loss: 85.088776
epoch: 1283, train precision: 0.999022, train loss: 10.634794, valid precision: 0.879600, valid loss: 84.863611
epoch: 1284, train precision: 0.998667, train loss: 10.660872, valid precision: 0.877800, valid loss: 85.476209
epoch: 1285, train precision: 0.999089, train loss: 10.582893, valid precision: 0.879200, valid loss: 84.551034
epoch: 1286, train precision: 0.998644, train loss: 10.752238, valid precision: 0.876600, valid loss: 86.245241
epoch: 1287, train precision: 0.998600, train loss: 10.737014, valid precision: 0.877600, valid loss: 86.919958
epoch: 1288, train precision: 0.998956, train loss: 10.592734, valid precision: 0.876600, valid loss: 86.502214
epoch: 1289, train precision: 0.998756, train loss: 10.612546, valid precision: 0.878400, valid loss: 86.350270
epoch: 1290, train precision: 0.998622, train loss: 10.640780, valid precision: 0.875600, valid loss: 86.901411
epoch: 1291, train precision: 0.999133, train loss: 10.596220, valid precision: 0.879200, valid loss: 85.667708
epoch: 1292, train precision: 0.998733, train loss: 10.723807, valid precision: 0.879400, valid loss: 86.257785
epoch: 1293, train precision: 0.998533, train loss: 10.738955, valid precision: 0.880800, valid loss: 83.647135
epoch: 1294, train precision: 0.998800, train loss: 10.656890, valid precision: 0.877800, valid loss: 82.328543
epoch: 1295, train precision: 0.998622, train loss: 10.715119, valid precision: 0.876800, valid loss: 85.020510
epoch: 1296, train precision: 0.998467, train loss: 10.707168, valid precision: 0.875000, valid loss: 85.199242
epoch: 1297, train precision: 0.999089, train loss: 10.596395, valid precision: 0.877800, valid loss: 84.125392
epoch: 1298, train precision: 0.998689, train loss: 10.699545, valid precision: 0.877000, valid loss: 85.638687
epoch: 1299, train precision: 0.998600, train loss: 10.714455, valid precision: 0.878600, valid loss: 86.610822
epoch: 1300, train precision: 0.998378, train loss: 10.788860, valid precision: 0.872400, valid loss: 87.837538
epoch: 1301, train precision: 0.998733, train loss: 10.647741, valid precision: 0.879800, valid loss: 83.307230
epoch: 1302, train precision: 0.999022, train loss: 10.576935, valid precision: 0.879000, valid loss: 82.064054
epoch: 1303, train precision: 0.998378, train loss: 10.807251, valid precision: 0.879800, valid loss: 84.822466
epoch: 1304, train precision: 0.999022, train loss: 10.603507, valid precision: 0.877800, valid loss: 86.935671
epoch: 1305, train precision: 0.998822, train loss: 10.720452, valid precision: 0.878200, valid loss: 85.330316
epoch: 1306, train precision: 0.998911, train loss: 10.607026, valid precision: 0.878800, valid loss: 85.111027
epoch: 1307, train precision: 0.998689, train loss: 10.709546, valid precision: 0.876800, valid loss: 85.867669
epoch: 1308, train precision: 0.998911, train loss: 10.611702, valid precision: 0.883000, valid loss: 84.375735
epoch: 1309, train precision: 0.999089, train loss: 10.603874, valid precision: 0.879800, valid loss: 83.351344
epoch: 1310, train precision: 0.998533, train loss: 10.799572, valid precision: 0.876400, valid loss: 84.084422
epoch: 1311, train precision: 0.998956, train loss: 10.675380, valid precision: 0.878800, valid loss: 84.493226
epoch: 1312, train precision: 0.998556, train loss: 10.691031, valid precision: 0.878800, valid loss: 85.853604
epoch: 1313, train precision: 0.998844, train loss: 10.622010, valid precision: 0.882200, valid loss: 83.798985
epoch: 1314, train precision: 0.999044, train loss: 10.602438, valid precision: 0.879000, valid loss: 83.393838
epoch: 1315, train precision: 0.998644, train loss: 10.746306, valid precision: 0.877400, valid loss: 84.563820
epoch: 1316, train precision: 0.999067, train loss: 10.576476, valid precision: 0.880800, valid loss: 83.013199
epoch: 1317, train precision: 0.998489, train loss: 10.789679, valid precision: 0.876600, valid loss: 86.524322
epoch: 1318, train precision: 0.998511, train loss: 10.732199, valid precision: 0.877200, valid loss: 83.439502
epoch: 1319, train precision: 0.999067, train loss: 10.599978, valid precision: 0.880600, valid loss: 82.599984
epoch: 1320, train precision: 0.998711, train loss: 10.708315, valid precision: 0.878600, valid loss: 85.754822
epoch: 1321, train precision: 0.998667, train loss: 10.756798, valid precision: 0.874200, valid loss: 87.028308
epoch: 1322, train precision: 0.999133, train loss: 10.580721, valid precision: 0.880000, valid loss: 83.604029
epoch: 1323, train precision: 0.998600, train loss: 10.708016, valid precision: 0.880200, valid loss: 85.446613
epoch: 1324, train precision: 0.998444, train loss: 10.769678, valid precision: 0.877400, valid loss: 86.250384
epoch: 1325, train precision: 0.998978, train loss: 10.615244, valid precision: 0.875400, valid loss: 87.023249
epoch: 1326, train precision: 0.998933, train loss: 10.667300, valid precision: 0.879200, valid loss: 83.200595
epoch: 1327, train precision: 0.998711, train loss: 10.668162, valid precision: 0.876200, valid loss: 86.589335
epoch: 1328, train precision: 0.999022, train loss: 10.644107, valid precision: 0.877000, valid loss: 84.952770
epoch: 1329, train precision: 0.998867, train loss: 10.692879, valid precision: 0.877200, valid loss: 84.562222
epoch: 1330, train precision: 0.999000, train loss: 10.667071, valid precision: 0.873200, valid loss: 88.177673
epoch: 1331, train precision: 0.999133, train loss: 10.527208, valid precision: 0.878600, valid loss: 84.607181
epoch: 1332, train precision: 0.998689, train loss: 10.685307, valid precision: 0.874400, valid loss: 85.838986
epoch: 1333, train precision: 0.998911, train loss: 10.640123, valid precision: 0.877800, valid loss: 85.780644
epoch: 1334, train precision: 0.999044, train loss: 10.612236, valid precision: 0.880000, valid loss: 83.807568
epoch: 1335, train precision: 0.998889, train loss: 10.558158, valid precision: 0.876400, valid loss: 87.010952
epoch: 1336, train precision: 0.999022, train loss: 10.597064, valid precision: 0.877200, valid loss: 86.631368
epoch: 1337, train precision: 0.998489, train loss: 10.738022, valid precision: 0.877200, valid loss: 86.093752
epoch: 1338, train precision: 0.998889, train loss: 10.630787, valid precision: 0.876600, valid loss: 85.953463
epoch: 1339, train precision: 0.998822, train loss: 10.745797, valid precision: 0.879200, valid loss: 83.982604
epoch: 1340, train precision: 0.998800, train loss: 10.678348, valid precision: 0.880400, valid loss: 87.338955
epoch: 1341, train precision: 0.998956, train loss: 10.648577, valid precision: 0.879200, valid loss: 84.211290
epoch: 1342, train precision: 0.998933, train loss: 10.595333, valid precision: 0.876400, valid loss: 86.143210
epoch: 1343, train precision: 0.999089, train loss: 10.610828, valid precision: 0.874000, valid loss: 85.359535
epoch: 1344, train precision: 0.998933, train loss: 10.600008, valid precision: 0.880000, valid loss: 82.919759
epoch: 1345, train precision: 0.998822, train loss: 10.602848, valid precision: 0.878800, valid loss: 84.232593
epoch: 1346, train precision: 0.998733, train loss: 10.654139, valid precision: 0.879000, valid loss: 83.618530
epoch: 1347, train precision: 0.998978, train loss: 10.656290, valid precision: 0.877600, valid loss: 85.874700
epoch: 1348, train precision: 0.998400, train loss: 10.795664, valid precision: 0.880400, valid loss: 82.754867
epoch: 1349, train precision: 0.998622, train loss: 10.696405, valid precision: 0.876400, valid loss: 83.688145
epoch: 1350, train precision: 0.998867, train loss: 10.648745, valid precision: 0.882000, valid loss: 85.940499
epoch: 1351, train precision: 0.998778, train loss: 10.654851, valid precision: 0.880000, valid loss: 84.735379
epoch: 1352, train precision: 0.998200, train loss: 10.817669, valid precision: 0.876200, valid loss: 85.167383
epoch: 1353, train precision: 0.999022, train loss: 10.670327, valid precision: 0.877600, valid loss: 87.816565
epoch: 1354, train precision: 0.998956, train loss: 10.678081, valid precision: 0.877600, valid loss: 86.211926
epoch: 1355, train precision: 0.998800, train loss: 10.663833, valid precision: 0.875200, valid loss: 87.521438
epoch: 1356, train precision: 0.998600, train loss: 10.704825, valid precision: 0.874200, valid loss: 83.962148
epoch: 1357, train precision: 0.998267, train loss: 10.787160, valid precision: 0.876600, valid loss: 88.176195
epoch: 1358, train precision: 0.998444, train loss: 10.818613, valid precision: 0.879200, valid loss: 85.154789
epoch: 1359, train precision: 0.998889, train loss: 10.680898, valid precision: 0.875200, valid loss: 85.296406
epoch: 1360, train precision: 0.998911, train loss: 10.635525, valid precision: 0.879600, valid loss: 86.649472
epoch: 1361, train precision: 0.999067, train loss: 10.662878, valid precision: 0.872600, valid loss: 86.556417
epoch: 1362, train precision: 0.998844, train loss: 10.660028, valid precision: 0.877800, valid loss: 84.058304
epoch: 1363, train precision: 0.998444, train loss: 10.725521, valid precision: 0.878800, valid loss: 83.551127
epoch: 1364, train precision: 0.999111, train loss: 10.600340, valid precision: 0.878800, valid loss: 82.864744
epoch: 1365, train precision: 0.999089, train loss: 10.560888, valid precision: 0.879600, valid loss: 82.458354
epoch: 1366, train precision: 0.998956, train loss: 10.596651, valid precision: 0.876200, valid loss: 85.170343
epoch: 1367, train precision: 0.998911, train loss: 10.654323, valid precision: 0.877200, valid loss: 83.027504
epoch: 1368, train precision: 0.998733, train loss: 10.651372, valid precision: 0.880600, valid loss: 83.303877
epoch: 1369, train precision: 0.999044, train loss: 10.547249, valid precision: 0.882600, valid loss: 83.288025
epoch: 1370, train precision: 0.998800, train loss: 10.612408, valid precision: 0.879400, valid loss: 86.869464
epoch: 1371, train precision: 0.998689, train loss: 10.754384, valid precision: 0.874600, valid loss: 85.984149
epoch: 1372, train precision: 0.998578, train loss: 10.749644, valid precision: 0.875800, valid loss: 85.320573
epoch: 1373, train precision: 0.998667, train loss: 10.655278, valid precision: 0.877600, valid loss: 83.955120
epoch: 1374, train precision: 0.998933, train loss: 10.666632, valid precision: 0.878200, valid loss: 84.773045
epoch: 1375, train precision: 0.998511, train loss: 10.759690, valid precision: 0.879200, valid loss: 85.819308
epoch: 1376, train precision: 0.999133, train loss: 10.588231, valid precision: 0.881200, valid loss: 82.765720
epoch: 1377, train precision: 0.998844, train loss: 10.601452, valid precision: 0.879400, valid loss: 84.358469
epoch: 1378, train precision: 0.999067, train loss: 10.662486, valid precision: 0.880600, valid loss: 83.179971
epoch: 1379, train precision: 0.999022, train loss: 10.543799, valid precision: 0.881600, valid loss: 84.306797
epoch: 1380, train precision: 0.998689, train loss: 10.736957, valid precision: 0.880200, valid loss: 85.626421
epoch: 1381, train precision: 0.998711, train loss: 10.641138, valid precision: 0.878000, valid loss: 84.540414
epoch: 1382, train precision: 0.999044, train loss: 10.564322, valid precision: 0.878200, valid loss: 85.748237
epoch: 1383, train precision: 0.998867, train loss: 10.651929, valid precision: 0.880000, valid loss: 84.392890
epoch: 1384, train precision: 0.998978, train loss: 10.567110, valid precision: 0.875200, valid loss: 86.127541
epoch: 1385, train precision: 0.998911, train loss: 10.603600, valid precision: 0.877600, valid loss: 85.857798
epoch: 1386, train precision: 0.998133, train loss: 10.865934, valid precision: 0.877000, valid loss: 86.711096
epoch: 1387, train precision: 0.998711, train loss: 10.691742, valid precision: 0.878800, valid loss: 84.829483
epoch: 1388, train precision: 0.999111, train loss: 10.571018, valid precision: 0.879000, valid loss: 84.935764
epoch: 1389, train precision: 0.999067, train loss: 10.565442, valid precision: 0.881400, valid loss: 83.865834
epoch: 1390, train precision: 0.999111, train loss: 10.586154, valid precision: 0.879600, valid loss: 86.480986
epoch: 1391, train precision: 0.998667, train loss: 10.684487, valid precision: 0.880800, valid loss: 85.811914
epoch: 1392, train precision: 0.998800, train loss: 10.722232, valid precision: 0.877600, valid loss: 86.696991
epoch: 1393, train precision: 0.998911, train loss: 10.623907, valid precision: 0.879200, valid loss: 85.720257
epoch: 1394, train precision: 0.999244, train loss: 10.539508, valid precision: 0.880400, valid loss: 85.562705
epoch: 1395, train precision: 0.998689, train loss: 10.684133, valid precision: 0.882000, valid loss: 89.192651
epoch: 1396, train precision: 0.998956, train loss: 10.597570, valid precision: 0.879200, valid loss: 88.672638
epoch: 1397, train precision: 0.998578, train loss: 10.683740, valid precision: 0.880400, valid loss: 87.951763
epoch: 1398, train precision: 0.998867, train loss: 10.665232, valid precision: 0.878400, valid loss: 88.388821
epoch: 1399, train precision: 0.998822, train loss: 10.587483, valid precision: 0.879800, valid loss: 86.182243
epoch: 1400, train precision: 0.998956, train loss: 10.590340, valid precision: 0.877400, valid loss: 88.914509
epoch: 1401, train precision: 0.998511, train loss: 10.727396, valid precision: 0.880600, valid loss: 87.658177
epoch: 1402, train precision: 0.998911, train loss: 10.672577, valid precision: 0.878200, valid loss: 86.768985
epoch: 1403, train precision: 0.999022, train loss: 10.577667, valid precision: 0.880800, valid loss: 85.106179
epoch: 1404, train precision: 0.998911, train loss: 10.593334, valid precision: 0.879600, valid loss: 85.451166
epoch: 1405, train precision: 0.998933, train loss: 10.622273, valid precision: 0.876200, valid loss: 87.684582
epoch: 1406, train precision: 0.998756, train loss: 10.653312, valid precision: 0.877800, valid loss: 85.371374
epoch: 1407, train precision: 0.998578, train loss: 10.745805, valid precision: 0.877400, valid loss: 87.784893
epoch: 1408, train precision: 0.998956, train loss: 10.698384, valid precision: 0.882400, valid loss: 85.340371
epoch: 1409, train precision: 0.998511, train loss: 10.706178, valid precision: 0.881200, valid loss: 83.752166
epoch: 1410, train precision: 0.998400, train loss: 10.814900, valid precision: 0.881200, valid loss: 85.482300
epoch: 1411, train precision: 0.998844, train loss: 10.667321, valid precision: 0.875800, valid loss: 85.567218
epoch: 1412, train precision: 0.999022, train loss: 10.673260, valid precision: 0.876400, valid loss: 87.104693
epoch: 1413, train precision: 0.999044, train loss: 10.601719, valid precision: 0.878800, valid loss: 84.517332
epoch: 1414, train precision: 0.998644, train loss: 10.716383, valid precision: 0.881000, valid loss: 85.911746
epoch: 1415, train precision: 0.998644, train loss: 10.688146, valid precision: 0.879400, valid loss: 86.687156
epoch: 1416, train precision: 0.998978, train loss: 10.603037, valid precision: 0.875600, valid loss: 86.723973
epoch: 1417, train precision: 0.999089, train loss: 10.563181, valid precision: 0.879000, valid loss: 83.652022
epoch: 1418, train precision: 0.999156, train loss: 10.503318, valid precision: 0.876800, valid loss: 86.435801
epoch: 1419, train precision: 0.999133, train loss: 10.598686, valid precision: 0.879400, valid loss: 85.999756
epoch: 1420, train precision: 0.999111, train loss: 10.558741, valid precision: 0.884200, valid loss: 85.701354
epoch: 1421, train precision: 0.999067, train loss: 10.591500, valid precision: 0.879000, valid loss: 83.866597
epoch: 1422, train precision: 0.998644, train loss: 10.652355, valid precision: 0.881000, valid loss: 87.979907
epoch: 1423, train precision: 0.999111, train loss: 10.580058, valid precision: 0.877000, valid loss: 87.659114
epoch: 1424, train precision: 0.999044, train loss: 10.548047, valid precision: 0.879200, valid loss: 87.595425
epoch: 1425, train precision: 0.999111, train loss: 10.603032, valid precision: 0.881200, valid loss: 85.541120
epoch: 1426, train precision: 0.998644, train loss: 10.651357, valid precision: 0.881400, valid loss: 85.556427
epoch: 1427, train precision: 0.999133, train loss: 10.534216, valid precision: 0.881800, valid loss: 86.369926
epoch: 1428, train precision: 0.999311, train loss: 10.542392, valid precision: 0.882600, valid loss: 83.789929
epoch: 1429, train precision: 0.998822, train loss: 10.597033, valid precision: 0.878800, valid loss: 84.065484
epoch: 1430, train precision: 0.999200, train loss: 10.545081, valid precision: 0.877000, valid loss: 86.245404
epoch: 1431, train precision: 0.998933, train loss: 10.601237, valid precision: 0.878000, valid loss: 87.138829
epoch: 1432, train precision: 0.999067, train loss: 10.598451, valid precision: 0.876200, valid loss: 87.136037
epoch: 1433, train precision: 0.999200, train loss: 10.572634, valid precision: 0.879000, valid loss: 86.196677
epoch: 1434, train precision: 0.999044, train loss: 10.581312, valid precision: 0.879600, valid loss: 85.832879
epoch: 1435, train precision: 0.998756, train loss: 10.607314, valid precision: 0.880200, valid loss: 86.566122
epoch: 1436, train precision: 0.998844, train loss: 10.643197, valid precision: 0.881000, valid loss: 86.862396
epoch: 1437, train precision: 0.999311, train loss: 10.506305, valid precision: 0.880200, valid loss: 87.051602
epoch: 1438, train precision: 0.998844, train loss: 10.618101, valid precision: 0.880000, valid loss: 87.002621
epoch: 1439, train precision: 0.998711, train loss: 10.647697, valid precision: 0.880600, valid loss: 85.158071
epoch: 1440, train precision: 0.998889, train loss: 10.642297, valid precision: 0.881600, valid loss: 84.311370
epoch: 1441, train precision: 0.998800, train loss: 10.650714, valid precision: 0.880600, valid loss: 83.434485
epoch: 1442, train precision: 0.999089, train loss: 10.549584, valid precision: 0.880600, valid loss: 85.844073
epoch: 1443, train precision: 0.998756, train loss: 10.682321, valid precision: 0.875800, valid loss: 85.557336
epoch: 1444, train precision: 0.998956, train loss: 10.651015, valid precision: 0.877000, valid loss: 86.811144
epoch: 1445, train precision: 0.998778, train loss: 10.622190, valid precision: 0.882000, valid loss: 84.120697
epoch: 1446, train precision: 0.998844, train loss: 10.618717, valid precision: 0.883600, valid loss: 83.241039
epoch: 1447, train precision: 0.998822, train loss: 10.622331, valid precision: 0.878600, valid loss: 84.854228
epoch: 1448, train precision: 0.999044, train loss: 10.580699, valid precision: 0.878400, valid loss: 85.878001
epoch: 1449, train precision: 0.999044, train loss: 10.587270, valid precision: 0.883000, valid loss: 85.144201
epoch: 1450, train precision: 0.999244, train loss: 10.471674, valid precision: 0.877000, valid loss: 86.727550
epoch: 1451, train precision: 0.998556, train loss: 10.688120, valid precision: 0.875600, valid loss: 87.251353
epoch: 1452, train precision: 0.999156, train loss: 10.592215, valid precision: 0.877800, valid loss: 86.058390
epoch: 1453, train precision: 0.998778, train loss: 10.654114, valid precision: 0.880400, valid loss: 88.560306
epoch: 1454, train precision: 0.998933, train loss: 10.565502, valid precision: 0.881000, valid loss: 85.890263
epoch: 1455, train precision: 0.998956, train loss: 10.581541, valid precision: 0.876400, valid loss: 87.053015
epoch: 1456, train precision: 0.998733, train loss: 10.624356, valid precision: 0.871800, valid loss: 88.714127
epoch: 1457, train precision: 0.999133, train loss: 10.581093, valid precision: 0.877800, valid loss: 86.219745
epoch: 1458, train precision: 0.998889, train loss: 10.644482, valid precision: 0.877000, valid loss: 88.710438
epoch: 1459, train precision: 0.998733, train loss: 10.645481, valid precision: 0.873800, valid loss: 88.302087
epoch: 1460, train precision: 0.998578, train loss: 10.635994, valid precision: 0.878200, valid loss: 90.158977
epoch: 1461, train precision: 0.998533, train loss: 10.719425, valid precision: 0.875800, valid loss: 86.477892
epoch: 1462, train precision: 0.998733, train loss: 10.590290, valid precision: 0.875000, valid loss: 87.457923
epoch: 1463, train precision: 0.998733, train loss: 10.690979, valid precision: 0.880200, valid loss: 87.814140
epoch: 1464, train precision: 0.998800, train loss: 10.662164, valid precision: 0.878400, valid loss: 86.745343
epoch: 1465, train precision: 0.998733, train loss: 10.685183, valid precision: 0.877200, valid loss: 85.812152
epoch: 1466, train precision: 0.998889, train loss: 10.615492, valid precision: 0.877200, valid loss: 86.066191
epoch: 1467, train precision: 0.998667, train loss: 10.668513, valid precision: 0.876200, valid loss: 88.040292
epoch: 1468, train precision: 0.998667, train loss: 10.669006, valid precision: 0.878000, valid loss: 86.872882
epoch: 1469, train precision: 0.998933, train loss: 10.609867, valid precision: 0.881000, valid loss: 86.631633
epoch: 1470, train precision: 0.999222, train loss: 10.528676, valid precision: 0.881200, valid loss: 85.569764
epoch: 1471, train precision: 0.999289, train loss: 10.518024, valid precision: 0.879800, valid loss: 86.250741
epoch: 1472, train precision: 0.998667, train loss: 10.701569, valid precision: 0.877000, valid loss: 86.855942
epoch: 1473, train precision: 0.998978, train loss: 10.654794, valid precision: 0.869600, valid loss: 87.612720
epoch: 1474, train precision: 0.998911, train loss: 10.616056, valid precision: 0.875000, valid loss: 88.538537
epoch: 1475, train precision: 0.998800, train loss: 10.660237, valid precision: 0.875000, valid loss: 88.157013
epoch: 1476, train precision: 0.998822, train loss: 10.743578, valid precision: 0.872800, valid loss: 89.264343
epoch: 1477, train precision: 0.998844, train loss: 10.588770, valid precision: 0.875400, valid loss: 87.371939
epoch: 1478, train precision: 0.998778, train loss: 10.704142, valid precision: 0.880000, valid loss: 84.675047
epoch: 1479, train precision: 0.999156, train loss: 10.556069, valid precision: 0.880400, valid loss: 85.445777
epoch: 1480, train precision: 0.999022, train loss: 10.574815, valid precision: 0.874000, valid loss: 87.401243
epoch: 1481, train precision: 0.998889, train loss: 10.545650, valid precision: 0.881400, valid loss: 85.790383
epoch: 1482, train precision: 0.998956, train loss: 10.635631, valid precision: 0.878600, valid loss: 86.671305
epoch: 1483, train precision: 0.998844, train loss: 10.563129, valid precision: 0.876000, valid loss: 85.927837
epoch: 1484, train precision: 0.998978, train loss: 10.591502, valid precision: 0.879400, valid loss: 86.896034
epoch: 1485, train precision: 0.998844, train loss: 10.581068, valid precision: 0.880400, valid loss: 86.371783
epoch: 1486, train precision: 0.998578, train loss: 10.678496, valid precision: 0.880000, valid loss: 87.445434
epoch: 1487, train precision: 0.999222, train loss: 10.525644, valid precision: 0.882000, valid loss: 84.534550
epoch: 1488, train precision: 0.998911, train loss: 10.667927, valid precision: 0.878400, valid loss: 84.365553
epoch: 1489, train precision: 0.998711, train loss: 10.638869, valid precision: 0.879400, valid loss: 85.597740
epoch: 1490, train precision: 0.998644, train loss: 10.715482, valid precision: 0.880200, valid loss: 84.413338
epoch: 1491, train precision: 0.998822, train loss: 10.695186, valid precision: 0.880600, valid loss: 82.584811
epoch: 1492, train precision: 0.999089, train loss: 10.595208, valid precision: 0.879800, valid loss: 82.238428
epoch: 1493, train precision: 0.998311, train loss: 10.751649, valid precision: 0.877200, valid loss: 83.668103
epoch: 1494, train precision: 0.999156, train loss: 10.556086, valid precision: 0.880000, valid loss: 83.894159
epoch: 1495, train precision: 0.998933, train loss: 10.606765, valid precision: 0.877600, valid loss: 86.980670
epoch: 1496, train precision: 0.999178, train loss: 10.606739, valid precision: 0.879200, valid loss: 85.497737
epoch: 1497, train precision: 0.999000, train loss: 10.538682, valid precision: 0.878000, valid loss: 86.120802
epoch: 1498, train precision: 0.999156, train loss: 10.625345, valid precision: 0.880000, valid loss: 82.201363
epoch: 1499, train precision: 0.999311, train loss: 10.537303, valid precision: 0.877800, valid loss: 83.841254
epoch: 1500, train precision: 0.999156, train loss: 10.573740, valid precision: 0.879600, valid loss: 83.982313
epoch: 1501, train precision: 0.998622, train loss: 10.699326, valid precision: 0.879800, valid loss: 83.397685
epoch: 1502, train precision: 0.998511, train loss: 10.707021, valid precision: 0.879400, valid loss: 83.073944
epoch: 1503, train precision: 0.998911, train loss: 10.650301, valid precision: 0.880600, valid loss: 84.149459
epoch: 1504, train precision: 0.999000, train loss: 10.551299, valid precision: 0.880600, valid loss: 84.641242
epoch: 1505, train precision: 0.999022, train loss: 10.630219, valid precision: 0.879000, valid loss: 85.364830
epoch: 1506, train precision: 0.998800, train loss: 10.649142, valid precision: 0.882400, valid loss: 83.615502
epoch: 1507, train precision: 0.998244, train loss: 10.768645, valid precision: 0.882400, valid loss: 85.132054
epoch: 1508, train precision: 0.999067, train loss: 10.598730, valid precision: 0.883200, valid loss: 84.470587
epoch: 1509, train precision: 0.999000, train loss: 10.567133, valid precision: 0.879000, valid loss: 84.995961
epoch: 1510, train precision: 0.998444, train loss: 10.671660, valid precision: 0.879800, valid loss: 83.891979
epoch: 1511, train precision: 0.999022, train loss: 10.561001, valid precision: 0.881000, valid loss: 83.904223
epoch: 1512, train precision: 0.998867, train loss: 10.600046, valid precision: 0.880400, valid loss: 84.672683
epoch: 1513, train precision: 0.998667, train loss: 10.577352, valid precision: 0.881000, valid loss: 87.060282
epoch: 1514, train precision: 0.999311, train loss: 10.520079, valid precision: 0.876800, valid loss: 87.544003
epoch: 1515, train precision: 0.999111, train loss: 10.502849, valid precision: 0.878400, valid loss: 87.153805
epoch: 1516, train precision: 0.998600, train loss: 10.689539, valid precision: 0.877800, valid loss: 85.669658
epoch: 1517, train precision: 0.999044, train loss: 10.575309, valid precision: 0.882400, valid loss: 84.270578
epoch: 1518, train precision: 0.998956, train loss: 10.575504, valid precision: 0.879000, valid loss: 86.733503
epoch: 1519, train precision: 0.998933, train loss: 10.590639, valid precision: 0.881800, valid loss: 85.673833
epoch: 1520, train precision: 0.998622, train loss: 10.719629, valid precision: 0.880800, valid loss: 86.434083
epoch: 1521, train precision: 0.998778, train loss: 10.657064, valid precision: 0.881800, valid loss: 84.741335
epoch: 1522, train precision: 0.999022, train loss: 10.621615, valid precision: 0.881800, valid loss: 84.210073
epoch: 1523, train precision: 0.998711, train loss: 10.744173, valid precision: 0.880400, valid loss: 83.500610
epoch: 1524, train precision: 0.998711, train loss: 10.689496, valid precision: 0.881600, valid loss: 83.954788
epoch: 1525, train precision: 0.998911, train loss: 10.560012, valid precision: 0.880200, valid loss: 85.613067
epoch: 1526, train precision: 0.998444, train loss: 10.697613, valid precision: 0.880400, valid loss: 86.887610
epoch: 1527, train precision: 0.998533, train loss: 10.682016, valid precision: 0.882400, valid loss: 85.124986
epoch: 1528, train precision: 0.998956, train loss: 10.617389, valid precision: 0.877600, valid loss: 86.223677
epoch: 1529, train precision: 0.998933, train loss: 10.611082, valid precision: 0.876200, valid loss: 85.505905
epoch: 1530, train precision: 0.999000, train loss: 10.574633, valid precision: 0.874800, valid loss: 84.873140
epoch: 1531, train precision: 0.998622, train loss: 10.671657, valid precision: 0.876400, valid loss: 85.853978
epoch: 1532, train precision: 0.999156, train loss: 10.577276, valid precision: 0.878800, valid loss: 84.746689
epoch: 1533, train precision: 0.999133, train loss: 10.588063, valid precision: 0.874800, valid loss: 90.363295
epoch: 1534, train precision: 0.998978, train loss: 10.576021, valid precision: 0.876600, valid loss: 88.840984
epoch: 1535, train precision: 0.999267, train loss: 10.541161, valid precision: 0.877400, valid loss: 84.204231
epoch: 1536, train precision: 0.998933, train loss: 10.592550, valid precision: 0.878400, valid loss: 83.000054
epoch: 1537, train precision: 0.999067, train loss: 10.575954, valid precision: 0.879600, valid loss: 85.857716
epoch: 1538, train precision: 0.999067, train loss: 10.563831, valid precision: 0.881600, valid loss: 83.055752
epoch: 1539, train precision: 0.999244, train loss: 10.478246, valid precision: 0.877600, valid loss: 86.455998
epoch: 1540, train precision: 0.998622, train loss: 10.692234, valid precision: 0.876400, valid loss: 85.829413
epoch: 1541, train precision: 0.998889, train loss: 10.656950, valid precision: 0.879200, valid loss: 86.427814
epoch: 1542, train precision: 0.998822, train loss: 10.621788, valid precision: 0.880400, valid loss: 87.052555
epoch: 1543, train precision: 0.998689, train loss: 10.736056, valid precision: 0.878000, valid loss: 87.720454
epoch: 1544, train precision: 0.998956, train loss: 10.596257, valid precision: 0.878400, valid loss: 84.273439
epoch: 1545, train precision: 0.999200, train loss: 10.508065, valid precision: 0.878200, valid loss: 84.488609
epoch: 1546, train precision: 0.998756, train loss: 10.618571, valid precision: 0.878000, valid loss: 88.053468
epoch: 1547, train precision: 0.999000, train loss: 10.590324, valid precision: 0.879400, valid loss: 85.782095
epoch: 1548, train precision: 0.998778, train loss: 10.697982, valid precision: 0.880800, valid loss: 87.842735
epoch: 1549, train precision: 0.999111, train loss: 10.580352, valid precision: 0.876400, valid loss: 86.355631
epoch: 1550, train precision: 0.998689, train loss: 10.673281, valid precision: 0.882000, valid loss: 86.196885
epoch: 1551, train precision: 0.998467, train loss: 10.801404, valid precision: 0.879400, valid loss: 87.723997
epoch: 1552, train precision: 0.998800, train loss: 10.642192, valid precision: 0.882400, valid loss: 85.490973
epoch: 1553, train precision: 0.999200, train loss: 10.552257, valid precision: 0.882600, valid loss: 84.035205
epoch: 1554, train precision: 0.998800, train loss: 10.699386, valid precision: 0.879800, valid loss: 84.171311
epoch: 1555, train precision: 0.999022, train loss: 10.605174, valid precision: 0.879600, valid loss: 83.449320
epoch: 1556, train precision: 0.999311, train loss: 10.547918, valid precision: 0.879200, valid loss: 83.257588
epoch: 1557, train precision: 0.999000, train loss: 10.614247, valid precision: 0.881400, valid loss: 85.239626
epoch: 1558, train precision: 0.998844, train loss: 10.613588, valid precision: 0.877200, valid loss: 85.717582
epoch: 1559, train precision: 0.998578, train loss: 10.743687, valid precision: 0.878200, valid loss: 86.014760
epoch: 1560, train precision: 0.999022, train loss: 10.526718, valid precision: 0.882600, valid loss: 84.332414
epoch: 1561, train precision: 0.999000, train loss: 10.575151, valid precision: 0.878200, valid loss: 83.584761
epoch: 1562, train precision: 0.998756, train loss: 10.742261, valid precision: 0.878400, valid loss: 87.735834
epoch: 1563, train precision: 0.999044, train loss: 10.583686, valid precision: 0.883400, valid loss: 84.901854
epoch: 1564, train precision: 0.999022, train loss: 10.623266, valid precision: 0.881800, valid loss: 83.606359
epoch: 1565, train precision: 0.999067, train loss: 10.568120, valid precision: 0.878600, valid loss: 86.518599
epoch: 1566, train precision: 0.998844, train loss: 10.589438, valid precision: 0.880000, valid loss: 84.010067
epoch: 1567, train precision: 0.999044, train loss: 10.569873, valid precision: 0.880800, valid loss: 86.516250
epoch: 1568, train precision: 0.998867, train loss: 10.627174, valid precision: 0.876200, valid loss: 87.885863
epoch: 1569, train precision: 0.998800, train loss: 10.663846, valid precision: 0.874000, valid loss: 86.602292
epoch: 1570, train precision: 0.998867, train loss: 10.614122, valid precision: 0.879400, valid loss: 84.419790
epoch: 1571, train precision: 0.998778, train loss: 10.668157, valid precision: 0.877000, valid loss: 86.960098
epoch: 1572, train precision: 0.999111, train loss: 10.560208, valid precision: 0.878400, valid loss: 85.730592
epoch: 1573, train precision: 0.998756, train loss: 10.599668, valid precision: 0.878000, valid loss: 85.209449
epoch: 1574, train precision: 0.998978, train loss: 10.612913, valid precision: 0.880600, valid loss: 85.366325
epoch: 1575, train precision: 0.998467, train loss: 10.717209, valid precision: 0.876800, valid loss: 87.138084
epoch: 1576, train precision: 0.998756, train loss: 10.647538, valid precision: 0.876600, valid loss: 88.567659
epoch: 1577, train precision: 0.998444, train loss: 10.712998, valid precision: 0.875400, valid loss: 87.250988
epoch: 1578, train precision: 0.999067, train loss: 10.593496, valid precision: 0.876200, valid loss: 87.125058
epoch: 1579, train precision: 0.998978, train loss: 10.603256, valid precision: 0.873200, valid loss: 86.484654
epoch: 1580, train precision: 0.998689, train loss: 10.640201, valid precision: 0.880600, valid loss: 85.471697
epoch: 1581, train precision: 0.998889, train loss: 10.608168, valid precision: 0.876600, valid loss: 86.604840
epoch: 1582, train precision: 0.999156, train loss: 10.534760, valid precision: 0.880400, valid loss: 85.673584
epoch: 1583, train precision: 0.998800, train loss: 10.595157, valid precision: 0.878600, valid loss: 86.049371
epoch: 1584, train precision: 0.998867, train loss: 10.662483, valid precision: 0.877200, valid loss: 88.406493
epoch: 1585, train precision: 0.998933, train loss: 10.575304, valid precision: 0.880200, valid loss: 86.709625
epoch: 1586, train precision: 0.999044, train loss: 10.535246, valid precision: 0.879200, valid loss: 84.815333
epoch: 1587, train precision: 0.998689, train loss: 10.677580, valid precision: 0.883800, valid loss: 83.975098
epoch: 1588, train precision: 0.999133, train loss: 10.591796, valid precision: 0.881200, valid loss: 84.200379
epoch: 1589, train precision: 0.998822, train loss: 10.669975, valid precision: 0.881800, valid loss: 83.354145
epoch: 1590, train precision: 0.998622, train loss: 10.700948, valid precision: 0.878400, valid loss: 85.521714
epoch: 1591, train precision: 0.998667, train loss: 10.632147, valid precision: 0.882600, valid loss: 84.887306
epoch: 1592, train precision: 0.998711, train loss: 10.598213, valid precision: 0.881600, valid loss: 84.508675
epoch: 1593, train precision: 0.998578, train loss: 10.697761, valid precision: 0.879800, valid loss: 86.893412
epoch: 1594, train precision: 0.998844, train loss: 10.591529, valid precision: 0.879600, valid loss: 84.895589
epoch: 1595, train precision: 0.999089, train loss: 10.547759, valid precision: 0.875800, valid loss: 83.561412
epoch: 1596, train precision: 0.999067, train loss: 10.560948, valid precision: 0.878200, valid loss: 85.852607
epoch: 1597, train precision: 0.998756, train loss: 10.704233, valid precision: 0.877400, valid loss: 85.812776
epoch: 1598, train precision: 0.998956, train loss: 10.560574, valid precision: 0.881400, valid loss: 85.003448
epoch: 1599, train precision: 0.999156, train loss: 10.514407, valid precision: 0.877800, valid loss: 85.895336
epoch: 1600, train precision: 0.998778, train loss: 10.622472, valid precision: 0.879000, valid loss: 85.849671
epoch: 1601, train precision: 0.998911, train loss: 10.668946, valid precision: 0.872600, valid loss: 89.203978
epoch: 1602, train precision: 0.998956, train loss: 10.579292, valid precision: 0.874200, valid loss: 88.222641
epoch: 1603, train precision: 0.998844, train loss: 10.577952, valid precision: 0.874800, valid loss: 87.210644
epoch: 1604, train precision: 0.998956, train loss: 10.603804, valid precision: 0.874600, valid loss: 87.742739
epoch: 1605, train precision: 0.998622, train loss: 10.655500, valid precision: 0.873000, valid loss: 87.361605
epoch: 1606, train precision: 0.999133, train loss: 10.522488, valid precision: 0.875200, valid loss: 85.229857
epoch: 1607, train precision: 0.998889, train loss: 10.557742, valid precision: 0.876600, valid loss: 86.290767
epoch: 1608, train precision: 0.998933, train loss: 10.621990, valid precision: 0.877000, valid loss: 87.164140
epoch: 1609, train precision: 0.999000, train loss: 10.585707, valid precision: 0.870400, valid loss: 85.807083
epoch: 1610, train precision: 0.998511, train loss: 10.694813, valid precision: 0.875200, valid loss: 88.215292
epoch: 1611, train precision: 0.999000, train loss: 10.547274, valid precision: 0.879200, valid loss: 86.235559
epoch: 1612, train precision: 0.998978, train loss: 10.590538, valid precision: 0.876400, valid loss: 86.776592
epoch: 1613, train precision: 0.999089, train loss: 10.547972, valid precision: 0.877200, valid loss: 86.214189
epoch: 1614, train precision: 0.999133, train loss: 10.592078, valid precision: 0.874600, valid loss: 84.514489
epoch: 1615, train precision: 0.999178, train loss: 10.525696, valid precision: 0.878400, valid loss: 84.917084
epoch: 1616, train precision: 0.999489, train loss: 10.498118, valid precision: 0.880200, valid loss: 84.083169
epoch: 1617, train precision: 0.999178, train loss: 10.499903, valid precision: 0.878400, valid loss: 84.159881
epoch: 1618, train precision: 0.998689, train loss: 10.591312, valid precision: 0.878800, valid loss: 82.372743
epoch: 1619, train precision: 0.998911, train loss: 10.572648, valid precision: 0.879200, valid loss: 84.693340
epoch: 1620, train precision: 0.998778, train loss: 10.715415, valid precision: 0.878200, valid loss: 84.685048
epoch: 1621, train precision: 0.999156, train loss: 10.540443, valid precision: 0.879800, valid loss: 85.071014
epoch: 1622, train precision: 0.999067, train loss: 10.534742, valid precision: 0.878400, valid loss: 84.002598
epoch: 1623, train precision: 0.998956, train loss: 10.580176, valid precision: 0.877800, valid loss: 84.692041
epoch: 1624, train precision: 0.998822, train loss: 10.602067, valid precision: 0.879600, valid loss: 83.155841
epoch: 1625, train precision: 0.999244, train loss: 10.512053, valid precision: 0.879000, valid loss: 83.001047
epoch: 1626, train precision: 0.999044, train loss: 10.524527, valid precision: 0.877600, valid loss: 85.553621
epoch: 1627, train precision: 0.998489, train loss: 10.710365, valid precision: 0.877200, valid loss: 85.014966
epoch: 1628, train precision: 0.998911, train loss: 10.565762, valid precision: 0.876800, valid loss: 84.913378
epoch: 1629, train precision: 0.998911, train loss: 10.576022, valid precision: 0.879400, valid loss: 83.413115
epoch: 1630, train precision: 0.998933, train loss: 10.563555, valid precision: 0.878600, valid loss: 84.283742
epoch: 1631, train precision: 0.998667, train loss: 10.576651, valid precision: 0.878200, valid loss: 83.824381
epoch: 1632, train precision: 0.998867, train loss: 10.585065, valid precision: 0.879800, valid loss: 83.815031
epoch: 1633, train precision: 0.998711, train loss: 10.651682, valid precision: 0.878000, valid loss: 83.710615
epoch: 1634, train precision: 0.998933, train loss: 10.542774, valid precision: 0.877200, valid loss: 86.272077
epoch: 1635, train precision: 0.998511, train loss: 10.619657, valid precision: 0.879200, valid loss: 83.789607
epoch: 1636, train precision: 0.999244, train loss: 10.454916, valid precision: 0.876200, valid loss: 85.260149
epoch: 1637, train precision: 0.999111, train loss: 10.474509, valid precision: 0.877000, valid loss: 86.875511
epoch: 1638, train precision: 0.998644, train loss: 10.708614, valid precision: 0.876000, valid loss: 86.207153
epoch: 1639, train precision: 0.998756, train loss: 10.622148, valid precision: 0.878400, valid loss: 84.185570
epoch: 1640, train precision: 0.998889, train loss: 10.576149, valid precision: 0.876200, valid loss: 87.104280
epoch: 1641, train precision: 0.998600, train loss: 10.589691, valid precision: 0.875600, valid loss: 88.103510
epoch: 1642, train precision: 0.998911, train loss: 10.603651, valid precision: 0.876400, valid loss: 87.361879
epoch: 1643, train precision: 0.998422, train loss: 10.733618, valid precision: 0.875800, valid loss: 87.774017
epoch: 1644, train precision: 0.998889, train loss: 10.626721, valid precision: 0.873200, valid loss: 86.984925
epoch: 1645, train precision: 0.999133, train loss: 10.560827, valid precision: 0.878200, valid loss: 86.067389
epoch: 1646, train precision: 0.998978, train loss: 10.592849, valid precision: 0.875200, valid loss: 88.153753
epoch: 1647, train precision: 0.998800, train loss: 10.588592, valid precision: 0.872400, valid loss: 86.810479
epoch: 1648, train precision: 0.998644, train loss: 10.638140, valid precision: 0.876400, valid loss: 86.538005
epoch: 1649, train precision: 0.998711, train loss: 10.723336, valid precision: 0.873200, valid loss: 87.186166
epoch: 1650, train precision: 0.999156, train loss: 10.512278, valid precision: 0.873600, valid loss: 85.351323
epoch: 1651, train precision: 0.998978, train loss: 10.559243, valid precision: 0.878000, valid loss: 85.366906
epoch: 1652, train precision: 0.998356, train loss: 10.651743, valid precision: 0.877000, valid loss: 86.715786
epoch: 1653, train precision: 0.998778, train loss: 10.616339, valid precision: 0.872800, valid loss: 86.368416
epoch: 1654, train precision: 0.998800, train loss: 10.534943, valid precision: 0.876600, valid loss: 87.437166
epoch: 1655, train precision: 0.999022, train loss: 10.545687, valid precision: 0.876200, valid loss: 85.394148
epoch: 1656, train precision: 0.999133, train loss: 10.571952, valid precision: 0.878600, valid loss: 85.195039
epoch: 1657, train precision: 0.999178, train loss: 10.524904, valid precision: 0.879800, valid loss: 82.602085
epoch: 1658, train precision: 0.998711, train loss: 10.621934, valid precision: 0.872000, valid loss: 83.991832
epoch: 1659, train precision: 0.999067, train loss: 10.478233, valid precision: 0.876600, valid loss: 84.111111
epoch: 1660, train precision: 0.998956, train loss: 10.580837, valid precision: 0.876800, valid loss: 83.700126
epoch: 1661, train precision: 0.998844, train loss: 10.603308, valid precision: 0.868200, valid loss: 86.765742
epoch: 1662, train precision: 0.999267, train loss: 10.441673, valid precision: 0.875600, valid loss: 87.599437
epoch: 1663, train precision: 0.998778, train loss: 10.586258, valid precision: 0.877000, valid loss: 85.693943
epoch: 1664, train precision: 0.999044, train loss: 10.592229, valid precision: 0.879200, valid loss: 83.513034
epoch: 1665, train precision: 0.998867, train loss: 10.599277, valid precision: 0.877200, valid loss: 82.604266
epoch: 1666, train precision: 0.998911, train loss: 10.583988, valid precision: 0.874000, valid loss: 84.132468
epoch: 1667, train precision: 0.998822, train loss: 10.597868, valid precision: 0.879000, valid loss: 85.156154
epoch: 1668, train precision: 0.998933, train loss: 10.538217, valid precision: 0.876600, valid loss: 85.306758
epoch: 1669, train precision: 0.998822, train loss: 10.571252, valid precision: 0.872200, valid loss: 84.514543
epoch: 1670, train precision: 0.999244, train loss: 10.431890, valid precision: 0.875600, valid loss: 84.601055
epoch: 1671, train precision: 0.998800, train loss: 10.640680, valid precision: 0.875400, valid loss: 85.591346
epoch: 1672, train precision: 0.999089, train loss: 10.473564, valid precision: 0.879600, valid loss: 84.104503
epoch: 1673, train precision: 0.998911, train loss: 10.519248, valid precision: 0.875800, valid loss: 85.699583
epoch: 1674, train precision: 0.998822, train loss: 10.482181, valid precision: 0.874800, valid loss: 86.342156
epoch: 1675, train precision: 0.998956, train loss: 10.656437, valid precision: 0.874000, valid loss: 86.227123
epoch: 1676, train precision: 0.999156, train loss: 10.493939, valid precision: 0.876200, valid loss: 87.503148
epoch: 1677, train precision: 0.998978, train loss: 10.570294, valid precision: 0.878200, valid loss: 86.314613
epoch: 1678, train precision: 0.998644, train loss: 10.674448, valid precision: 0.877400, valid loss: 86.813066
epoch: 1679, train precision: 0.998844, train loss: 10.583347, valid precision: 0.877200, valid loss: 84.305270
epoch: 1680, train precision: 0.998622, train loss: 10.637824, valid precision: 0.875600, valid loss: 88.487348
epoch: 1681, train precision: 0.998733, train loss: 10.544595, valid precision: 0.877000, valid loss: 86.459540
epoch: 1682, train precision: 0.999067, train loss: 10.506627, valid precision: 0.876000, valid loss: 88.336812
epoch: 1683, train precision: 0.999178, train loss: 10.532616, valid precision: 0.883000, valid loss: 84.135562
epoch: 1684, train precision: 0.998733, train loss: 10.599901, valid precision: 0.875600, valid loss: 84.819834
epoch: 1685, train precision: 0.998911, train loss: 10.544879, valid precision: 0.880800, valid loss: 84.774926
epoch: 1686, train precision: 0.999067, train loss: 10.560204, valid precision: 0.877800, valid loss: 83.243800
epoch: 1687, train precision: 0.998822, train loss: 10.553197, valid precision: 0.876200, valid loss: 86.285332
epoch: 1688, train precision: 0.998844, train loss: 10.568993, valid precision: 0.878200, valid loss: 86.561595
epoch: 1689, train precision: 0.998689, train loss: 10.637758, valid precision: 0.877000, valid loss: 86.683842
epoch: 1690, train precision: 0.999022, train loss: 10.565171, valid precision: 0.876800, valid loss: 84.442240
epoch: 1691, train precision: 0.998756, train loss: 10.615539, valid precision: 0.871800, valid loss: 86.763215
epoch: 1692, train precision: 0.998867, train loss: 10.531001, valid precision: 0.873600, valid loss: 89.310231
epoch: 1693, train precision: 0.998689, train loss: 10.663453, valid precision: 0.877800, valid loss: 89.068349
epoch: 1694, train precision: 0.999133, train loss: 10.492644, valid precision: 0.879200, valid loss: 85.782063
epoch: 1695, train precision: 0.998978, train loss: 10.482177, valid precision: 0.878600, valid loss: 87.773297
epoch: 1696, train precision: 0.999044, train loss: 10.477025, valid precision: 0.875200, valid loss: 87.268395
epoch: 1697, train precision: 0.998822, train loss: 10.654705, valid precision: 0.876200, valid loss: 87.544084
epoch: 1698, train precision: 0.999156, train loss: 10.484539, valid precision: 0.876400, valid loss: 86.824066
epoch: 1699, train precision: 0.999089, train loss: 10.529399, valid precision: 0.879800, valid loss: 86.568347
epoch: 1700, train precision: 0.999089, train loss: 10.455307, valid precision: 0.876200, valid loss: 90.815343
epoch: 1701, train precision: 0.999022, train loss: 10.567392, valid precision: 0.876000, valid loss: 91.136573
epoch: 1702, train precision: 0.998978, train loss: 10.517828, valid precision: 0.878800, valid loss: 89.908575
epoch: 1703, train precision: 0.999156, train loss: 10.492339, valid precision: 0.878200, valid loss: 90.137350
epoch: 1704, train precision: 0.998933, train loss: 10.607903, valid precision: 0.879400, valid loss: 86.037789
epoch: 1705, train precision: 0.999111, train loss: 10.535620, valid precision: 0.875000, valid loss: 88.642222
epoch: 1706, train precision: 0.998978, train loss: 10.547226, valid precision: 0.878000, valid loss: 87.122851
epoch: 1707, train precision: 0.999067, train loss: 10.521445, valid precision: 0.875200, valid loss: 92.691869
epoch: 1708, train precision: 0.998644, train loss: 10.567036, valid precision: 0.875400, valid loss: 89.918332
epoch: 1709, train precision: 0.998956, train loss: 10.567537, valid precision: 0.877600, valid loss: 87.841209
epoch: 1710, train precision: 0.999044, train loss: 10.543298, valid precision: 0.878800, valid loss: 89.178295
epoch: 1711, train precision: 0.998800, train loss: 10.614129, valid precision: 0.878600, valid loss: 88.260277
epoch: 1712, train precision: 0.999089, train loss: 10.466200, valid precision: 0.880800, valid loss: 89.217439
epoch: 1713, train precision: 0.998378, train loss: 10.727069, valid precision: 0.878200, valid loss: 88.214835
epoch: 1714, train precision: 0.998733, train loss: 10.600861, valid precision: 0.878200, valid loss: 86.544518
epoch: 1715, train precision: 0.999244, train loss: 10.473708, valid precision: 0.877400, valid loss: 86.786042
epoch: 1716, train precision: 0.998844, train loss: 10.587565, valid precision: 0.879200, valid loss: 86.070989
epoch: 1717, train precision: 0.998711, train loss: 10.585811, valid precision: 0.871400, valid loss: 87.749460
epoch: 1718, train precision: 0.998933, train loss: 10.538262, valid precision: 0.876200, valid loss: 86.582006
epoch: 1719, train precision: 0.998689, train loss: 10.652523, valid precision: 0.877600, valid loss: 83.165860
epoch: 1720, train precision: 0.999000, train loss: 10.571872, valid precision: 0.880800, valid loss: 85.229137
epoch: 1721, train precision: 0.998689, train loss: 10.554831, valid precision: 0.878800, valid loss: 86.438552
epoch: 1722, train precision: 0.999089, train loss: 10.470537, valid precision: 0.875000, valid loss: 86.379079
epoch: 1723, train precision: 0.999089, train loss: 10.507249, valid precision: 0.873800, valid loss: 85.372953
epoch: 1724, train precision: 0.998933, train loss: 10.606530, valid precision: 0.876600, valid loss: 85.735171
epoch: 1725, train precision: 0.998956, train loss: 10.521138, valid precision: 0.876600, valid loss: 88.345707
epoch: 1726, train precision: 0.999133, train loss: 10.528197, valid precision: 0.875600, valid loss: 85.344748
epoch: 1727, train precision: 0.999067, train loss: 10.471575, valid precision: 0.879600, valid loss: 83.958509
epoch: 1728, train precision: 0.998622, train loss: 10.667305, valid precision: 0.878600, valid loss: 83.626808
epoch: 1729, train precision: 0.999044, train loss: 10.511536, valid precision: 0.876800, valid loss: 85.460010
epoch: 1730, train precision: 0.999156, train loss: 10.519031, valid precision: 0.880000, valid loss: 85.346292
epoch: 1731, train precision: 0.998822, train loss: 10.542316, valid precision: 0.879000, valid loss: 87.222684
epoch: 1732, train precision: 0.998867, train loss: 10.594210, valid precision: 0.878600, valid loss: 88.128781
epoch: 1733, train precision: 0.999244, train loss: 10.486761, valid precision: 0.881400, valid loss: 86.883094
epoch: 1734, train precision: 0.999044, train loss: 10.467858, valid precision: 0.878400, valid loss: 89.256935
epoch: 1735, train precision: 0.998911, train loss: 10.563027, valid precision: 0.877600, valid loss: 87.942908
epoch: 1736, train precision: 0.999244, train loss: 10.452673, valid precision: 0.876200, valid loss: 87.102105
epoch: 1737, train precision: 0.998867, train loss: 10.490108, valid precision: 0.879400, valid loss: 85.840649
epoch: 1738, train precision: 0.999044, train loss: 10.480460, valid precision: 0.877600, valid loss: 85.565040
epoch: 1739, train precision: 0.998756, train loss: 10.597877, valid precision: 0.877200, valid loss: 87.737539
epoch: 1740, train precision: 0.998822, train loss: 10.629447, valid precision: 0.878200, valid loss: 88.524774
epoch: 1741, train precision: 0.999133, train loss: 10.544345, valid precision: 0.876600, valid loss: 88.467272
epoch: 1742, train precision: 0.998889, train loss: 10.532906, valid precision: 0.879600, valid loss: 86.754089
epoch: 1743, train precision: 0.998578, train loss: 10.589789, valid precision: 0.880600, valid loss: 87.678301
epoch: 1744, train precision: 0.998800, train loss: 10.585896, valid precision: 0.879800, valid loss: 86.847228
epoch: 1745, train precision: 0.999067, train loss: 10.449938, valid precision: 0.879400, valid loss: 89.214832
epoch: 1746, train precision: 0.998733, train loss: 10.645799, valid precision: 0.882600, valid loss: 85.459453
epoch: 1747, train precision: 0.998956, train loss: 10.605570, valid precision: 0.877800, valid loss: 86.164203
epoch: 1748, train precision: 0.999289, train loss: 10.427270, valid precision: 0.878000, valid loss: 86.529603
epoch: 1749, train precision: 0.999133, train loss: 10.475797, valid precision: 0.876400, valid loss: 88.904259
epoch: 1750, train precision: 0.999133, train loss: 10.512290, valid precision: 0.877000, valid loss: 88.651099
epoch: 1751, train precision: 0.999200, train loss: 10.505454, valid precision: 0.876000, valid loss: 90.715833
epoch: 1752, train precision: 0.998378, train loss: 10.752843, valid precision: 0.879200, valid loss: 88.536154
epoch: 1753, train precision: 0.999089, train loss: 10.543469, valid precision: 0.877200, valid loss: 88.753137
epoch: 1754, train precision: 0.998800, train loss: 10.566020, valid precision: 0.878600, valid loss: 88.489157
epoch: 1755, train precision: 0.998711, train loss: 10.615250, valid precision: 0.874600, valid loss: 92.337148
epoch: 1756, train precision: 0.998956, train loss: 10.577962, valid precision: 0.878200, valid loss: 86.572204
epoch: 1757, train precision: 0.998444, train loss: 10.716842, valid precision: 0.871800, valid loss: 91.447577
epoch: 1758, train precision: 0.998889, train loss: 10.601425, valid precision: 0.879200, valid loss: 86.045302
epoch: 1759, train precision: 0.998689, train loss: 10.588420, valid precision: 0.879000, valid loss: 88.126926
epoch: 1760, train precision: 0.999178, train loss: 10.498246, valid precision: 0.879600, valid loss: 86.030133
epoch: 1761, train precision: 0.998822, train loss: 10.588178, valid precision: 0.877000, valid loss: 88.704620
epoch: 1762, train precision: 0.998800, train loss: 10.566823, valid precision: 0.877600, valid loss: 87.907202
epoch: 1763, train precision: 0.998911, train loss: 10.573597, valid precision: 0.876200, valid loss: 88.164885
epoch: 1764, train precision: 0.998889, train loss: 10.543159, valid precision: 0.872800, valid loss: 90.419349
epoch: 1765, train precision: 0.998800, train loss: 10.536955, valid precision: 0.873600, valid loss: 88.942836
epoch: 1766, train precision: 0.999222, train loss: 10.513103, valid precision: 0.875800, valid loss: 89.736641
epoch: 1767, train precision: 0.998756, train loss: 10.570375, valid precision: 0.876000, valid loss: 88.561187
epoch: 1768, train precision: 0.998867, train loss: 10.573104, valid precision: 0.877600, valid loss: 88.526851
epoch: 1769, train precision: 0.998600, train loss: 10.710057, valid precision: 0.877000, valid loss: 88.133626
epoch: 1770, train precision: 0.998600, train loss: 10.610241, valid precision: 0.882000, valid loss: 89.387401
epoch: 1771, train precision: 0.999133, train loss: 10.494046, valid precision: 0.876000, valid loss: 88.535013
epoch: 1772, train precision: 0.999133, train loss: 10.457668, valid precision: 0.875600, valid loss: 89.290535
epoch: 1773, train precision: 0.999178, train loss: 10.420485, valid precision: 0.876400, valid loss: 88.978315
epoch: 1774, train precision: 0.998756, train loss: 10.608510, valid precision: 0.875400, valid loss: 88.695696
epoch: 1775, train precision: 0.999044, train loss: 10.458489, valid precision: 0.880000, valid loss: 85.293705
epoch: 1776, train precision: 0.998911, train loss: 10.495962, valid precision: 0.875200, valid loss: 86.920123
epoch: 1777, train precision: 0.998822, train loss: 10.587176, valid precision: 0.876200, valid loss: 86.018556
epoch: 1778, train precision: 0.999089, train loss: 10.534753, valid precision: 0.882800, valid loss: 88.251791
epoch: 1779, train precision: 0.998867, train loss: 10.556012, valid precision: 0.876200, valid loss: 89.907445
epoch: 1780, train precision: 0.998800, train loss: 10.591439, valid precision: 0.875800, valid loss: 91.401196
epoch: 1781, train precision: 0.998911, train loss: 10.564703, valid precision: 0.878200, valid loss: 90.124787
epoch: 1782, train precision: 0.998778, train loss: 10.610129, valid precision: 0.875600, valid loss: 89.691607
epoch: 1783, train precision: 0.998600, train loss: 10.634753, valid precision: 0.875000, valid loss: 92.430914
epoch: 1784, train precision: 0.999200, train loss: 10.500951, valid precision: 0.878800, valid loss: 89.086439
epoch: 1785, train precision: 0.999067, train loss: 10.496826, valid precision: 0.876200, valid loss: 90.819490
epoch: 1786, train precision: 0.999267, train loss: 10.478988, valid precision: 0.879200, valid loss: 89.238606
epoch: 1787, train precision: 0.998822, train loss: 10.589020, valid precision: 0.873400, valid loss: 90.201558
epoch: 1788, train precision: 0.999133, train loss: 10.544297, valid precision: 0.877800, valid loss: 89.532379
epoch: 1789, train precision: 0.998911, train loss: 10.599376, valid precision: 0.877800, valid loss: 89.487377
epoch: 1790, train precision: 0.999356, train loss: 10.422670, valid precision: 0.876600, valid loss: 87.557699
epoch: 1791, train precision: 0.999022, train loss: 10.552873, valid precision: 0.874600, valid loss: 92.439583
epoch: 1792, train precision: 0.998911, train loss: 10.564382, valid precision: 0.876000, valid loss: 91.067632
epoch: 1793, train precision: 0.999022, train loss: 10.473489, valid precision: 0.875600, valid loss: 88.646994
epoch: 1794, train precision: 0.999133, train loss: 10.466830, valid precision: 0.877000, valid loss: 90.504649
epoch: 1795, train precision: 0.998933, train loss: 10.518725, valid precision: 0.876400, valid loss: 89.849627
epoch: 1796, train precision: 0.999156, train loss: 10.513168, valid precision: 0.875600, valid loss: 90.687179
epoch: 1797, train precision: 0.998867, train loss: 10.558522, valid precision: 0.873600, valid loss: 90.632533
epoch: 1798, train precision: 0.999022, train loss: 10.490602, valid precision: 0.874600, valid loss: 90.969717
epoch: 1799, train precision: 0.998956, train loss: 10.527258, valid precision: 0.880600, valid loss: 90.236202
epoch: 1800, train precision: 0.999067, train loss: 10.443274, valid precision: 0.875000, valid loss: 90.636574
epoch: 1801, train precision: 0.999222, train loss: 10.500569, valid precision: 0.877400, valid loss: 90.437085
epoch: 1802, train precision: 0.999000, train loss: 10.527486, valid precision: 0.872200, valid loss: 91.097862
epoch: 1803, train precision: 0.998956, train loss: 10.570080, valid precision: 0.875400, valid loss: 90.928406
epoch: 1804, train precision: 0.998400, train loss: 10.745639, valid precision: 0.874200, valid loss: 89.496013
epoch: 1805, train precision: 0.998844, train loss: 10.545770, valid precision: 0.879200, valid loss: 87.692231
epoch: 1806, train precision: 0.999378, train loss: 10.488298, valid precision: 0.877200, valid loss: 90.177513
epoch: 1807, train precision: 0.999089, train loss: 10.508234, valid precision: 0.879200, valid loss: 87.396008
epoch: 1808, train precision: 0.998933, train loss: 10.542216, valid precision: 0.880000, valid loss: 88.520288
epoch: 1809, train precision: 0.998911, train loss: 10.508860, valid precision: 0.874200, valid loss: 90.900851
epoch: 1810, train precision: 0.999022, train loss: 10.587782, valid precision: 0.877600, valid loss: 90.191329
epoch: 1811, train precision: 0.998733, train loss: 10.595167, valid precision: 0.879400, valid loss: 90.820964
epoch: 1812, train precision: 0.998822, train loss: 10.562758, valid precision: 0.878600, valid loss: 88.553256
epoch: 1813, train precision: 0.999156, train loss: 10.522915, valid precision: 0.879600, valid loss: 87.106422
epoch: 1814, train precision: 0.998778, train loss: 10.605228, valid precision: 0.877400, valid loss: 87.552490
epoch: 1815, train precision: 0.999267, train loss: 10.420816, valid precision: 0.879800, valid loss: 88.288950
epoch: 1816, train precision: 0.998733, train loss: 10.596988, valid precision: 0.877200, valid loss: 88.423592
epoch: 1817, train precision: 0.999067, train loss: 10.543808, valid precision: 0.882000, valid loss: 89.376994
epoch: 1818, train precision: 0.999178, train loss: 10.483309, valid precision: 0.879000, valid loss: 86.987689
epoch: 1819, train precision: 0.998733, train loss: 10.614696, valid precision: 0.878400, valid loss: 86.914802
epoch: 1820, train precision: 0.999244, train loss: 10.495757, valid precision: 0.877400, valid loss: 88.157326
epoch: 1821, train precision: 0.999333, train loss: 10.475135, valid precision: 0.878400, valid loss: 87.359522
epoch: 1822, train precision: 0.998489, train loss: 10.682265, valid precision: 0.877400, valid loss: 88.378663
epoch: 1823, train precision: 0.999156, train loss: 10.521076, valid precision: 0.880600, valid loss: 86.761272
epoch: 1824, train precision: 0.999267, train loss: 10.487376, valid precision: 0.882200, valid loss: 86.040180
epoch: 1825, train precision: 0.999000, train loss: 10.535985, valid precision: 0.882200, valid loss: 87.650084
epoch: 1826, train precision: 0.999000, train loss: 10.560458, valid precision: 0.878000, valid loss: 88.798746
epoch: 1827, train precision: 0.999000, train loss: 10.468221, valid precision: 0.876800, valid loss: 86.027786
epoch: 1828, train precision: 0.999178, train loss: 10.486763, valid precision: 0.878400, valid loss: 89.263662
epoch: 1829, train precision: 0.998578, train loss: 10.676112, valid precision: 0.873400, valid loss: 88.380822
epoch: 1830, train precision: 0.998911, train loss: 10.541647, valid precision: 0.879800, valid loss: 85.533680
epoch: 1831, train precision: 0.999133, train loss: 10.478349, valid precision: 0.876200, valid loss: 87.044595
epoch: 1832, train precision: 0.998822, train loss: 10.557514, valid precision: 0.876000, valid loss: 88.322617
epoch: 1833, train precision: 0.998667, train loss: 10.635291, valid precision: 0.874000, valid loss: 89.266850
epoch: 1834, train precision: 0.999000, train loss: 10.560110, valid precision: 0.878600, valid loss: 85.947490
epoch: 1835, train precision: 0.998889, train loss: 10.517681, valid precision: 0.877000, valid loss: 87.454379
epoch: 1836, train precision: 0.999000, train loss: 10.513278, valid precision: 0.880000, valid loss: 88.189783
epoch: 1837, train precision: 0.998800, train loss: 10.520863, valid precision: 0.882000, valid loss: 90.362186
epoch: 1838, train precision: 0.998444, train loss: 10.616811, valid precision: 0.876200, valid loss: 89.204766
epoch: 1839, train precision: 0.998756, train loss: 10.615712, valid precision: 0.876200, valid loss: 89.874397
epoch: 1840, train precision: 0.999067, train loss: 10.490777, valid precision: 0.876600, valid loss: 90.128393
epoch: 1841, train precision: 0.998933, train loss: 10.571035, valid precision: 0.876800, valid loss: 89.187818
epoch: 1842, train precision: 0.998911, train loss: 10.533249, valid precision: 0.878800, valid loss: 87.191346
epoch: 1843, train precision: 0.999044, train loss: 10.470742, valid precision: 0.877000, valid loss: 88.614430
epoch: 1844, train precision: 0.999178, train loss: 10.460318, valid precision: 0.880600, valid loss: 85.310380
epoch: 1845, train precision: 0.998800, train loss: 10.533888, valid precision: 0.879400, valid loss: 87.823656
epoch: 1846, train precision: 0.998844, train loss: 10.592281, valid precision: 0.883200, valid loss: 89.492170
epoch: 1847, train precision: 0.998778, train loss: 10.570957, valid precision: 0.881400, valid loss: 87.341284
epoch: 1848, train precision: 0.999067, train loss: 10.509782, valid precision: 0.879400, valid loss: 85.729008
epoch: 1849, train precision: 0.998933, train loss: 10.521829, valid precision: 0.879000, valid loss: 86.586519
epoch: 1850, train precision: 0.998844, train loss: 10.594282, valid precision: 0.877800, valid loss: 89.921233
epoch: 1851, train precision: 0.999067, train loss: 10.503943, valid precision: 0.878600, valid loss: 88.063057
epoch: 1852, train precision: 0.998600, train loss: 10.674971, valid precision: 0.876000, valid loss: 90.170011
epoch: 1853, train precision: 0.999089, train loss: 10.487077, valid precision: 0.874600, valid loss: 88.063498
epoch: 1854, train precision: 0.998778, train loss: 10.583225, valid precision: 0.879000, valid loss: 89.231392
epoch: 1855, train precision: 0.999022, train loss: 10.507176, valid precision: 0.879200, valid loss: 89.802734
epoch: 1856, train precision: 0.998889, train loss: 10.580851, valid precision: 0.877600, valid loss: 88.240579
epoch: 1857, train precision: 0.999111, train loss: 10.512411, valid precision: 0.878200, valid loss: 86.635112
epoch: 1858, train precision: 0.998889, train loss: 10.582374, valid precision: 0.877200, valid loss: 88.674613
epoch: 1859, train precision: 0.998978, train loss: 10.517874, valid precision: 0.879800, valid loss: 88.226926
epoch: 1860, train precision: 0.999067, train loss: 10.494641, valid precision: 0.878600, valid loss: 86.783454
epoch: 1861, train precision: 0.999267, train loss: 10.404699, valid precision: 0.879000, valid loss: 86.838382
epoch: 1862, train precision: 0.998422, train loss: 10.665794, valid precision: 0.877800, valid loss: 88.059632
epoch: 1863, train precision: 0.999067, train loss: 10.503962, valid precision: 0.875400, valid loss: 90.252794
epoch: 1864, train precision: 0.999022, train loss: 10.486975, valid precision: 0.876600, valid loss: 87.449556
epoch: 1865, train precision: 0.999067, train loss: 10.512257, valid precision: 0.878600, valid loss: 89.464370
epoch: 1866, train precision: 0.998533, train loss: 10.731042, valid precision: 0.872400, valid loss: 92.484312
epoch: 1867, train precision: 0.999000, train loss: 10.543897, valid precision: 0.874000, valid loss: 92.246156
epoch: 1868, train precision: 0.999289, train loss: 10.504432, valid precision: 0.881200, valid loss: 88.880834
epoch: 1869, train precision: 0.998556, train loss: 10.662946, valid precision: 0.878000, valid loss: 89.264343
epoch: 1870, train precision: 0.998911, train loss: 10.547395, valid precision: 0.880200, valid loss: 88.863347
epoch: 1871, train precision: 0.999022, train loss: 10.548912, valid precision: 0.880000, valid loss: 88.285239
epoch: 1872, train precision: 0.998733, train loss: 10.618864, valid precision: 0.876000, valid loss: 89.948120
epoch: 1873, train precision: 0.999111, train loss: 10.505353, valid precision: 0.876800, valid loss: 89.974527
epoch: 1874, train precision: 0.999044, train loss: 10.602695, valid precision: 0.880400, valid loss: 87.349822
epoch: 1875, train precision: 0.998911, train loss: 10.526194, valid precision: 0.877000, valid loss: 90.076556
epoch: 1876, train precision: 0.999089, train loss: 10.473315, valid precision: 0.881000, valid loss: 90.594666
epoch: 1877, train precision: 0.999267, train loss: 10.469803, valid precision: 0.881600, valid loss: 88.438795
epoch: 1878, train precision: 0.998711, train loss: 10.563432, valid precision: 0.882400, valid loss: 90.686440
epoch: 1879, train precision: 0.998911, train loss: 10.539864, valid precision: 0.877800, valid loss: 90.114362
epoch: 1880, train precision: 0.998956, train loss: 10.502158, valid precision: 0.877400, valid loss: 91.928983
epoch: 1881, train precision: 0.998800, train loss: 10.559353, valid precision: 0.881000, valid loss: 92.199872
epoch: 1882, train precision: 0.999067, train loss: 10.570354, valid precision: 0.876800, valid loss: 90.588704
epoch: 1883, train precision: 0.998933, train loss: 10.505394, valid precision: 0.879200, valid loss: 88.763217
epoch: 1884, train precision: 0.999156, train loss: 10.513456, valid precision: 0.878200, valid loss: 88.048552
epoch: 1885, train precision: 0.998956, train loss: 10.545466, valid precision: 0.880200, valid loss: 89.420268
epoch: 1886, train precision: 0.998689, train loss: 10.643910, valid precision: 0.878600, valid loss: 91.477705
epoch: 1887, train precision: 0.999000, train loss: 10.488853, valid precision: 0.877800, valid loss: 91.913194
epoch: 1888, train precision: 0.999022, train loss: 10.510203, valid precision: 0.876400, valid loss: 90.327568
epoch: 1889, train precision: 0.998889, train loss: 10.544182, valid precision: 0.875200, valid loss: 89.961732
epoch: 1890, train precision: 0.999244, train loss: 10.478783, valid precision: 0.876800, valid loss: 88.296737
epoch: 1891, train precision: 0.999067, train loss: 10.487059, valid precision: 0.882400, valid loss: 88.739969
epoch: 1892, train precision: 0.999000, train loss: 10.553759, valid precision: 0.877400, valid loss: 89.402541
epoch: 1893, train precision: 0.998889, train loss: 10.529542, valid precision: 0.880800, valid loss: 87.208382
epoch: 1894, train precision: 0.998822, train loss: 10.573208, valid precision: 0.875200, valid loss: 88.136256
epoch: 1895, train precision: 0.999222, train loss: 10.428363, valid precision: 0.875600, valid loss: 88.425977
epoch: 1896, train precision: 0.999044, train loss: 10.521644, valid precision: 0.876400, valid loss: 87.817432
epoch: 1897, train precision: 0.999200, train loss: 10.486723, valid precision: 0.875600, valid loss: 88.963209
epoch: 1898, train precision: 0.999111, train loss: 10.510686, valid precision: 0.873600, valid loss: 88.074658
epoch: 1899, train precision: 0.998911, train loss: 10.533324, valid precision: 0.875600, valid loss: 90.382508
epoch: 1900, train precision: 0.998889, train loss: 10.571224, valid precision: 0.878200, valid loss: 89.676876
epoch: 1901, train precision: 0.999000, train loss: 10.523775, valid precision: 0.876400, valid loss: 89.699725
epoch: 1902, train precision: 0.999044, train loss: 10.488695, valid precision: 0.878400, valid loss: 89.180094
epoch: 1903, train precision: 0.998911, train loss: 10.468581, valid precision: 0.876400, valid loss: 91.582349
epoch: 1904, train precision: 0.998800, train loss: 10.573034, valid precision: 0.875200, valid loss: 89.805531
epoch: 1905, train precision: 0.998689, train loss: 10.582042, valid precision: 0.875200, valid loss: 89.517829
epoch: 1906, train precision: 0.998578, train loss: 10.649606, valid precision: 0.871800, valid loss: 88.274094
epoch: 1907, train precision: 0.999022, train loss: 10.487905, valid precision: 0.878200, valid loss: 88.099648
epoch: 1908, train precision: 0.998822, train loss: 10.551231, valid precision: 0.875200, valid loss: 89.193994
epoch: 1909, train precision: 0.999000, train loss: 10.520972, valid precision: 0.878400, valid loss: 88.000292
epoch: 1910, train precision: 0.999133, train loss: 10.476623, valid precision: 0.875600, valid loss: 85.783595
epoch: 1911, train precision: 0.999089, train loss: 10.524675, valid precision: 0.878400, valid loss: 85.313181
epoch: 1912, train precision: 0.999000, train loss: 10.539723, valid precision: 0.877400, valid loss: 89.276191
epoch: 1913, train precision: 0.998600, train loss: 10.658093, valid precision: 0.875200, valid loss: 89.322730
epoch: 1914, train precision: 0.999156, train loss: 10.463596, valid precision: 0.879000, valid loss: 87.733635
epoch: 1915, train precision: 0.999022, train loss: 10.526281, valid precision: 0.879800, valid loss: 86.108958
epoch: 1916, train precision: 0.999022, train loss: 10.486065, valid precision: 0.877000, valid loss: 87.222536
epoch: 1917, train precision: 0.998800, train loss: 10.562927, valid precision: 0.876800, valid loss: 88.117101
epoch: 1918, train precision: 0.999089, train loss: 10.441902, valid precision: 0.878400, valid loss: 85.814923
epoch: 1919, train precision: 0.998844, train loss: 10.578513, valid precision: 0.876400, valid loss: 87.198313
epoch: 1920, train precision: 0.998978, train loss: 10.473864, valid precision: 0.878400, valid loss: 85.585949
epoch: 1921, train precision: 0.998822, train loss: 10.557094, valid precision: 0.875400, valid loss: 85.561463
epoch: 1922, train precision: 0.999133, train loss: 10.511812, valid precision: 0.878400, valid loss: 90.097537
epoch: 1923, train precision: 0.999111, train loss: 10.483823, valid precision: 0.877200, valid loss: 89.697325
epoch: 1924, train precision: 0.998644, train loss: 10.617365, valid precision: 0.875000, valid loss: 87.835802
epoch: 1925, train precision: 0.999111, train loss: 10.473334, valid precision: 0.875400, valid loss: 87.418667
epoch: 1926, train precision: 0.999467, train loss: 10.433538, valid precision: 0.874200, valid loss: 87.463595
epoch: 1927, train precision: 0.999178, train loss: 10.449125, valid precision: 0.878400, valid loss: 88.357986
epoch: 1928, train precision: 0.998622, train loss: 10.667139, valid precision: 0.878400, valid loss: 91.071604
epoch: 1929, train precision: 0.999089, train loss: 10.428128, valid precision: 0.877800, valid loss: 87.124089
epoch: 1930, train precision: 0.998889, train loss: 10.541324, valid precision: 0.877400, valid loss: 87.771352
epoch: 1931, train precision: 0.998978, train loss: 10.476606, valid precision: 0.877400, valid loss: 87.349920
epoch: 1932, train precision: 0.998378, train loss: 10.636935, valid precision: 0.877200, valid loss: 86.373947
epoch: 1933, train precision: 0.999044, train loss: 10.469550, valid precision: 0.876000, valid loss: 88.139858
epoch: 1934, train precision: 0.999022, train loss: 10.604987, valid precision: 0.875200, valid loss: 90.011163
epoch: 1935, train precision: 0.998556, train loss: 10.715396, valid precision: 0.877400, valid loss: 88.313914
epoch: 1936, train precision: 0.998800, train loss: 10.587667, valid precision: 0.874000, valid loss: 87.791749
epoch: 1937, train precision: 0.998689, train loss: 10.621133, valid precision: 0.878000, valid loss: 87.385740
epoch: 1938, train precision: 0.999067, train loss: 10.431611, valid precision: 0.881200, valid loss: 86.384222
epoch: 1939, train precision: 0.998933, train loss: 10.484337, valid precision: 0.880600, valid loss: 86.933492
epoch: 1940, train precision: 0.998733, train loss: 10.658084, valid precision: 0.875200, valid loss: 88.265863
epoch: 1941, train precision: 0.998511, train loss: 10.696412, valid precision: 0.875800, valid loss: 88.049211
epoch: 1942, train precision: 0.999022, train loss: 10.473991, valid precision: 0.880600, valid loss: 87.382794
epoch: 1943, train precision: 0.999067, train loss: 10.511539, valid precision: 0.878000, valid loss: 87.654127
epoch: 1944, train precision: 0.999089, train loss: 10.467523, valid precision: 0.876400, valid loss: 90.289156
epoch: 1945, train precision: 0.998733, train loss: 10.568210, valid precision: 0.877000, valid loss: 89.273733
epoch: 1946, train precision: 0.999156, train loss: 10.452594, valid precision: 0.873200, valid loss: 88.053258
epoch: 1947, train precision: 0.999289, train loss: 10.422964, valid precision: 0.879200, valid loss: 88.366997
epoch: 1948, train precision: 0.998978, train loss: 10.519188, valid precision: 0.876000, valid loss: 90.714712
epoch: 1949, train precision: 0.999022, train loss: 10.455669, valid precision: 0.878600, valid loss: 86.975268
epoch: 1950, train precision: 0.998978, train loss: 10.501392, valid precision: 0.875600, valid loss: 89.451019
epoch: 1951, train precision: 0.999000, train loss: 10.533952, valid precision: 0.876600, valid loss: 90.078790
epoch: 1952, train precision: 0.999200, train loss: 10.423951, valid precision: 0.875800, valid loss: 90.261311
epoch: 1953, train precision: 0.998911, train loss: 10.496054, valid precision: 0.873400, valid loss: 90.037444
epoch: 1954, train precision: 0.999044, train loss: 10.511198, valid precision: 0.876800, valid loss: 87.913445
epoch: 1955, train precision: 0.998956, train loss: 10.451402, valid precision: 0.877600, valid loss: 86.398564
epoch: 1956, train precision: 0.999067, train loss: 10.463996, valid precision: 0.878000, valid loss: 89.117605
epoch: 1957, train precision: 0.998889, train loss: 10.517971, valid precision: 0.877800, valid loss: 89.120810
epoch: 1958, train precision: 0.998844, train loss: 10.514578, valid precision: 0.876800, valid loss: 89.759795
epoch: 1959, train precision: 0.998711, train loss: 10.520410, valid precision: 0.877200, valid loss: 90.003022
epoch: 1960, train precision: 0.998644, train loss: 10.597478, valid precision: 0.871000, valid loss: 93.293600
epoch: 1961, train precision: 0.999000, train loss: 10.503171, valid precision: 0.874200, valid loss: 89.507067
epoch: 1962, train precision: 0.998622, train loss: 10.592514, valid precision: 0.872400, valid loss: 90.635452
epoch: 1963, train precision: 0.999111, train loss: 10.465423, valid precision: 0.879400, valid loss: 87.497120
epoch: 1964, train precision: 0.999000, train loss: 10.411046, valid precision: 0.875600, valid loss: 88.238109
epoch: 1965, train precision: 0.998622, train loss: 10.532599, valid precision: 0.874200, valid loss: 91.781675
epoch: 1966, train precision: 0.999022, train loss: 10.566516, valid precision: 0.877600, valid loss: 89.392332
epoch: 1967, train precision: 0.998711, train loss: 10.563528, valid precision: 0.878400, valid loss: 88.669884
epoch: 1968, train precision: 0.998956, train loss: 10.549288, valid precision: 0.877400, valid loss: 89.510806
epoch: 1969, train precision: 0.999000, train loss: 10.502060, valid precision: 0.871800, valid loss: 88.786839
epoch: 1970, train precision: 0.998933, train loss: 10.539018, valid precision: 0.876400, valid loss: 89.677143
epoch: 1971, train precision: 0.999044, train loss: 10.461743, valid precision: 0.877200, valid loss: 87.866766
epoch: 1972, train precision: 0.998867, train loss: 10.520357, valid precision: 0.881200, valid loss: 88.230003
epoch: 1973, train precision: 0.998689, train loss: 10.559960, valid precision: 0.879200, valid loss: 87.960312
epoch: 1974, train precision: 0.999000, train loss: 10.474358, valid precision: 0.878400, valid loss: 88.420484
epoch: 1975, train precision: 0.998733, train loss: 10.596386, valid precision: 0.874200, valid loss: 89.356880
epoch: 1976, train precision: 0.999333, train loss: 10.396801, valid precision: 0.878800, valid loss: 87.395983
epoch: 1977, train precision: 0.999067, train loss: 10.506738, valid precision: 0.875800, valid loss: 86.706397
epoch: 1978, train precision: 0.999133, train loss: 10.425955, valid precision: 0.876200, valid loss: 88.505191
epoch: 1979, train precision: 0.999178, train loss: 10.425686, valid precision: 0.879200, valid loss: 87.364777
epoch: 1980, train precision: 0.999244, train loss: 10.442031, valid precision: 0.876400, valid loss: 87.852329
epoch: 1981, train precision: 0.998956, train loss: 10.511136, valid precision: 0.875600, valid loss: 88.219510
epoch: 1982, train precision: 0.999067, train loss: 10.495533, valid precision: 0.879200, valid loss: 87.001088
epoch: 1983, train precision: 0.998889, train loss: 10.501307, valid precision: 0.877000, valid loss: 87.447526
epoch: 1984, train precision: 0.999111, train loss: 10.480578, valid precision: 0.872200, valid loss: 90.929384
epoch: 1985, train precision: 0.998800, train loss: 10.552269, valid precision: 0.873800, valid loss: 90.621521
epoch: 1986, train precision: 0.999400, train loss: 10.358379, valid precision: 0.879000, valid loss: 90.986471
epoch: 1987, train precision: 0.999089, train loss: 10.492769, valid precision: 0.879600, valid loss: 90.074442
epoch: 1988, train precision: 0.998733, train loss: 10.531738, valid precision: 0.874600, valid loss: 89.860899
epoch: 1989, train precision: 0.999044, train loss: 10.404757, valid precision: 0.879400, valid loss: 88.454185
epoch: 1990, train precision: 0.999044, train loss: 10.474528, valid precision: 0.877000, valid loss: 89.609573
epoch: 1991, train precision: 0.998800, train loss: 10.553864, valid precision: 0.872600, valid loss: 92.242315
epoch: 1992, train precision: 0.999289, train loss: 10.401671, valid precision: 0.872800, valid loss: 88.918354
epoch: 1993, train precision: 0.998889, train loss: 10.509880, valid precision: 0.878000, valid loss: 88.865142
epoch: 1994, train precision: 0.999356, train loss: 10.391576, valid precision: 0.877400, valid loss: 86.131968
epoch: 1995, train precision: 0.998889, train loss: 10.470891, valid precision: 0.876400, valid loss: 88.557499
epoch: 1996, train precision: 0.999267, train loss: 10.405651, valid precision: 0.877000, valid loss: 88.467322
epoch: 1997, train precision: 0.998644, train loss: 10.671437, valid precision: 0.875400, valid loss: 88.756814
epoch: 1998, train precision: 0.999222, train loss: 10.425719, valid precision: 0.879200, valid loss: 87.018867
epoch: 1999, train precision: 0.998844, train loss: 10.571248, valid precision: 0.878600, valid loss: 87.500293
epoch: 2000, train precision: 0.998778, train loss: 10.552527, valid precision: 0.872800, valid loss: 89.366719
epoch: 2001, train precision: 0.998978, train loss: 10.477848, valid precision: 0.875400, valid loss: 88.139234
epoch: 2002, train precision: 0.999333, train loss: 10.424804, valid precision: 0.877400, valid loss: 88.534865
epoch: 2003, train precision: 0.998844, train loss: 10.524928, valid precision: 0.876400, valid loss: 86.831385
epoch: 2004, train precision: 0.999222, train loss: 10.454611, valid precision: 0.881600, valid loss: 86.551848
epoch: 2005, train precision: 0.998644, train loss: 10.548984, valid precision: 0.880600, valid loss: 85.465306
epoch: 2006, train precision: 0.999067, train loss: 10.456695, valid precision: 0.879600, valid loss: 87.144680
epoch: 2007, train precision: 0.999000, train loss: 10.508536, valid precision: 0.879000, valid loss: 87.661007
epoch: 2008, train precision: 0.998822, train loss: 10.530181, valid precision: 0.878600, valid loss: 87.007613
epoch: 2009, train precision: 0.998933, train loss: 10.523669, valid precision: 0.878600, valid loss: 86.989436
epoch: 2010, train precision: 0.999178, train loss: 10.408775, valid precision: 0.878800, valid loss: 87.228380
epoch: 2011, train precision: 0.998978, train loss: 10.460979, valid precision: 0.881800, valid loss: 88.835153
epoch: 2012, train precision: 0.999022, train loss: 10.477716, valid precision: 0.879400, valid loss: 88.880185
epoch: 2013, train precision: 0.999089, train loss: 10.457263, valid precision: 0.877200, valid loss: 88.024944
epoch: 2014, train precision: 0.999222, train loss: 10.357201, valid precision: 0.877200, valid loss: 89.142075
epoch: 2015, train precision: 0.999111, train loss: 10.391008, valid precision: 0.877000, valid loss: 89.106245
epoch: 2016, train precision: 0.998733, train loss: 10.524354, valid precision: 0.880400, valid loss: 90.040041
epoch: 2017, train precision: 0.999200, train loss: 10.375167, valid precision: 0.881400, valid loss: 88.796773
epoch: 2018, train precision: 0.999000, train loss: 10.483902, valid precision: 0.878200, valid loss: 91.058098
epoch: 2019, train precision: 0.998400, train loss: 10.681624, valid precision: 0.877200, valid loss: 88.635268
epoch: 2020, train precision: 0.999000, train loss: 10.547992, valid precision: 0.878600, valid loss: 88.417845
epoch: 2021, train precision: 0.998956, train loss: 10.532024, valid precision: 0.876400, valid loss: 87.964649
epoch: 2022, train precision: 0.999111, train loss: 10.519954, valid precision: 0.880000, valid loss: 87.030348
epoch: 2023, train precision: 0.998933, train loss: 10.509804, valid precision: 0.879800, valid loss: 88.072779
epoch: 2024, train precision: 0.999022, train loss: 10.485844, valid precision: 0.877200, valid loss: 87.552619
epoch: 2025, train precision: 0.999244, train loss: 10.406054, valid precision: 0.880000, valid loss: 87.405171
epoch: 2026, train precision: 0.998867, train loss: 10.475964, valid precision: 0.883000, valid loss: 86.440435
epoch: 2027, train precision: 0.999244, train loss: 10.403055, valid precision: 0.879600, valid loss: 86.782885
epoch: 2028, train precision: 0.999000, train loss: 10.467656, valid precision: 0.878400, valid loss: 87.351962
epoch: 2029, train precision: 0.998711, train loss: 10.561573, valid precision: 0.881000, valid loss: 86.357592
epoch: 2030, train precision: 0.999067, train loss: 10.459509, valid precision: 0.881200, valid loss: 87.118917
epoch: 2031, train precision: 0.999156, train loss: 10.475757, valid precision: 0.877200, valid loss: 89.609482
epoch: 2032, train precision: 0.998889, train loss: 10.508929, valid precision: 0.877200, valid loss: 89.736813
epoch: 2033, train precision: 0.998711, train loss: 10.600292, valid precision: 0.878200, valid loss: 92.275578
epoch: 2034, train precision: 0.999222, train loss: 10.451114, valid precision: 0.873600, valid loss: 93.161446
epoch: 2035, train precision: 0.999111, train loss: 10.469666, valid precision: 0.877800, valid loss: 90.461255
epoch: 2036, train precision: 0.999089, train loss: 10.437570, valid precision: 0.878200, valid loss: 90.247867
epoch: 2037, train precision: 0.998978, train loss: 10.516615, valid precision: 0.877000, valid loss: 91.127514
epoch: 2038, train precision: 0.998956, train loss: 10.514597, valid precision: 0.875200, valid loss: 93.176782
epoch: 2039, train precision: 0.998667, train loss: 10.595262, valid precision: 0.876800, valid loss: 94.995769
epoch: 2040, train precision: 0.998489, train loss: 10.659339, valid precision: 0.877400, valid loss: 93.626760
epoch: 2041, train precision: 0.998867, train loss: 10.538729, valid precision: 0.880000, valid loss: 88.931405
epoch: 2042, train precision: 0.998867, train loss: 10.478559, valid precision: 0.881400, valid loss: 89.538365
epoch: 2043, train precision: 0.999133, train loss: 10.437747, valid precision: 0.878400, valid loss: 88.530703
epoch: 2044, train precision: 0.999044, train loss: 10.464181, valid precision: 0.879400, valid loss: 89.340153
epoch: 2045, train precision: 0.999133, train loss: 10.456964, valid precision: 0.876400, valid loss: 93.022405
epoch: 2046, train precision: 0.998578, train loss: 10.587849, valid precision: 0.877000, valid loss: 92.313489
epoch: 2047, train precision: 0.999222, train loss: 10.376461, valid precision: 0.878600, valid loss: 91.651071
epoch: 2048, train precision: 0.999111, train loss: 10.466101, valid precision: 0.878400, valid loss: 88.700491
epoch: 2049, train precision: 0.999044, train loss: 10.485591, valid precision: 0.878800, valid loss: 87.953153
epoch: 2050, train precision: 0.998867, train loss: 10.536699, valid precision: 0.881400, valid loss: 88.560662
epoch: 2051, train precision: 0.998378, train loss: 10.676341, valid precision: 0.875000, valid loss: 90.543433
epoch: 2052, train precision: 0.999000, train loss: 10.471234, valid precision: 0.882200, valid loss: 88.111773
epoch: 2053, train precision: 0.998978, train loss: 10.526706, valid precision: 0.877000, valid loss: 89.090562
epoch: 2054, train precision: 0.999156, train loss: 10.410000, valid precision: 0.878000, valid loss: 88.581746
epoch: 2055, train precision: 0.999289, train loss: 10.359988, valid precision: 0.876200, valid loss: 91.420584
epoch: 2056, train precision: 0.998956, train loss: 10.476714, valid precision: 0.876800, valid loss: 91.618643
epoch: 2057, train precision: 0.998822, train loss: 10.533810, valid precision: 0.875800, valid loss: 89.635905
epoch: 2058, train precision: 0.999111, train loss: 10.476405, valid precision: 0.873200, valid loss: 90.116534
epoch: 2059, train precision: 0.999133, train loss: 10.491548, valid precision: 0.877800, valid loss: 88.808423
epoch: 2060, train precision: 0.999222, train loss: 10.441678, valid precision: 0.880000, valid loss: 88.419503
epoch: 2061, train precision: 0.999267, train loss: 10.438537, valid precision: 0.881400, valid loss: 87.306117
epoch: 2062, train precision: 0.999178, train loss: 10.388773, valid precision: 0.881000, valid loss: 85.880832
epoch: 2063, train precision: 0.999178, train loss: 10.414863, valid precision: 0.882200, valid loss: 88.450200
epoch: 2064, train precision: 0.999000, train loss: 10.467344, valid precision: 0.880400, valid loss: 86.842654
epoch: 2065, train precision: 0.998800, train loss: 10.580293, valid precision: 0.877800, valid loss: 88.980468
epoch: 2066, train precision: 0.998956, train loss: 10.451046, valid precision: 0.878800, valid loss: 87.759298
epoch: 2067, train precision: 0.999111, train loss: 10.432699, valid precision: 0.876200, valid loss: 86.602330
epoch: 2068, train precision: 0.999000, train loss: 10.509983, valid precision: 0.874800, valid loss: 87.758364
epoch: 2069, train precision: 0.998444, train loss: 10.639266, valid precision: 0.876600, valid loss: 87.894894
epoch: 2070, train precision: 0.999000, train loss: 10.460932, valid precision: 0.880400, valid loss: 85.676658
epoch: 2071, train precision: 0.998978, train loss: 10.490657, valid precision: 0.878000, valid loss: 86.944429
epoch: 2072, train precision: 0.998756, train loss: 10.623771, valid precision: 0.877000, valid loss: 88.583440
epoch: 2073, train precision: 0.999022, train loss: 10.455021, valid precision: 0.876200, valid loss: 88.332821
epoch: 2074, train precision: 0.998933, train loss: 10.498161, valid precision: 0.874400, valid loss: 88.410291
epoch: 2075, train precision: 0.998756, train loss: 10.553860, valid precision: 0.875000, valid loss: 88.945707
epoch: 2076, train precision: 0.999111, train loss: 10.474220, valid precision: 0.880600, valid loss: 87.497392
epoch: 2077, train precision: 0.999133, train loss: 10.442036, valid precision: 0.878000, valid loss: 88.460604
epoch: 2078, train precision: 0.999089, train loss: 10.473651, valid precision: 0.878600, valid loss: 85.435695
epoch: 2079, train precision: 0.998956, train loss: 10.540512, valid precision: 0.877000, valid loss: 88.918829
epoch: 2080, train precision: 0.999356, train loss: 10.326038, valid precision: 0.877800, valid loss: 85.582603
epoch: 2081, train precision: 0.998667, train loss: 10.580394, valid precision: 0.878600, valid loss: 88.794146
epoch: 2082, train precision: 0.999156, train loss: 10.436896, valid precision: 0.883600, valid loss: 86.562520
epoch: 2083, train precision: 0.998889, train loss: 10.489232, valid precision: 0.879600, valid loss: 86.991929
epoch: 2084, train precision: 0.998756, train loss: 10.497970, valid precision: 0.877600, valid loss: 85.491923
epoch: 2085, train precision: 0.999089, train loss: 10.450821, valid precision: 0.876000, valid loss: 88.866656
epoch: 2086, train precision: 0.999022, train loss: 10.513257, valid precision: 0.876600, valid loss: 85.598114
epoch: 2087, train precision: 0.998911, train loss: 10.510902, valid precision: 0.876800, valid loss: 88.546460
epoch: 2088, train precision: 0.999156, train loss: 10.450439, valid precision: 0.876600, valid loss: 88.482416
epoch: 2089, train precision: 0.998844, train loss: 10.552508, valid precision: 0.874400, valid loss: 87.457177
epoch: 2090, train precision: 0.999022, train loss: 10.464964, valid precision: 0.877400, valid loss: 86.906755
epoch: 2091, train precision: 0.998778, train loss: 10.555484, valid precision: 0.874000, valid loss: 87.913865
epoch: 2092, train precision: 0.999067, train loss: 10.452915, valid precision: 0.875600, valid loss: 86.963584
epoch: 2093, train precision: 0.998956, train loss: 10.436064, valid precision: 0.875400, valid loss: 87.459513
epoch: 2094, train precision: 0.998978, train loss: 10.448778, valid precision: 0.876000, valid loss: 87.211164
epoch: 2095, train precision: 0.998978, train loss: 10.472236, valid precision: 0.876000, valid loss: 87.157334
epoch: 2096, train precision: 0.999111, train loss: 10.453170, valid precision: 0.879200, valid loss: 86.266852
epoch: 2097, train precision: 0.999356, train loss: 10.402571, valid precision: 0.878800, valid loss: 84.313963
epoch: 2098, train precision: 0.998800, train loss: 10.509933, valid precision: 0.877400, valid loss: 88.734202
epoch: 2099, train precision: 0.998800, train loss: 10.546470, valid precision: 0.876200, valid loss: 88.306492
epoch: 2100, train precision: 0.998889, train loss: 10.545099, valid precision: 0.879600, valid loss: 90.010821
epoch: 2101, train precision: 0.998756, train loss: 10.508694, valid precision: 0.878600, valid loss: 90.938625
epoch: 2102, train precision: 0.998556, train loss: 10.582319, valid precision: 0.875600, valid loss: 89.908972
epoch: 2103, train precision: 0.999000, train loss: 10.486577, valid precision: 0.875400, valid loss: 90.783402
epoch: 2104, train precision: 0.998911, train loss: 10.519591, valid precision: 0.872600, valid loss: 90.862240
epoch: 2105, train precision: 0.999067, train loss: 10.435563, valid precision: 0.875800, valid loss: 87.772749
epoch: 2106, train precision: 0.999156, train loss: 10.456502, valid precision: 0.873800, valid loss: 89.757522
epoch: 2107, train precision: 0.999111, train loss: 10.540976, valid precision: 0.877000, valid loss: 89.956594
epoch: 2108, train precision: 0.999356, train loss: 10.354510, valid precision: 0.876800, valid loss: 89.142552
epoch: 2109, train precision: 0.999000, train loss: 10.453968, valid precision: 0.878000, valid loss: 87.791954
epoch: 2110, train precision: 0.999000, train loss: 10.518196, valid precision: 0.876000, valid loss: 88.358338
epoch: 2111, train precision: 0.999044, train loss: 10.443229, valid precision: 0.879000, valid loss: 87.924883
epoch: 2112, train precision: 0.999000, train loss: 10.424421, valid precision: 0.873800, valid loss: 89.605335
epoch: 2113, train precision: 0.998511, train loss: 10.701297, valid precision: 0.880000, valid loss: 85.227831
epoch: 2114, train precision: 0.999133, train loss: 10.466361, valid precision: 0.875800, valid loss: 88.556457
epoch: 2115, train precision: 0.998622, train loss: 10.584536, valid precision: 0.877600, valid loss: 87.156823
epoch: 2116, train precision: 0.998822, train loss: 10.491911, valid precision: 0.878400, valid loss: 85.538858
epoch: 2117, train precision: 0.999156, train loss: 10.433489, valid precision: 0.882600, valid loss: 84.401772
epoch: 2118, train precision: 0.998978, train loss: 10.443691, valid precision: 0.880200, valid loss: 86.973519
epoch: 2119, train precision: 0.998867, train loss: 10.572692, valid precision: 0.877000, valid loss: 88.834125
epoch: 2120, train precision: 0.999111, train loss: 10.420329, valid precision: 0.879600, valid loss: 90.803019
epoch: 2121, train precision: 0.999044, train loss: 10.410590, valid precision: 0.877400, valid loss: 88.429700
epoch: 2122, train precision: 0.999333, train loss: 10.387146, valid precision: 0.877200, valid loss: 88.556397
epoch: 2123, train precision: 0.998733, train loss: 10.541675, valid precision: 0.874400, valid loss: 91.025563
epoch: 2124, train precision: 0.999178, train loss: 10.408118, valid precision: 0.877200, valid loss: 88.657961
epoch: 2125, train precision: 0.998756, train loss: 10.540936, valid precision: 0.877600, valid loss: 88.499632
epoch: 2126, train precision: 0.998444, train loss: 10.621523, valid precision: 0.879800, valid loss: 86.836688
epoch: 2127, train precision: 0.999044, train loss: 10.486880, valid precision: 0.876200, valid loss: 86.935639
epoch: 2128, train precision: 0.998733, train loss: 10.522253, valid precision: 0.880200, valid loss: 88.253963
epoch: 2129, train precision: 0.999222, train loss: 10.410370, valid precision: 0.879400, valid loss: 87.195810
epoch: 2130, train precision: 0.999200, train loss: 10.418110, valid precision: 0.877200, valid loss: 86.212873
epoch: 2131, train precision: 0.998533, train loss: 10.551590, valid precision: 0.877600, valid loss: 88.865358
epoch: 2132, train precision: 0.999400, train loss: 10.332059, valid precision: 0.879600, valid loss: 86.994753
epoch: 2133, train precision: 0.998667, train loss: 10.609730, valid precision: 0.878200, valid loss: 88.435554
epoch: 2134, train precision: 0.998911, train loss: 10.512940, valid precision: 0.878800, valid loss: 88.982022
epoch: 2135, train precision: 0.998911, train loss: 10.498840, valid precision: 0.880800, valid loss: 87.664691
epoch: 2136, train precision: 0.999200, train loss: 10.442294, valid precision: 0.879600, valid loss: 87.417819
epoch: 2137, train precision: 0.998600, train loss: 10.537246, valid precision: 0.876000, valid loss: 87.741605
epoch: 2138, train precision: 0.998956, train loss: 10.477817, valid precision: 0.878600, valid loss: 86.236123
epoch: 2139, train precision: 0.999067, train loss: 10.456712, valid precision: 0.876600, valid loss: 88.490665
epoch: 2140, train precision: 0.998956, train loss: 10.483838, valid precision: 0.882400, valid loss: 87.421553
epoch: 2141, train precision: 0.998622, train loss: 10.538096, valid precision: 0.879400, valid loss: 86.860493
epoch: 2142, train precision: 0.998889, train loss: 10.487783, valid precision: 0.878000, valid loss: 87.129968
epoch: 2143, train precision: 0.998667, train loss: 10.561077, valid precision: 0.877200, valid loss: 87.178745
epoch: 2144, train precision: 0.999000, train loss: 10.454241, valid precision: 0.874000, valid loss: 86.433188
epoch: 2145, train precision: 0.998844, train loss: 10.530014, valid precision: 0.877400, valid loss: 86.208829
epoch: 2146, train precision: 0.999000, train loss: 10.479363, valid precision: 0.876200, valid loss: 86.852779
epoch: 2147, train precision: 0.998889, train loss: 10.546607, valid precision: 0.878400, valid loss: 89.432121
epoch: 2148, train precision: 0.998778, train loss: 10.500804, valid precision: 0.877600, valid loss: 87.871235
epoch: 2149, train precision: 0.998600, train loss: 10.582715, valid precision: 0.873000, valid loss: 88.508991
epoch: 2150, train precision: 0.998978, train loss: 10.416453, valid precision: 0.877600, valid loss: 89.761174
epoch: 2151, train precision: 0.998511, train loss: 10.619389, valid precision: 0.877600, valid loss: 90.479330
epoch: 2152, train precision: 0.998756, train loss: 10.515256, valid precision: 0.877200, valid loss: 89.125931
epoch: 2153, train precision: 0.999067, train loss: 10.468912, valid precision: 0.877000, valid loss: 89.137368
epoch: 2154, train precision: 0.999089, train loss: 10.437051, valid precision: 0.874400, valid loss: 87.293660
epoch: 2155, train precision: 0.999244, train loss: 10.470478, valid precision: 0.877400, valid loss: 89.507200
epoch: 2156, train precision: 0.999089, train loss: 10.397259, valid precision: 0.879000, valid loss: 89.759459
epoch: 2157, train precision: 0.998644, train loss: 10.573086, valid precision: 0.877200, valid loss: 89.435000
epoch: 2158, train precision: 0.999178, train loss: 10.389018, valid precision: 0.876000, valid loss: 90.078190
epoch: 2159, train precision: 0.998711, train loss: 10.547748, valid precision: 0.878200, valid loss: 88.617117
epoch: 2160, train precision: 0.999089, train loss: 10.431594, valid precision: 0.875800, valid loss: 90.463586
epoch: 2161, train precision: 0.998689, train loss: 10.536307, valid precision: 0.875000, valid loss: 91.897700
epoch: 2162, train precision: 0.999133, train loss: 10.468054, valid precision: 0.875400, valid loss: 89.689349
epoch: 2163, train precision: 0.998978, train loss: 10.394023, valid precision: 0.878400, valid loss: 88.303661
epoch: 2164, train precision: 0.999222, train loss: 10.380825, valid precision: 0.882800, valid loss: 86.533398
epoch: 2165, train precision: 0.998756, train loss: 10.454496, valid precision: 0.877400, valid loss: 90.296828
epoch: 2166, train precision: 0.999222, train loss: 10.380772, valid precision: 0.872800, valid loss: 89.918082
epoch: 2167, train precision: 0.999067, train loss: 10.463735, valid precision: 0.875200, valid loss: 89.266669
epoch: 2168, train precision: 0.999044, train loss: 10.412870, valid precision: 0.877400, valid loss: 91.763935
epoch: 2169, train precision: 0.999111, train loss: 10.395626, valid precision: 0.875800, valid loss: 90.774576
epoch: 2170, train precision: 0.999156, train loss: 10.403445, valid precision: 0.877000, valid loss: 90.613738
epoch: 2171, train precision: 0.998956, train loss: 10.502988, valid precision: 0.873800, valid loss: 93.122434
epoch: 2172, train precision: 0.998778, train loss: 10.560434, valid precision: 0.877800, valid loss: 90.875839
epoch: 2173, train precision: 0.998956, train loss: 10.428696, valid precision: 0.877400, valid loss: 88.855490
epoch: 2174, train precision: 0.999111, train loss: 10.449965, valid precision: 0.881200, valid loss: 88.788261
epoch: 2175, train precision: 0.998911, train loss: 10.491125, valid precision: 0.877000, valid loss: 87.397890
epoch: 2176, train precision: 0.999244, train loss: 10.414573, valid precision: 0.874600, valid loss: 89.627063
epoch: 2177, train precision: 0.999089, train loss: 10.461107, valid precision: 0.881400, valid loss: 87.819756
epoch: 2178, train precision: 0.998778, train loss: 10.505002, valid precision: 0.876000, valid loss: 88.982221
epoch: 2179, train precision: 0.999022, train loss: 10.503983, valid precision: 0.878800, valid loss: 87.192478
epoch: 2180, train precision: 0.998822, train loss: 10.475254, valid precision: 0.879000, valid loss: 89.653342
epoch: 2181, train precision: 0.999244, train loss: 10.369472, valid precision: 0.877800, valid loss: 89.009950
epoch: 2182, train precision: 0.998844, train loss: 10.460323, valid precision: 0.876800, valid loss: 89.704360
epoch: 2183, train precision: 0.998933, train loss: 10.481497, valid precision: 0.875200, valid loss: 90.544084
epoch: 2184, train precision: 0.998956, train loss: 10.445984, valid precision: 0.880800, valid loss: 88.880556
epoch: 2185, train precision: 0.999178, train loss: 10.414597, valid precision: 0.878800, valid loss: 87.021350
epoch: 2186, train precision: 0.998822, train loss: 10.440601, valid precision: 0.878200, valid loss: 88.292777
epoch: 2187, train precision: 0.999133, train loss: 10.383516, valid precision: 0.880000, valid loss: 86.781880
epoch: 2188, train precision: 0.998822, train loss: 10.476207, valid precision: 0.880200, valid loss: 86.492984
epoch: 2189, train precision: 0.998711, train loss: 10.508121, valid precision: 0.884400, valid loss: 87.832983
epoch: 2190, train precision: 0.998911, train loss: 10.492702, valid precision: 0.879000, valid loss: 87.389077
epoch: 2191, train precision: 0.998467, train loss: 10.540963, valid precision: 0.876800, valid loss: 89.947483
epoch: 2192, train precision: 0.999156, train loss: 10.389785, valid precision: 0.880600, valid loss: 85.460244
epoch: 2193, train precision: 0.998778, train loss: 10.506090, valid precision: 0.876600, valid loss: 89.370781
epoch: 2194, train precision: 0.999311, train loss: 10.361713, valid precision: 0.873200, valid loss: 89.802253
epoch: 2195, train precision: 0.999222, train loss: 10.358570, valid precision: 0.879600, valid loss: 87.753918
epoch: 2196, train precision: 0.999089, train loss: 10.464298, valid precision: 0.876200, valid loss: 87.652762
epoch: 2197, train precision: 0.998756, train loss: 10.549359, valid precision: 0.875200, valid loss: 88.826471
epoch: 2198, train precision: 0.998911, train loss: 10.440547, valid precision: 0.876800, valid loss: 89.104989
epoch: 2199, train precision: 0.999267, train loss: 10.413160, valid precision: 0.876400, valid loss: 86.506624
epoch: 2200, train precision: 0.999289, train loss: 10.309608, valid precision: 0.877600, valid loss: 87.817455
epoch: 2201, train precision: 0.999200, train loss: 10.388378, valid precision: 0.880000, valid loss: 88.209234
epoch: 2202, train precision: 0.999022, train loss: 10.421569, valid precision: 0.876600, valid loss: 86.495281
epoch: 2203, train precision: 0.999178, train loss: 10.385067, valid precision: 0.876000, valid loss: 88.122590
epoch: 2204, train precision: 0.999067, train loss: 10.422760, valid precision: 0.873800, valid loss: 90.083946
epoch: 2205, train precision: 0.998711, train loss: 10.538400, valid precision: 0.878400, valid loss: 89.338141
epoch: 2206, train precision: 0.998333, train loss: 10.626015, valid precision: 0.873400, valid loss: 91.175448
epoch: 2207, train precision: 0.999400, train loss: 10.360468, valid precision: 0.877400, valid loss: 85.770196
epoch: 2208, train precision: 0.998933, train loss: 10.427207, valid precision: 0.879200, valid loss: 85.843345
epoch: 2209, train precision: 0.998733, train loss: 10.572177, valid precision: 0.879400, valid loss: 87.393035
epoch: 2210, train precision: 0.998956, train loss: 10.427151, valid precision: 0.877600, valid loss: 88.630888
epoch: 2211, train precision: 0.999022, train loss: 10.395976, valid precision: 0.878000, valid loss: 87.121303
epoch: 2212, train precision: 0.999311, train loss: 10.338722, valid precision: 0.878400, valid loss: 89.429189
epoch: 2213, train precision: 0.999089, train loss: 10.415271, valid precision: 0.877000, valid loss: 89.521249
epoch: 2214, train precision: 0.998556, train loss: 10.549561, valid precision: 0.874600, valid loss: 89.275832
epoch: 2215, train precision: 0.998867, train loss: 10.429429, valid precision: 0.879800, valid loss: 90.134854
epoch: 2216, train precision: 0.999111, train loss: 10.380272, valid precision: 0.879800, valid loss: 89.000557
epoch: 2217, train precision: 0.999000, train loss: 10.469205, valid precision: 0.878000, valid loss: 89.471738
epoch: 2218, train precision: 0.999111, train loss: 10.373648, valid precision: 0.876000, valid loss: 87.816435
epoch: 2219, train precision: 0.999067, train loss: 10.380194, valid precision: 0.879200, valid loss: 87.868355
epoch: 2220, train precision: 0.999133, train loss: 10.434366, valid precision: 0.879400, valid loss: 88.399119
epoch: 2221, train precision: 0.998933, train loss: 10.455452, valid precision: 0.874400, valid loss: 90.827170
epoch: 2222, train precision: 0.998911, train loss: 10.443939, valid precision: 0.876800, valid loss: 87.212210
epoch: 2223, train precision: 0.998400, train loss: 10.595457, valid precision: 0.881000, valid loss: 87.813627
epoch: 2224, train precision: 0.999244, train loss: 10.373070, valid precision: 0.879800, valid loss: 86.245063
epoch: 2225, train precision: 0.999222, train loss: 10.368328, valid precision: 0.878800, valid loss: 86.233582
epoch: 2226, train precision: 0.999044, train loss: 10.389878, valid precision: 0.875800, valid loss: 87.806244
epoch: 2227, train precision: 0.998956, train loss: 10.505717, valid precision: 0.880000, valid loss: 88.824977
epoch: 2228, train precision: 0.999378, train loss: 10.286167, valid precision: 0.879400, valid loss: 87.911049
epoch: 2229, train precision: 0.998978, train loss: 10.413833, valid precision: 0.878800, valid loss: 88.007550
epoch: 2230, train precision: 0.998778, train loss: 10.521428, valid precision: 0.878800, valid loss: 90.018319
epoch: 2231, train precision: 0.999044, train loss: 10.442679, valid precision: 0.876400, valid loss: 87.430013
epoch: 2232, train precision: 0.999067, train loss: 10.403480, valid precision: 0.880200, valid loss: 88.068586
epoch: 2233, train precision: 0.998778, train loss: 10.471740, valid precision: 0.876200, valid loss: 90.627357
epoch: 2234, train precision: 0.999333, train loss: 10.317260, valid precision: 0.879600, valid loss: 88.982604
epoch: 2235, train precision: 0.999000, train loss: 10.456644, valid precision: 0.880800, valid loss: 90.139489
epoch: 2236, train precision: 0.998889, train loss: 10.509307, valid precision: 0.879200, valid loss: 88.419193
epoch: 2237, train precision: 0.999178, train loss: 10.420595, valid precision: 0.880600, valid loss: 87.118711
epoch: 2238, train precision: 0.998622, train loss: 10.564465, valid precision: 0.876000, valid loss: 89.747235
epoch: 2239, train precision: 0.999000, train loss: 10.543348, valid precision: 0.874400, valid loss: 88.818794
epoch: 2240, train precision: 0.998733, train loss: 10.505808, valid precision: 0.877000, valid loss: 91.706028
epoch: 2241, train precision: 0.998911, train loss: 10.503741, valid precision: 0.875200, valid loss: 88.306296
epoch: 2242, train precision: 0.999244, train loss: 10.327909, valid precision: 0.878600, valid loss: 88.518995
epoch: 2243, train precision: 0.998778, train loss: 10.482483, valid precision: 0.879000, valid loss: 88.910964
epoch: 2244, train precision: 0.998867, train loss: 10.451017, valid precision: 0.873200, valid loss: 90.143383
epoch: 2245, train precision: 0.998778, train loss: 10.459529, valid precision: 0.877200, valid loss: 87.778156
epoch: 2246, train precision: 0.998956, train loss: 10.439417, valid precision: 0.878200, valid loss: 90.659461
epoch: 2247, train precision: 0.999311, train loss: 10.370754, valid precision: 0.880600, valid loss: 87.787360
epoch: 2248, train precision: 0.998689, train loss: 10.488444, valid precision: 0.877200, valid loss: 90.626781
epoch: 2249, train precision: 0.998933, train loss: 10.476746, valid precision: 0.874000, valid loss: 92.118884
epoch: 2250, train precision: 0.999133, train loss: 10.351396, valid precision: 0.878800, valid loss: 91.616693
epoch: 2251, train precision: 0.998778, train loss: 10.451445, valid precision: 0.873800, valid loss: 92.039386
epoch: 2252, train precision: 0.999044, train loss: 10.369044, valid precision: 0.876000, valid loss: 91.286245
epoch: 2253, train precision: 0.998778, train loss: 10.467496, valid precision: 0.874800, valid loss: 93.406305
epoch: 2254, train precision: 0.999533, train loss: 10.277334, valid precision: 0.874600, valid loss: 89.469332
epoch: 2255, train precision: 0.998933, train loss: 10.465053, valid precision: 0.875200, valid loss: 90.975331
epoch: 2256, train precision: 0.999244, train loss: 10.388045, valid precision: 0.878400, valid loss: 89.320839
epoch: 2257, train precision: 0.999111, train loss: 10.397880, valid precision: 0.874200, valid loss: 90.926345
epoch: 2258, train precision: 0.998733, train loss: 10.501371, valid precision: 0.879800, valid loss: 88.627260
epoch: 2259, train precision: 0.998956, train loss: 10.429130, valid precision: 0.874600, valid loss: 90.807893
epoch: 2260, train precision: 0.999222, train loss: 10.373006, valid precision: 0.880000, valid loss: 90.837819
epoch: 2261, train precision: 0.999044, train loss: 10.431030, valid precision: 0.880000, valid loss: 91.827614
epoch: 2262, train precision: 0.998933, train loss: 10.387412, valid precision: 0.881200, valid loss: 90.599966
epoch: 2263, train precision: 0.998956, train loss: 10.432962, valid precision: 0.881200, valid loss: 92.195012
epoch: 2264, train precision: 0.998911, train loss: 10.473549, valid precision: 0.876200, valid loss: 90.341928
epoch: 2265, train precision: 0.998889, train loss: 10.416838, valid precision: 0.878800, valid loss: 90.882610
epoch: 2266, train precision: 0.998844, train loss: 10.433051, valid precision: 0.879400, valid loss: 90.549556
epoch: 2267, train precision: 0.999267, train loss: 10.313204, valid precision: 0.877200, valid loss: 90.008658
epoch: 2268, train precision: 0.998889, train loss: 10.433179, valid precision: 0.876000, valid loss: 94.646692
epoch: 2269, train precision: 0.999089, train loss: 10.370965, valid precision: 0.874000, valid loss: 93.504373
epoch: 2270, train precision: 0.998978, train loss: 10.467837, valid precision: 0.879800, valid loss: 90.299908
epoch: 2271, train precision: 0.999044, train loss: 10.414232, valid precision: 0.877200, valid loss: 93.018102
epoch: 2272, train precision: 0.998933, train loss: 10.478408, valid precision: 0.876400, valid loss: 90.592924
epoch: 2273, train precision: 0.998956, train loss: 10.415449, valid precision: 0.873200, valid loss: 90.500099
epoch: 2274, train precision: 0.998956, train loss: 10.415010, valid precision: 0.880400, valid loss: 89.136886
epoch: 2275, train precision: 0.998867, train loss: 10.484049, valid precision: 0.875600, valid loss: 92.857514
epoch: 2276, train precision: 0.999133, train loss: 10.387464, valid precision: 0.877200, valid loss: 88.631365
epoch: 2277, train precision: 0.999111, train loss: 10.392033, valid precision: 0.882200, valid loss: 88.666046
epoch: 2278, train precision: 0.999200, train loss: 10.344149, valid precision: 0.881000, valid loss: 89.031727
epoch: 2279, train precision: 0.998644, train loss: 10.514580, valid precision: 0.881800, valid loss: 87.362623
epoch: 2280, train precision: 0.998956, train loss: 10.421393, valid precision: 0.879400, valid loss: 88.600292
epoch: 2281, train precision: 0.998489, train loss: 10.529207, valid precision: 0.881600, valid loss: 88.875808
