nohup: ignoring input
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:82:00.0
Total memory: 11.90GiB
Free memory: 5.98GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:82:00.0)
epoch: 0, train precision: 0.583200, train loss: 174.030037, valid precision: 0.602800, valid loss: 169.157844
epoch: 1, train precision: 0.684444, train loss: 135.991619, valid precision: 0.699600, valid loss: 133.025722
epoch: 2, train precision: 0.722422, train loss: 116.684536, valid precision: 0.719600, valid loss: 115.901657
epoch: 3, train precision: 0.756956, train loss: 101.575049, valid precision: 0.738800, valid loss: 103.556228
epoch: 4, train precision: 0.775156, train loss: 92.564421, valid precision: 0.757200, valid loss: 96.121571
epoch: 5, train precision: 0.791644, train loss: 84.890026, valid precision: 0.769200, valid loss: 90.308193
epoch: 6, train precision: 0.814200, train loss: 76.840530, valid precision: 0.777800, valid loss: 84.617818
epoch: 7, train precision: 0.819022, train loss: 74.054612, valid precision: 0.784400, valid loss: 82.528885
epoch: 8, train precision: 0.828356, train loss: 69.800765, valid precision: 0.794600, valid loss: 79.327030
epoch: 9, train precision: 0.835711, train loss: 66.509251, valid precision: 0.795400, valid loss: 78.407600
epoch: 10, train precision: 0.846889, train loss: 61.435148, valid precision: 0.800400, valid loss: 75.524656
epoch: 11, train precision: 0.859822, train loss: 57.784052, valid precision: 0.806600, valid loss: 72.505251
epoch: 12, train precision: 0.861844, train loss: 56.459213, valid precision: 0.808800, valid loss: 72.476587
epoch: 13, train precision: 0.868022, train loss: 54.248814, valid precision: 0.819200, valid loss: 70.180975
epoch: 14, train precision: 0.876978, train loss: 51.276663, valid precision: 0.821200, valid loss: 67.991215
epoch: 15, train precision: 0.879911, train loss: 49.627559, valid precision: 0.819400, valid loss: 67.662220
epoch: 16, train precision: 0.884956, train loss: 47.715615, valid precision: 0.824200, valid loss: 66.621309
epoch: 17, train precision: 0.891956, train loss: 45.594215, valid precision: 0.828800, valid loss: 65.172685
epoch: 18, train precision: 0.899111, train loss: 42.989158, valid precision: 0.833600, valid loss: 64.068843
epoch: 19, train precision: 0.891156, train loss: 44.861587, valid precision: 0.834000, valid loss: 64.608989
epoch: 20, train precision: 0.902111, train loss: 41.346836, valid precision: 0.830200, valid loss: 63.882432
epoch: 21, train precision: 0.910689, train loss: 38.942393, valid precision: 0.834600, valid loss: 62.600049
epoch: 22, train precision: 0.914578, train loss: 37.206321, valid precision: 0.836400, valid loss: 61.229335
epoch: 23, train precision: 0.915667, train loss: 36.857873, valid precision: 0.835200, valid loss: 62.471356
epoch: 24, train precision: 0.919556, train loss: 35.135296, valid precision: 0.836800, valid loss: 62.006264
epoch: 25, train precision: 0.923156, train loss: 34.144634, valid precision: 0.842000, valid loss: 60.644364
epoch: 26, train precision: 0.924533, train loss: 33.304951, valid precision: 0.841600, valid loss: 61.454562
epoch: 27, train precision: 0.930556, train loss: 31.430455, valid precision: 0.839200, valid loss: 61.190892
epoch: 28, train precision: 0.934933, train loss: 30.554332, valid precision: 0.842000, valid loss: 60.444318
epoch: 29, train precision: 0.935467, train loss: 29.723697, valid precision: 0.840800, valid loss: 60.229125
epoch: 30, train precision: 0.935267, train loss: 29.409835, valid precision: 0.840800, valid loss: 60.404025
epoch: 31, train precision: 0.936689, train loss: 28.843688, valid precision: 0.845600, valid loss: 60.288583
epoch: 32, train precision: 0.938956, train loss: 28.243795, valid precision: 0.844400, valid loss: 61.253162
epoch: 33, train precision: 0.941800, train loss: 27.170289, valid precision: 0.850000, valid loss: 59.403201
epoch: 34, train precision: 0.944911, train loss: 26.472815, valid precision: 0.850400, valid loss: 58.545593
epoch: 35, train precision: 0.949000, train loss: 25.328085, valid precision: 0.846600, valid loss: 59.261945
epoch: 36, train precision: 0.947333, train loss: 25.304437, valid precision: 0.845400, valid loss: 59.259243
epoch: 37, train precision: 0.953156, train loss: 23.767910, valid precision: 0.847600, valid loss: 58.795342
epoch: 38, train precision: 0.952800, train loss: 23.757836, valid precision: 0.853400, valid loss: 57.738347
epoch: 39, train precision: 0.950622, train loss: 24.120362, valid precision: 0.849200, valid loss: 59.414680
epoch: 40, train precision: 0.957289, train loss: 22.136175, valid precision: 0.848200, valid loss: 60.015559
epoch: 41, train precision: 0.956689, train loss: 22.500596, valid precision: 0.852000, valid loss: 58.917166
epoch: 42, train precision: 0.957178, train loss: 22.120274, valid precision: 0.850400, valid loss: 58.766849
epoch: 43, train precision: 0.960044, train loss: 21.160231, valid precision: 0.854400, valid loss: 59.436591
epoch: 44, train precision: 0.959200, train loss: 21.276558, valid precision: 0.854600, valid loss: 59.805664
epoch: 45, train precision: 0.961333, train loss: 20.581896, valid precision: 0.851800, valid loss: 60.062036
epoch: 46, train precision: 0.964622, train loss: 19.721770, valid precision: 0.852600, valid loss: 58.168113
epoch: 47, train precision: 0.963111, train loss: 19.977226, valid precision: 0.850200, valid loss: 60.837423
epoch: 48, train precision: 0.963200, train loss: 19.725029, valid precision: 0.851000, valid loss: 58.891405
epoch: 49, train precision: 0.965022, train loss: 19.331694, valid precision: 0.857000, valid loss: 59.807070
epoch: 50, train precision: 0.967133, train loss: 18.431203, valid precision: 0.853000, valid loss: 58.780901
epoch: 51, train precision: 0.969844, train loss: 17.661503, valid precision: 0.857400, valid loss: 59.201718
epoch: 52, train precision: 0.967311, train loss: 18.409732, valid precision: 0.859000, valid loss: 58.451528
epoch: 53, train precision: 0.969178, train loss: 17.766843, valid precision: 0.856400, valid loss: 60.051901
epoch: 54, train precision: 0.968378, train loss: 17.944961, valid precision: 0.849200, valid loss: 60.889006
epoch: 55, train precision: 0.965978, train loss: 18.439777, valid precision: 0.851600, valid loss: 61.906871
epoch: 56, train precision: 0.970578, train loss: 17.161829, valid precision: 0.851800, valid loss: 60.631296
epoch: 57, train precision: 0.973778, train loss: 16.220602, valid precision: 0.858000, valid loss: 58.716204
epoch: 58, train precision: 0.973333, train loss: 16.228066, valid precision: 0.858800, valid loss: 59.413608
epoch: 59, train precision: 0.973867, train loss: 16.044380, valid precision: 0.855600, valid loss: 59.512894
epoch: 60, train precision: 0.971733, train loss: 16.650579, valid precision: 0.856200, valid loss: 60.414707
epoch: 61, train precision: 0.971711, train loss: 16.764852, valid precision: 0.852800, valid loss: 61.760955
epoch: 62, train precision: 0.974044, train loss: 15.941109, valid precision: 0.856600, valid loss: 60.289901
epoch: 63, train precision: 0.973578, train loss: 15.737313, valid precision: 0.858600, valid loss: 61.300482
epoch: 64, train precision: 0.974778, train loss: 15.658617, valid precision: 0.861000, valid loss: 59.430651
epoch: 65, train precision: 0.975556, train loss: 15.300264, valid precision: 0.861800, valid loss: 58.944158
epoch: 66, train precision: 0.977467, train loss: 14.442898, valid precision: 0.860600, valid loss: 59.163416
epoch: 67, train precision: 0.978000, train loss: 14.599665, valid precision: 0.861600, valid loss: 60.559533
epoch: 68, train precision: 0.976667, train loss: 14.722483, valid precision: 0.856800, valid loss: 61.034261
epoch: 69, train precision: 0.979911, train loss: 13.947281, valid precision: 0.858400, valid loss: 61.604581
epoch: 70, train precision: 0.978067, train loss: 14.484016, valid precision: 0.856200, valid loss: 61.517098
epoch: 71, train precision: 0.978622, train loss: 14.205404, valid precision: 0.860600, valid loss: 60.921827
epoch: 72, train precision: 0.982311, train loss: 13.329949, valid precision: 0.861200, valid loss: 58.953428
epoch: 73, train precision: 0.980578, train loss: 13.763269, valid precision: 0.861400, valid loss: 61.388816
epoch: 74, train precision: 0.980444, train loss: 13.718836, valid precision: 0.862000, valid loss: 61.544448
epoch: 75, train precision: 0.979467, train loss: 13.789138, valid precision: 0.857800, valid loss: 62.579557
epoch: 76, train precision: 0.982378, train loss: 12.933474, valid precision: 0.859400, valid loss: 63.032454
epoch: 77, train precision: 0.984933, train loss: 12.432973, valid precision: 0.858800, valid loss: 62.236350
epoch: 78, train precision: 0.981333, train loss: 13.298206, valid precision: 0.852200, valid loss: 63.312793
epoch: 79, train precision: 0.980000, train loss: 13.752781, valid precision: 0.858200, valid loss: 61.624108
epoch: 80, train precision: 0.981867, train loss: 12.940643, valid precision: 0.858600, valid loss: 60.959463
epoch: 81, train precision: 0.983711, train loss: 12.303381, valid precision: 0.860000, valid loss: 60.476413
epoch: 82, train precision: 0.984333, train loss: 12.226083, valid precision: 0.858800, valid loss: 61.051383
epoch: 83, train precision: 0.984200, train loss: 12.246658, valid precision: 0.860000, valid loss: 61.970597
epoch: 84, train precision: 0.981956, train loss: 12.803619, valid precision: 0.861600, valid loss: 62.788090
epoch: 85, train precision: 0.984356, train loss: 12.267968, valid precision: 0.853400, valid loss: 63.512264
epoch: 86, train precision: 0.984022, train loss: 12.492416, valid precision: 0.855600, valid loss: 63.157302
epoch: 87, train precision: 0.984756, train loss: 12.134236, valid precision: 0.859000, valid loss: 63.150186
epoch: 88, train precision: 0.986067, train loss: 11.934658, valid precision: 0.859000, valid loss: 63.783546
epoch: 89, train precision: 0.984200, train loss: 12.103503, valid precision: 0.857800, valid loss: 63.609587
epoch: 90, train precision: 0.982533, train loss: 12.681183, valid precision: 0.859600, valid loss: 63.117338
epoch: 91, train precision: 0.987311, train loss: 11.425482, valid precision: 0.861400, valid loss: 63.146136
epoch: 92, train precision: 0.985356, train loss: 11.968832, valid precision: 0.856600, valid loss: 64.285806
epoch: 93, train precision: 0.985244, train loss: 11.884259, valid precision: 0.858600, valid loss: 63.552732
epoch: 94, train precision: 0.986911, train loss: 11.341709, valid precision: 0.862400, valid loss: 61.312276
epoch: 95, train precision: 0.985578, train loss: 11.695862, valid precision: 0.858400, valid loss: 66.018744
epoch: 96, train precision: 0.987444, train loss: 11.205381, valid precision: 0.865600, valid loss: 62.492425
epoch: 97, train precision: 0.986756, train loss: 11.305319, valid precision: 0.860000, valid loss: 64.914736
epoch: 98, train precision: 0.986311, train loss: 11.380982, valid precision: 0.861600, valid loss: 65.165162
epoch: 99, train precision: 0.989089, train loss: 10.774545, valid precision: 0.862200, valid loss: 65.546420
epoch: 100, train precision: 0.986933, train loss: 11.278372, valid precision: 0.859400, valid loss: 65.942257
epoch: 101, train precision: 0.987000, train loss: 11.402270, valid precision: 0.856800, valid loss: 64.741045
epoch: 102, train precision: 0.986111, train loss: 11.567414, valid precision: 0.855000, valid loss: 65.494290
epoch: 103, train precision: 0.985800, train loss: 11.739780, valid precision: 0.856000, valid loss: 67.238055
epoch: 104, train precision: 0.987644, train loss: 11.189313, valid precision: 0.860800, valid loss: 64.588722
epoch: 105, train precision: 0.989200, train loss: 10.670520, valid precision: 0.858000, valid loss: 65.560630
epoch: 106, train precision: 0.989911, train loss: 10.508483, valid precision: 0.856600, valid loss: 65.352204
epoch: 107, train precision: 0.989022, train loss: 10.743110, valid precision: 0.864600, valid loss: 65.455451
epoch: 108, train precision: 0.988889, train loss: 10.677625, valid precision: 0.864200, valid loss: 64.624177
epoch: 109, train precision: 0.988333, train loss: 11.009128, valid precision: 0.859800, valid loss: 66.565896
epoch: 110, train precision: 0.988000, train loss: 11.119428, valid precision: 0.857000, valid loss: 68.139023
epoch: 111, train precision: 0.987667, train loss: 10.915479, valid precision: 0.859800, valid loss: 66.110967
epoch: 112, train precision: 0.986933, train loss: 11.249185, valid precision: 0.857000, valid loss: 68.435752
epoch: 113, train precision: 0.989022, train loss: 10.694493, valid precision: 0.853400, valid loss: 68.834388
epoch: 114, train precision: 0.989867, train loss: 10.589465, valid precision: 0.856200, valid loss: 66.018075
epoch: 115, train precision: 0.990356, train loss: 10.302444, valid precision: 0.860400, valid loss: 65.983035
epoch: 116, train precision: 0.987689, train loss: 11.052419, valid precision: 0.852200, valid loss: 69.425310
epoch: 117, train precision: 0.989178, train loss: 10.643950, valid precision: 0.862000, valid loss: 67.701499
epoch: 118, train precision: 0.988533, train loss: 10.823401, valid precision: 0.863200, valid loss: 68.398545
epoch: 119, train precision: 0.988622, train loss: 10.951084, valid precision: 0.861400, valid loss: 68.858926
epoch: 120, train precision: 0.989933, train loss: 10.433171, valid precision: 0.861400, valid loss: 67.840547
epoch: 121, train precision: 0.990933, train loss: 10.424907, valid precision: 0.862000, valid loss: 66.734739
epoch: 122, train precision: 0.989911, train loss: 10.552677, valid precision: 0.865800, valid loss: 66.490881
epoch: 123, train precision: 0.990067, train loss: 10.379613, valid precision: 0.863600, valid loss: 67.341816
epoch: 124, train precision: 0.990933, train loss: 10.127452, valid precision: 0.863800, valid loss: 65.978305
epoch: 125, train precision: 0.989889, train loss: 10.473555, valid precision: 0.865800, valid loss: 65.154984
epoch: 126, train precision: 0.989244, train loss: 10.714194, valid precision: 0.857600, valid loss: 68.040307
epoch: 127, train precision: 0.990533, train loss: 10.261587, valid precision: 0.860000, valid loss: 67.637845
epoch: 128, train precision: 0.990844, train loss: 10.244749, valid precision: 0.860800, valid loss: 67.539117
epoch: 129, train precision: 0.991667, train loss: 10.117521, valid precision: 0.859800, valid loss: 67.464591
epoch: 130, train precision: 0.990867, train loss: 10.176468, valid precision: 0.863600, valid loss: 67.903243
epoch: 131, train precision: 0.988978, train loss: 10.751785, valid precision: 0.860600, valid loss: 69.156513
epoch: 132, train precision: 0.991489, train loss: 10.035956, valid precision: 0.863800, valid loss: 68.445959
epoch: 133, train precision: 0.990356, train loss: 10.460263, valid precision: 0.863600, valid loss: 70.916963
epoch: 134, train precision: 0.989978, train loss: 10.296199, valid precision: 0.862400, valid loss: 69.475032
epoch: 135, train precision: 0.991444, train loss: 10.123102, valid precision: 0.864000, valid loss: 68.639086
epoch: 136, train precision: 0.992289, train loss: 9.957464, valid precision: 0.864600, valid loss: 67.857377
epoch: 137, train precision: 0.992756, train loss: 9.710760, valid precision: 0.866000, valid loss: 66.433216
epoch: 138, train precision: 0.991400, train loss: 9.963957, valid precision: 0.869400, valid loss: 67.852672
epoch: 139, train precision: 0.992400, train loss: 9.921752, valid precision: 0.865600, valid loss: 68.507585
epoch: 140, train precision: 0.991778, train loss: 10.062313, valid precision: 0.865800, valid loss: 69.041711
epoch: 141, train precision: 0.991600, train loss: 10.265069, valid precision: 0.869600, valid loss: 67.877154
epoch: 142, train precision: 0.991422, train loss: 10.293852, valid precision: 0.867000, valid loss: 68.505018
epoch: 143, train precision: 0.991378, train loss: 10.162609, valid precision: 0.866200, valid loss: 67.882776
epoch: 144, train precision: 0.991667, train loss: 10.180427, valid precision: 0.861000, valid loss: 70.612042
epoch: 145, train precision: 0.992044, train loss: 10.048881, valid precision: 0.863800, valid loss: 68.525830
epoch: 146, train precision: 0.991844, train loss: 10.199048, valid precision: 0.865600, valid loss: 69.210232
epoch: 147, train precision: 0.992156, train loss: 10.088832, valid precision: 0.862200, valid loss: 69.350788
epoch: 148, train precision: 0.991222, train loss: 10.263708, valid precision: 0.865800, valid loss: 69.240787
epoch: 149, train precision: 0.993622, train loss: 9.691870, valid precision: 0.865800, valid loss: 69.283696
epoch: 150, train precision: 0.991556, train loss: 10.219185, valid precision: 0.857200, valid loss: 71.392423
epoch: 151, train precision: 0.992289, train loss: 10.069131, valid precision: 0.866000, valid loss: 70.269289
epoch: 152, train precision: 0.991867, train loss: 10.028972, valid precision: 0.865800, valid loss: 69.486744
epoch: 153, train precision: 0.993289, train loss: 9.777287, valid precision: 0.867200, valid loss: 68.940526
epoch: 154, train precision: 0.993667, train loss: 9.598330, valid precision: 0.863000, valid loss: 69.563958
epoch: 155, train precision: 0.992867, train loss: 9.859400, valid precision: 0.863800, valid loss: 70.078601
epoch: 156, train precision: 0.993156, train loss: 9.778702, valid precision: 0.865200, valid loss: 69.416048
epoch: 157, train precision: 0.991533, train loss: 10.150653, valid precision: 0.859400, valid loss: 72.194079
epoch: 158, train precision: 0.991400, train loss: 10.149594, valid precision: 0.858800, valid loss: 72.729836
epoch: 159, train precision: 0.993222, train loss: 9.756358, valid precision: 0.866200, valid loss: 71.772867
epoch: 160, train precision: 0.993511, train loss: 9.755873, valid precision: 0.857200, valid loss: 70.768199
epoch: 161, train precision: 0.993711, train loss: 9.734681, valid precision: 0.862400, valid loss: 70.619384
epoch: 162, train precision: 0.992844, train loss: 9.891685, valid precision: 0.861000, valid loss: 72.305168
epoch: 163, train precision: 0.993600, train loss: 9.609403, valid precision: 0.867000, valid loss: 72.782470
epoch: 164, train precision: 0.992867, train loss: 9.904699, valid precision: 0.864000, valid loss: 71.646783
epoch: 165, train precision: 0.992489, train loss: 10.041148, valid precision: 0.861600, valid loss: 73.668994
epoch: 166, train precision: 0.993400, train loss: 9.868396, valid precision: 0.866600, valid loss: 71.641706
epoch: 167, train precision: 0.992800, train loss: 10.185684, valid precision: 0.862800, valid loss: 71.532737
epoch: 168, train precision: 0.992956, train loss: 10.013496, valid precision: 0.865200, valid loss: 72.583511
epoch: 169, train precision: 0.993467, train loss: 9.868586, valid precision: 0.862200, valid loss: 72.205432
epoch: 170, train precision: 0.993333, train loss: 9.921862, valid precision: 0.863400, valid loss: 72.594368
epoch: 171, train precision: 0.993533, train loss: 9.788799, valid precision: 0.866800, valid loss: 69.524932
epoch: 172, train precision: 0.991467, train loss: 10.535994, valid precision: 0.865600, valid loss: 70.334450
epoch: 173, train precision: 0.992556, train loss: 10.151985, valid precision: 0.862400, valid loss: 71.473656
epoch: 174, train precision: 0.993311, train loss: 9.988293, valid precision: 0.864400, valid loss: 71.645983
epoch: 175, train precision: 0.992489, train loss: 10.106217, valid precision: 0.863800, valid loss: 72.121355
epoch: 176, train precision: 0.993933, train loss: 9.884217, valid precision: 0.865600, valid loss: 70.176027
epoch: 177, train precision: 0.994533, train loss: 9.530913, valid precision: 0.865000, valid loss: 70.508691
epoch: 178, train precision: 0.989733, train loss: 11.103423, valid precision: 0.863000, valid loss: 71.747942
epoch: 179, train precision: 0.993289, train loss: 9.973303, valid precision: 0.866000, valid loss: 72.080076
epoch: 180, train precision: 0.994689, train loss: 9.629545, valid precision: 0.866600, valid loss: 71.375167
epoch: 181, train precision: 0.993644, train loss: 9.809752, valid precision: 0.865000, valid loss: 72.707655
epoch: 182, train precision: 0.994089, train loss: 9.732482, valid precision: 0.869400, valid loss: 70.738505
epoch: 183, train precision: 0.994444, train loss: 9.575261, valid precision: 0.862600, valid loss: 73.035900
epoch: 184, train precision: 0.993356, train loss: 9.921196, valid precision: 0.865000, valid loss: 71.696240
epoch: 185, train precision: 0.993933, train loss: 9.941345, valid precision: 0.864400, valid loss: 71.296524
epoch: 186, train precision: 0.993533, train loss: 9.985416, valid precision: 0.869800, valid loss: 72.312314
epoch: 187, train precision: 0.993844, train loss: 9.955238, valid precision: 0.868600, valid loss: 72.077559
epoch: 188, train precision: 0.994644, train loss: 9.744384, valid precision: 0.868800, valid loss: 69.354796
epoch: 189, train precision: 0.994156, train loss: 9.923850, valid precision: 0.862000, valid loss: 72.054165
epoch: 190, train precision: 0.995156, train loss: 9.627218, valid precision: 0.866000, valid loss: 72.748923
epoch: 191, train precision: 0.994600, train loss: 9.617018, valid precision: 0.866600, valid loss: 73.851001
epoch: 192, train precision: 0.994267, train loss: 9.793872, valid precision: 0.867200, valid loss: 71.875300
epoch: 193, train precision: 0.994622, train loss: 9.781416, valid precision: 0.866400, valid loss: 73.011322
epoch: 194, train precision: 0.994556, train loss: 9.685005, valid precision: 0.864800, valid loss: 73.642615
epoch: 195, train precision: 0.994289, train loss: 9.756522, valid precision: 0.870200, valid loss: 72.581889
epoch: 196, train precision: 0.994067, train loss: 9.938703, valid precision: 0.868800, valid loss: 73.246737
epoch: 197, train precision: 0.994800, train loss: 9.780530, valid precision: 0.872200, valid loss: 71.675151
epoch: 198, train precision: 0.995711, train loss: 9.497117, valid precision: 0.870000, valid loss: 72.078295
epoch: 199, train precision: 0.995133, train loss: 9.665219, valid precision: 0.868600, valid loss: 73.955858
epoch: 200, train precision: 0.993756, train loss: 9.979069, valid precision: 0.867800, valid loss: 74.604483
epoch: 201, train precision: 0.993511, train loss: 10.161379, valid precision: 0.862600, valid loss: 75.251151
epoch: 202, train precision: 0.993822, train loss: 10.028854, valid precision: 0.867800, valid loss: 74.324927
epoch: 203, train precision: 0.994956, train loss: 9.649933, valid precision: 0.868000, valid loss: 74.768427
epoch: 204, train precision: 0.994556, train loss: 9.787972, valid precision: 0.867200, valid loss: 73.695667
epoch: 205, train precision: 0.994378, train loss: 10.006325, valid precision: 0.869000, valid loss: 75.014765
epoch: 206, train precision: 0.993311, train loss: 10.130086, valid precision: 0.866200, valid loss: 76.487011
epoch: 207, train precision: 0.994933, train loss: 9.701280, valid precision: 0.862800, valid loss: 75.245983
epoch: 208, train precision: 0.995200, train loss: 9.697530, valid precision: 0.865400, valid loss: 75.852139
epoch: 209, train precision: 0.994622, train loss: 9.889766, valid precision: 0.862800, valid loss: 74.974610
epoch: 210, train precision: 0.993778, train loss: 10.269089, valid precision: 0.867200, valid loss: 74.695017
epoch: 211, train precision: 0.994467, train loss: 9.975732, valid precision: 0.866200, valid loss: 73.708525
epoch: 212, train precision: 0.995778, train loss: 9.540778, valid precision: 0.869200, valid loss: 72.913904
epoch: 213, train precision: 0.995244, train loss: 9.738964, valid precision: 0.867800, valid loss: 74.580149
epoch: 214, train precision: 0.995311, train loss: 9.691740, valid precision: 0.866800, valid loss: 76.966901
epoch: 215, train precision: 0.994689, train loss: 9.857945, valid precision: 0.872000, valid loss: 74.094470
epoch: 216, train precision: 0.994756, train loss: 9.972774, valid precision: 0.861600, valid loss: 76.865828
epoch: 217, train precision: 0.994733, train loss: 9.829048, valid precision: 0.864000, valid loss: 77.250058
epoch: 218, train precision: 0.994689, train loss: 9.893484, valid precision: 0.859800, valid loss: 76.170741
epoch: 219, train precision: 0.994600, train loss: 9.954562, valid precision: 0.867800, valid loss: 77.209341
epoch: 220, train precision: 0.994178, train loss: 10.090924, valid precision: 0.862400, valid loss: 77.402259
epoch: 221, train precision: 0.994311, train loss: 10.175160, valid precision: 0.865000, valid loss: 76.611065
epoch: 222, train precision: 0.995867, train loss: 9.689401, valid precision: 0.868800, valid loss: 78.556125
epoch: 223, train precision: 0.995422, train loss: 9.847505, valid precision: 0.868600, valid loss: 76.628549
epoch: 224, train precision: 0.993733, train loss: 10.257489, valid precision: 0.867800, valid loss: 77.710290
epoch: 225, train precision: 0.995378, train loss: 9.817852, valid precision: 0.866400, valid loss: 76.590330
epoch: 226, train precision: 0.996622, train loss: 9.462816, valid precision: 0.866200, valid loss: 76.946165
epoch: 227, train precision: 0.996733, train loss: 9.373483, valid precision: 0.863400, valid loss: 75.671088
epoch: 228, train precision: 0.995556, train loss: 9.767833, valid precision: 0.864400, valid loss: 76.781959
epoch: 229, train precision: 0.995600, train loss: 9.799798, valid precision: 0.869400, valid loss: 76.604171
epoch: 230, train precision: 0.995467, train loss: 9.844821, valid precision: 0.863600, valid loss: 76.552474
epoch: 231, train precision: 0.996000, train loss: 9.661262, valid precision: 0.865200, valid loss: 76.245837
epoch: 232, train precision: 0.994911, train loss: 10.058433, valid precision: 0.867600, valid loss: 76.399263
epoch: 233, train precision: 0.994933, train loss: 10.198006, valid precision: 0.865800, valid loss: 77.276104
epoch: 234, train precision: 0.994533, train loss: 10.015394, valid precision: 0.868200, valid loss: 76.265485
epoch: 235, train precision: 0.996156, train loss: 9.670140, valid precision: 0.868200, valid loss: 74.766662
epoch: 236, train precision: 0.995400, train loss: 9.817619, valid precision: 0.867400, valid loss: 77.481298
epoch: 237, train precision: 0.995889, train loss: 9.872451, valid precision: 0.863600, valid loss: 77.275854
epoch: 238, train precision: 0.995933, train loss: 9.680343, valid precision: 0.867600, valid loss: 73.995260
epoch: 239, train precision: 0.995978, train loss: 9.734041, valid precision: 0.865400, valid loss: 76.683549
epoch: 240, train precision: 0.995756, train loss: 9.755290, valid precision: 0.865600, valid loss: 76.611946
epoch: 241, train precision: 0.995267, train loss: 10.041429, valid precision: 0.862800, valid loss: 78.703185
epoch: 242, train precision: 0.995733, train loss: 9.932237, valid precision: 0.870000, valid loss: 79.118457
epoch: 243, train precision: 0.995689, train loss: 9.865906, valid precision: 0.867800, valid loss: 78.144704
epoch: 244, train precision: 0.995711, train loss: 9.923783, valid precision: 0.868200, valid loss: 78.778943
epoch: 245, train precision: 0.996467, train loss: 9.604428, valid precision: 0.869000, valid loss: 77.896420
epoch: 246, train precision: 0.996178, train loss: 9.800570, valid precision: 0.873000, valid loss: 75.529587
epoch: 247, train precision: 0.995956, train loss: 9.810830, valid precision: 0.871000, valid loss: 77.180531
epoch: 248, train precision: 0.994978, train loss: 10.250843, valid precision: 0.866200, valid loss: 79.700541
epoch: 249, train precision: 0.995489, train loss: 9.988773, valid precision: 0.871200, valid loss: 78.213967
epoch: 250, train precision: 0.995956, train loss: 9.779694, valid precision: 0.867400, valid loss: 78.205738
epoch: 251, train precision: 0.996489, train loss: 9.851559, valid precision: 0.869000, valid loss: 77.158210
epoch: 252, train precision: 0.995711, train loss: 9.885810, valid precision: 0.863400, valid loss: 78.907075
epoch: 253, train precision: 0.996422, train loss: 9.786027, valid precision: 0.868400, valid loss: 76.720069
epoch: 254, train precision: 0.995889, train loss: 9.876094, valid precision: 0.866400, valid loss: 78.318709
epoch: 255, train precision: 0.995733, train loss: 9.969213, valid precision: 0.868800, valid loss: 77.976230
epoch: 256, train precision: 0.996356, train loss: 9.740072, valid precision: 0.871400, valid loss: 77.361786
epoch: 257, train precision: 0.996178, train loss: 9.792436, valid precision: 0.870200, valid loss: 78.828493
epoch: 258, train precision: 0.996467, train loss: 9.740195, valid precision: 0.869000, valid loss: 77.978105
epoch: 259, train precision: 0.995800, train loss: 10.065671, valid precision: 0.864800, valid loss: 78.537728
epoch: 260, train precision: 0.995733, train loss: 9.944479, valid precision: 0.865400, valid loss: 79.616983
epoch: 261, train precision: 0.994667, train loss: 10.344220, valid precision: 0.863000, valid loss: 80.830634
epoch: 262, train precision: 0.996911, train loss: 9.683888, valid precision: 0.868000, valid loss: 79.909288
epoch: 263, train precision: 0.995511, train loss: 10.082454, valid precision: 0.867800, valid loss: 78.312202
epoch: 264, train precision: 0.995800, train loss: 9.966351, valid precision: 0.873400, valid loss: 79.400126
epoch: 265, train precision: 0.997022, train loss: 9.617180, valid precision: 0.872400, valid loss: 78.056065
epoch: 266, train precision: 0.995644, train loss: 10.122959, valid precision: 0.876000, valid loss: 77.740796
epoch: 267, train precision: 0.995800, train loss: 10.123853, valid precision: 0.869400, valid loss: 79.851243
epoch: 268, train precision: 0.997311, train loss: 9.601465, valid precision: 0.866800, valid loss: 77.888237
epoch: 269, train precision: 0.996711, train loss: 9.754814, valid precision: 0.869800, valid loss: 78.598114
epoch: 270, train precision: 0.995978, train loss: 9.975979, valid precision: 0.868800, valid loss: 78.931508
epoch: 271, train precision: 0.996378, train loss: 10.036546, valid precision: 0.871800, valid loss: 78.596607
epoch: 272, train precision: 0.997022, train loss: 9.752799, valid precision: 0.869000, valid loss: 79.218908
epoch: 273, train precision: 0.996067, train loss: 10.048137, valid precision: 0.868600, valid loss: 80.430381
epoch: 274, train precision: 0.996667, train loss: 9.817299, valid precision: 0.869400, valid loss: 78.028900
epoch: 275, train precision: 0.996244, train loss: 9.845062, valid precision: 0.868400, valid loss: 79.223402
epoch: 276, train precision: 0.995667, train loss: 10.143764, valid precision: 0.869000, valid loss: 79.081307
epoch: 277, train precision: 0.995778, train loss: 10.232056, valid precision: 0.873000, valid loss: 77.472169
epoch: 278, train precision: 0.997067, train loss: 9.758234, valid precision: 0.866000, valid loss: 79.727620
epoch: 279, train precision: 0.996711, train loss: 9.937326, valid precision: 0.867600, valid loss: 77.480557
epoch: 280, train precision: 0.996756, train loss: 9.876485, valid precision: 0.865000, valid loss: 78.901774
epoch: 281, train precision: 0.996089, train loss: 10.033035, valid precision: 0.867000, valid loss: 78.825090
epoch: 282, train precision: 0.996333, train loss: 9.973801, valid precision: 0.870200, valid loss: 76.872397
epoch: 283, train precision: 0.996600, train loss: 9.901202, valid precision: 0.870600, valid loss: 77.761185
epoch: 284, train precision: 0.996533, train loss: 9.976218, valid precision: 0.867400, valid loss: 79.687055
epoch: 285, train precision: 0.996289, train loss: 10.031634, valid precision: 0.870000, valid loss: 77.206108
epoch: 286, train precision: 0.996889, train loss: 9.955272, valid precision: 0.870400, valid loss: 77.128273
epoch: 287, train precision: 0.995933, train loss: 10.196328, valid precision: 0.866400, valid loss: 78.783165
epoch: 288, train precision: 0.996511, train loss: 10.074766, valid precision: 0.868400, valid loss: 79.601532
epoch: 289, train precision: 0.996844, train loss: 9.960316, valid precision: 0.871000, valid loss: 79.126118
epoch: 290, train precision: 0.996378, train loss: 10.139972, valid precision: 0.866800, valid loss: 79.826071
epoch: 291, train precision: 0.996333, train loss: 10.100384, valid precision: 0.864600, valid loss: 78.540442
epoch: 292, train precision: 0.997244, train loss: 9.834886, valid precision: 0.868000, valid loss: 78.319228
epoch: 293, train precision: 0.997000, train loss: 9.926170, valid precision: 0.870000, valid loss: 78.458681
epoch: 294, train precision: 0.995533, train loss: 10.324918, valid precision: 0.865000, valid loss: 78.845804
epoch: 295, train precision: 0.997222, train loss: 9.855493, valid precision: 0.863600, valid loss: 78.901004
epoch: 296, train precision: 0.996689, train loss: 10.059848, valid precision: 0.870800, valid loss: 75.916759
epoch: 297, train precision: 0.996244, train loss: 10.097521, valid precision: 0.866600, valid loss: 80.017680
epoch: 298, train precision: 0.996222, train loss: 10.162842, valid precision: 0.866000, valid loss: 80.905612
epoch: 299, train precision: 0.996200, train loss: 10.105697, valid precision: 0.869200, valid loss: 78.563683
epoch: 300, train precision: 0.995511, train loss: 10.392533, valid precision: 0.865600, valid loss: 81.615259
epoch: 301, train precision: 0.996267, train loss: 10.097467, valid precision: 0.866400, valid loss: 79.076674
epoch: 302, train precision: 0.996267, train loss: 10.144321, valid precision: 0.865000, valid loss: 80.017413
epoch: 303, train precision: 0.996600, train loss: 10.129952, valid precision: 0.869200, valid loss: 78.081176
epoch: 304, train precision: 0.997089, train loss: 9.952043, valid precision: 0.866800, valid loss: 78.413156
epoch: 305, train precision: 0.996067, train loss: 10.251673, valid precision: 0.867000, valid loss: 78.913109
epoch: 306, train precision: 0.997444, train loss: 9.946683, valid precision: 0.870200, valid loss: 76.629225
epoch: 307, train precision: 0.997022, train loss: 10.039409, valid precision: 0.872000, valid loss: 78.285569
epoch: 308, train precision: 0.996711, train loss: 10.016937, valid precision: 0.869400, valid loss: 76.899739
epoch: 309, train precision: 0.996800, train loss: 10.051467, valid precision: 0.871000, valid loss: 77.254511
epoch: 310, train precision: 0.996044, train loss: 10.258679, valid precision: 0.869800, valid loss: 78.324620
epoch: 311, train precision: 0.996867, train loss: 10.088226, valid precision: 0.868800, valid loss: 78.308715
epoch: 312, train precision: 0.997533, train loss: 9.884015, valid precision: 0.872400, valid loss: 77.444805
epoch: 313, train precision: 0.996467, train loss: 10.226569, valid precision: 0.868000, valid loss: 77.169481
epoch: 314, train precision: 0.997244, train loss: 9.974503, valid precision: 0.869800, valid loss: 76.929029
epoch: 315, train precision: 0.997844, train loss: 9.782958, valid precision: 0.867800, valid loss: 78.847248
epoch: 316, train precision: 0.996933, train loss: 10.051841, valid precision: 0.869000, valid loss: 79.190029
epoch: 317, train precision: 0.996600, train loss: 10.205415, valid precision: 0.866200, valid loss: 79.427821
epoch: 318, train precision: 0.997156, train loss: 10.035905, valid precision: 0.864400, valid loss: 80.787572
epoch: 319, train precision: 0.997289, train loss: 9.905899, valid precision: 0.869400, valid loss: 80.496350
epoch: 320, train precision: 0.996000, train loss: 10.412187, valid precision: 0.871000, valid loss: 79.655226
epoch: 321, train precision: 0.995978, train loss: 10.401656, valid precision: 0.871800, valid loss: 79.253630
epoch: 322, train precision: 0.997400, train loss: 9.927550, valid precision: 0.868000, valid loss: 78.686297
epoch: 323, train precision: 0.996489, train loss: 10.237125, valid precision: 0.875600, valid loss: 78.637286
epoch: 324, train precision: 0.996511, train loss: 10.210631, valid precision: 0.866000, valid loss: 81.455047
epoch: 325, train precision: 0.996644, train loss: 10.269640, valid precision: 0.863600, valid loss: 81.263501
epoch: 326, train precision: 0.997556, train loss: 9.997481, valid precision: 0.869800, valid loss: 80.658742
epoch: 327, train precision: 0.996200, train loss: 10.367195, valid precision: 0.868400, valid loss: 81.550968
epoch: 328, train precision: 0.996356, train loss: 10.196352, valid precision: 0.866400, valid loss: 80.738743
epoch: 329, train precision: 0.996400, train loss: 10.262272, valid precision: 0.864800, valid loss: 80.798061
epoch: 330, train precision: 0.996111, train loss: 10.432174, valid precision: 0.867400, valid loss: 81.881318
epoch: 331, train precision: 0.996778, train loss: 10.244848, valid precision: 0.870200, valid loss: 80.933013
epoch: 332, train precision: 0.996156, train loss: 10.523403, valid precision: 0.868600, valid loss: 82.750909
epoch: 333, train precision: 0.996600, train loss: 10.281926, valid precision: 0.870600, valid loss: 80.248978
epoch: 334, train precision: 0.996800, train loss: 10.241813, valid precision: 0.869200, valid loss: 79.644927
epoch: 335, train precision: 0.997511, train loss: 10.046467, valid precision: 0.870000, valid loss: 81.762227
epoch: 336, train precision: 0.997311, train loss: 10.080347, valid precision: 0.867000, valid loss: 82.217191
epoch: 337, train precision: 0.997133, train loss: 10.190154, valid precision: 0.862200, valid loss: 83.769448
epoch: 338, train precision: 0.997400, train loss: 10.050938, valid precision: 0.868800, valid loss: 80.915448
epoch: 339, train precision: 0.997600, train loss: 9.988896, valid precision: 0.870600, valid loss: 79.797315
epoch: 340, train precision: 0.997022, train loss: 10.179596, valid precision: 0.867800, valid loss: 82.230249
epoch: 341, train precision: 0.997556, train loss: 10.002426, valid precision: 0.868000, valid loss: 79.228323
epoch: 342, train precision: 0.997556, train loss: 10.099262, valid precision: 0.871800, valid loss: 79.208880
epoch: 343, train precision: 0.996000, train loss: 10.472512, valid precision: 0.867000, valid loss: 80.996403
epoch: 344, train precision: 0.996889, train loss: 10.201566, valid precision: 0.870600, valid loss: 79.740388
epoch: 345, train precision: 0.997444, train loss: 10.196862, valid precision: 0.866800, valid loss: 81.620246
epoch: 346, train precision: 0.996089, train loss: 10.454013, valid precision: 0.867400, valid loss: 81.137903
epoch: 347, train precision: 0.997556, train loss: 10.045109, valid precision: 0.869400, valid loss: 79.695630
epoch: 348, train precision: 0.996933, train loss: 10.305225, valid precision: 0.870800, valid loss: 80.605292
epoch: 349, train precision: 0.996311, train loss: 10.466926, valid precision: 0.864800, valid loss: 83.945738
epoch: 350, train precision: 0.997044, train loss: 10.207336, valid precision: 0.867400, valid loss: 81.149631
epoch: 351, train precision: 0.997356, train loss: 10.137895, valid precision: 0.870000, valid loss: 80.670557
epoch: 352, train precision: 0.997511, train loss: 10.051419, valid precision: 0.872200, valid loss: 80.264680
epoch: 353, train precision: 0.997356, train loss: 10.124818, valid precision: 0.873600, valid loss: 80.907352
epoch: 354, train precision: 0.997311, train loss: 10.226749, valid precision: 0.873600, valid loss: 82.373590
epoch: 355, train precision: 0.996133, train loss: 10.576578, valid precision: 0.867200, valid loss: 82.639721
epoch: 356, train precision: 0.996622, train loss: 10.256633, valid precision: 0.871000, valid loss: 81.522309
epoch: 357, train precision: 0.996889, train loss: 10.270677, valid precision: 0.870000, valid loss: 82.045999
epoch: 358, train precision: 0.997844, train loss: 9.967699, valid precision: 0.869000, valid loss: 80.861071
epoch: 359, train precision: 0.997600, train loss: 10.093194, valid precision: 0.873000, valid loss: 80.279244
epoch: 360, train precision: 0.996844, train loss: 10.233917, valid precision: 0.869600, valid loss: 80.951875
epoch: 361, train precision: 0.997222, train loss: 10.204137, valid precision: 0.866400, valid loss: 82.604042
epoch: 362, train precision: 0.996200, train loss: 10.566797, valid precision: 0.865200, valid loss: 85.170750
epoch: 363, train precision: 0.997133, train loss: 10.399044, valid precision: 0.866800, valid loss: 83.070105
epoch: 364, train precision: 0.996756, train loss: 10.332653, valid precision: 0.871400, valid loss: 81.471542
epoch: 365, train precision: 0.997244, train loss: 10.281318, valid precision: 0.870000, valid loss: 83.741069
epoch: 366, train precision: 0.996911, train loss: 10.319120, valid precision: 0.866600, valid loss: 83.976270
epoch: 367, train precision: 0.996933, train loss: 10.239493, valid precision: 0.870200, valid loss: 82.688001
epoch: 368, train precision: 0.995889, train loss: 10.664896, valid precision: 0.869200, valid loss: 83.126169
epoch: 369, train precision: 0.996422, train loss: 10.456959, valid precision: 0.865800, valid loss: 83.671681
epoch: 370, train precision: 0.998267, train loss: 10.002350, valid precision: 0.871200, valid loss: 81.404444
epoch: 371, train precision: 0.997289, train loss: 10.291558, valid precision: 0.870600, valid loss: 81.539939
epoch: 372, train precision: 0.998133, train loss: 10.019800, valid precision: 0.872600, valid loss: 80.463961
epoch: 373, train precision: 0.996800, train loss: 10.392720, valid precision: 0.867800, valid loss: 81.433505
epoch: 374, train precision: 0.996911, train loss: 10.364234, valid precision: 0.871000, valid loss: 81.258811
epoch: 375, train precision: 0.997822, train loss: 10.125259, valid precision: 0.873400, valid loss: 79.939376
epoch: 376, train precision: 0.996933, train loss: 10.389574, valid precision: 0.866400, valid loss: 82.645105
epoch: 377, train precision: 0.997311, train loss: 10.324883, valid precision: 0.870400, valid loss: 80.710446
epoch: 378, train precision: 0.997667, train loss: 10.226801, valid precision: 0.870200, valid loss: 81.630109
epoch: 379, train precision: 0.997444, train loss: 10.182856, valid precision: 0.869400, valid loss: 81.808957
epoch: 380, train precision: 0.997933, train loss: 10.157636, valid precision: 0.870400, valid loss: 81.697123
epoch: 381, train precision: 0.997356, train loss: 10.277837, valid precision: 0.872400, valid loss: 82.147093
epoch: 382, train precision: 0.997467, train loss: 10.328244, valid precision: 0.868600, valid loss: 82.378021
epoch: 383, train precision: 0.996822, train loss: 10.420152, valid precision: 0.869200, valid loss: 83.578580
epoch: 384, train precision: 0.996800, train loss: 10.418854, valid precision: 0.864200, valid loss: 83.212479
epoch: 385, train precision: 0.996844, train loss: 10.464686, valid precision: 0.869000, valid loss: 83.122938
epoch: 386, train precision: 0.997400, train loss: 10.263027, valid precision: 0.868400, valid loss: 83.801441
epoch: 387, train precision: 0.998200, train loss: 10.104324, valid precision: 0.871600, valid loss: 80.546650
epoch: 388, train precision: 0.997511, train loss: 10.329313, valid precision: 0.871400, valid loss: 81.475702
epoch: 389, train precision: 0.997756, train loss: 10.259670, valid precision: 0.873200, valid loss: 81.946646
epoch: 390, train precision: 0.996222, train loss: 10.768651, valid precision: 0.866400, valid loss: 85.073492
epoch: 391, train precision: 0.997022, train loss: 10.459077, valid precision: 0.873600, valid loss: 81.326227
epoch: 392, train precision: 0.997133, train loss: 10.448001, valid precision: 0.869400, valid loss: 83.098073
epoch: 393, train precision: 0.997400, train loss: 10.402209, valid precision: 0.869200, valid loss: 83.053360
epoch: 394, train precision: 0.997244, train loss: 10.359833, valid precision: 0.867600, valid loss: 84.478287
epoch: 395, train precision: 0.997578, train loss: 10.315735, valid precision: 0.872600, valid loss: 81.232283
epoch: 396, train precision: 0.997533, train loss: 10.308802, valid precision: 0.870400, valid loss: 81.651558
epoch: 397, train precision: 0.997422, train loss: 10.329472, valid precision: 0.872800, valid loss: 81.699107
epoch: 398, train precision: 0.997356, train loss: 10.387127, valid precision: 0.868400, valid loss: 81.776050
epoch: 399, train precision: 0.997067, train loss: 10.483575, valid precision: 0.871600, valid loss: 83.725432
epoch: 400, train precision: 0.997156, train loss: 10.305720, valid precision: 0.865800, valid loss: 82.534076
epoch: 401, train precision: 0.997444, train loss: 10.375264, valid precision: 0.870000, valid loss: 82.588291
epoch: 402, train precision: 0.997067, train loss: 10.285843, valid precision: 0.871000, valid loss: 82.801619
epoch: 403, train precision: 0.997844, train loss: 10.218674, valid precision: 0.864800, valid loss: 83.632127
epoch: 404, train precision: 0.997711, train loss: 10.258185, valid precision: 0.871800, valid loss: 80.961016
epoch: 405, train precision: 0.997511, train loss: 10.416942, valid precision: 0.871000, valid loss: 82.013171
epoch: 406, train precision: 0.996933, train loss: 10.564848, valid precision: 0.868800, valid loss: 81.664411
epoch: 407, train precision: 0.997800, train loss: 10.251023, valid precision: 0.871000, valid loss: 80.021976
epoch: 408, train precision: 0.997622, train loss: 10.319002, valid precision: 0.869200, valid loss: 81.125405
epoch: 409, train precision: 0.997156, train loss: 10.510002, valid precision: 0.872800, valid loss: 81.432597
epoch: 410, train precision: 0.997667, train loss: 10.353991, valid precision: 0.870400, valid loss: 78.967794
epoch: 411, train precision: 0.997156, train loss: 10.430114, valid precision: 0.869200, valid loss: 80.701958
epoch: 412, train precision: 0.997422, train loss: 10.326561, valid precision: 0.872000, valid loss: 81.305405
epoch: 413, train precision: 0.997444, train loss: 10.407436, valid precision: 0.871600, valid loss: 82.524900
epoch: 414, train precision: 0.997756, train loss: 10.285467, valid precision: 0.871200, valid loss: 80.932802
epoch: 415, train precision: 0.997622, train loss: 10.279707, valid precision: 0.872200, valid loss: 80.683146
epoch: 416, train precision: 0.996978, train loss: 10.500368, valid precision: 0.867600, valid loss: 82.335988
epoch: 417, train precision: 0.996822, train loss: 10.560155, valid precision: 0.872800, valid loss: 80.931334
epoch: 418, train precision: 0.997578, train loss: 10.334545, valid precision: 0.875800, valid loss: 79.694859
epoch: 419, train precision: 0.996800, train loss: 10.560266, valid precision: 0.868000, valid loss: 83.329002
epoch: 420, train precision: 0.997556, train loss: 10.369393, valid precision: 0.872600, valid loss: 81.473364
epoch: 421, train precision: 0.998289, train loss: 10.161742, valid precision: 0.873400, valid loss: 80.979993
epoch: 422, train precision: 0.997356, train loss: 10.442649, valid precision: 0.872000, valid loss: 80.797109
epoch: 423, train precision: 0.997978, train loss: 10.303908, valid precision: 0.871400, valid loss: 79.823192
epoch: 424, train precision: 0.997511, train loss: 10.358254, valid precision: 0.870600, valid loss: 81.520386
epoch: 425, train precision: 0.998000, train loss: 10.232461, valid precision: 0.873600, valid loss: 83.872938
epoch: 426, train precision: 0.997556, train loss: 10.393521, valid precision: 0.873800, valid loss: 82.286900
epoch: 427, train precision: 0.997333, train loss: 10.451451, valid precision: 0.869200, valid loss: 82.515713
epoch: 428, train precision: 0.997311, train loss: 10.489521, valid precision: 0.876200, valid loss: 81.890502
epoch: 429, train precision: 0.997311, train loss: 10.499692, valid precision: 0.869400, valid loss: 82.996156
epoch: 430, train precision: 0.997733, train loss: 10.332726, valid precision: 0.873800, valid loss: 82.873525
epoch: 431, train precision: 0.997711, train loss: 10.305711, valid precision: 0.871600, valid loss: 82.793889
epoch: 432, train precision: 0.997289, train loss: 10.504533, valid precision: 0.871000, valid loss: 84.307670
epoch: 433, train precision: 0.996889, train loss: 10.496939, valid precision: 0.870600, valid loss: 84.640294
epoch: 434, train precision: 0.997467, train loss: 10.431350, valid precision: 0.872600, valid loss: 83.669773
epoch: 435, train precision: 0.998089, train loss: 10.274668, valid precision: 0.873400, valid loss: 80.775049
epoch: 436, train precision: 0.997867, train loss: 10.376234, valid precision: 0.871200, valid loss: 82.633954
epoch: 437, train precision: 0.997156, train loss: 10.585770, valid precision: 0.871200, valid loss: 81.960243
epoch: 438, train precision: 0.997422, train loss: 10.462843, valid precision: 0.874200, valid loss: 83.584701
epoch: 439, train precision: 0.998244, train loss: 10.309228, valid precision: 0.872000, valid loss: 82.147200
epoch: 440, train precision: 0.997511, train loss: 10.466661, valid precision: 0.871200, valid loss: 82.990550
epoch: 441, train precision: 0.998489, train loss: 10.267319, valid precision: 0.872800, valid loss: 81.355906
epoch: 442, train precision: 0.997511, train loss: 10.557632, valid precision: 0.874800, valid loss: 81.589889
epoch: 443, train precision: 0.997378, train loss: 10.517432, valid precision: 0.872800, valid loss: 82.386267
epoch: 444, train precision: 0.997778, train loss: 10.416509, valid precision: 0.872600, valid loss: 82.354054
epoch: 445, train precision: 0.997667, train loss: 10.530046, valid precision: 0.872000, valid loss: 81.486902
epoch: 446, train precision: 0.996356, train loss: 10.899555, valid precision: 0.870200, valid loss: 84.945074
epoch: 447, train precision: 0.998311, train loss: 10.235251, valid precision: 0.870000, valid loss: 81.820487
epoch: 448, train precision: 0.997267, train loss: 10.596421, valid precision: 0.873600, valid loss: 81.498697
epoch: 449, train precision: 0.997533, train loss: 10.463772, valid precision: 0.877800, valid loss: 83.299457
epoch: 450, train precision: 0.997422, train loss: 10.549785, valid precision: 0.868800, valid loss: 82.878356
epoch: 451, train precision: 0.997178, train loss: 10.600316, valid precision: 0.867600, valid loss: 84.577739
epoch: 452, train precision: 0.997533, train loss: 10.509193, valid precision: 0.872000, valid loss: 83.296813
epoch: 453, train precision: 0.997933, train loss: 10.475148, valid precision: 0.871400, valid loss: 82.673546
epoch: 454, train precision: 0.997844, train loss: 10.405799, valid precision: 0.870600, valid loss: 84.468256
epoch: 455, train precision: 0.997667, train loss: 10.501477, valid precision: 0.870800, valid loss: 83.617719
epoch: 456, train precision: 0.997956, train loss: 10.403519, valid precision: 0.866400, valid loss: 83.346161
epoch: 457, train precision: 0.997778, train loss: 10.425009, valid precision: 0.871200, valid loss: 81.417442
epoch: 458, train precision: 0.997600, train loss: 10.470622, valid precision: 0.872600, valid loss: 82.238273
epoch: 459, train precision: 0.997911, train loss: 10.380298, valid precision: 0.869800, valid loss: 83.535689
epoch: 460, train precision: 0.997822, train loss: 10.415357, valid precision: 0.874600, valid loss: 82.381856
epoch: 461, train precision: 0.997311, train loss: 10.620150, valid precision: 0.867200, valid loss: 83.380084
epoch: 462, train precision: 0.997756, train loss: 10.439271, valid precision: 0.872400, valid loss: 81.477567
epoch: 463, train precision: 0.997733, train loss: 10.453386, valid precision: 0.872000, valid loss: 81.474474
epoch: 464, train precision: 0.997844, train loss: 10.461038, valid precision: 0.870800, valid loss: 83.785226
epoch: 465, train precision: 0.997422, train loss: 10.566082, valid precision: 0.873600, valid loss: 82.519939
epoch: 466, train precision: 0.997822, train loss: 10.491911, valid precision: 0.872000, valid loss: 83.860238
epoch: 467, train precision: 0.997689, train loss: 10.574970, valid precision: 0.865600, valid loss: 82.658713
epoch: 468, train precision: 0.998022, train loss: 10.458177, valid precision: 0.875200, valid loss: 79.885558
epoch: 469, train precision: 0.997756, train loss: 10.518076, valid precision: 0.870400, valid loss: 82.067452
epoch: 470, train precision: 0.997378, train loss: 10.658465, valid precision: 0.869400, valid loss: 81.762299
epoch: 471, train precision: 0.998022, train loss: 10.456698, valid precision: 0.868200, valid loss: 81.796406
epoch: 472, train precision: 0.997800, train loss: 10.459613, valid precision: 0.872400, valid loss: 82.181032
epoch: 473, train precision: 0.997644, train loss: 10.540280, valid precision: 0.869000, valid loss: 82.328144
epoch: 474, train precision: 0.997400, train loss: 10.705124, valid precision: 0.866000, valid loss: 83.780403
epoch: 475, train precision: 0.997689, train loss: 10.472784, valid precision: 0.868400, valid loss: 83.351293
epoch: 476, train precision: 0.998022, train loss: 10.533542, valid precision: 0.869400, valid loss: 84.858401
epoch: 477, train precision: 0.998044, train loss: 10.429349, valid precision: 0.868800, valid loss: 81.087685
epoch: 478, train precision: 0.998089, train loss: 10.390802, valid precision: 0.871600, valid loss: 81.703763
epoch: 479, train precision: 0.998111, train loss: 10.429850, valid precision: 0.872400, valid loss: 82.301461
epoch: 480, train precision: 0.997667, train loss: 10.557671, valid precision: 0.872200, valid loss: 81.271906
epoch: 481, train precision: 0.997711, train loss: 10.533442, valid precision: 0.872000, valid loss: 82.825760
epoch: 482, train precision: 0.997356, train loss: 10.623549, valid precision: 0.871600, valid loss: 82.040012
epoch: 483, train precision: 0.997822, train loss: 10.422045, valid precision: 0.872000, valid loss: 82.569009
epoch: 484, train precision: 0.997933, train loss: 10.506886, valid precision: 0.872400, valid loss: 82.044453
epoch: 485, train precision: 0.997444, train loss: 10.579582, valid precision: 0.871400, valid loss: 83.133572
epoch: 486, train precision: 0.998000, train loss: 10.494964, valid precision: 0.876000, valid loss: 81.127286
epoch: 487, train precision: 0.997644, train loss: 10.552140, valid precision: 0.874800, valid loss: 81.909485
epoch: 488, train precision: 0.998356, train loss: 10.422904, valid precision: 0.877000, valid loss: 81.123445
epoch: 489, train precision: 0.997578, train loss: 10.557081, valid precision: 0.873200, valid loss: 82.949138
epoch: 490, train precision: 0.997378, train loss: 10.620007, valid precision: 0.875400, valid loss: 84.007579
epoch: 491, train precision: 0.998311, train loss: 10.470248, valid precision: 0.869200, valid loss: 84.798148
epoch: 492, train precision: 0.997800, train loss: 10.490302, valid precision: 0.870000, valid loss: 81.461287
epoch: 493, train precision: 0.998111, train loss: 10.471722, valid precision: 0.872600, valid loss: 82.582192
epoch: 494, train precision: 0.997689, train loss: 10.487739, valid precision: 0.873800, valid loss: 83.617180
epoch: 495, train precision: 0.997533, train loss: 10.621755, valid precision: 0.875800, valid loss: 83.392709
epoch: 496, train precision: 0.997422, train loss: 10.739821, valid precision: 0.872400, valid loss: 82.998339
epoch: 497, train precision: 0.997533, train loss: 10.683635, valid precision: 0.872200, valid loss: 81.997808
epoch: 498, train precision: 0.998111, train loss: 10.536513, valid precision: 0.872600, valid loss: 83.113829
epoch: 499, train precision: 0.997333, train loss: 10.780039, valid precision: 0.875400, valid loss: 81.089518
epoch: 500, train precision: 0.997511, train loss: 10.591372, valid precision: 0.872400, valid loss: 84.035453
epoch: 501, train precision: 0.997578, train loss: 10.682139, valid precision: 0.871400, valid loss: 80.978436
epoch: 502, train precision: 0.997644, train loss: 10.615922, valid precision: 0.874200, valid loss: 82.823991
epoch: 503, train precision: 0.998222, train loss: 10.440548, valid precision: 0.873600, valid loss: 81.930462
epoch: 504, train precision: 0.997622, train loss: 10.504303, valid precision: 0.873800, valid loss: 83.089031
epoch: 505, train precision: 0.997467, train loss: 10.614277, valid precision: 0.868800, valid loss: 82.690100
epoch: 506, train precision: 0.997733, train loss: 10.601959, valid precision: 0.869000, valid loss: 81.969995
epoch: 507, train precision: 0.997956, train loss: 10.457834, valid precision: 0.866600, valid loss: 84.448728
epoch: 508, train precision: 0.997311, train loss: 10.775356, valid precision: 0.869200, valid loss: 83.293664
epoch: 509, train precision: 0.997556, train loss: 10.652951, valid precision: 0.870800, valid loss: 83.664825
epoch: 510, train precision: 0.997911, train loss: 10.535360, valid precision: 0.869800, valid loss: 82.849357
epoch: 511, train precision: 0.998267, train loss: 10.447349, valid precision: 0.865200, valid loss: 83.058059
epoch: 512, train precision: 0.998533, train loss: 10.417454, valid precision: 0.875600, valid loss: 82.678907
epoch: 513, train precision: 0.998178, train loss: 10.505131, valid precision: 0.871200, valid loss: 81.361984
epoch: 514, train precision: 0.997089, train loss: 10.762903, valid precision: 0.869800, valid loss: 84.594287
epoch: 515, train precision: 0.997711, train loss: 10.656392, valid precision: 0.867400, valid loss: 83.726075
epoch: 516, train precision: 0.998089, train loss: 10.531148, valid precision: 0.873200, valid loss: 83.640633
epoch: 517, train precision: 0.997356, train loss: 10.676317, valid precision: 0.874800, valid loss: 83.076441
epoch: 518, train precision: 0.997533, train loss: 10.588289, valid precision: 0.872600, valid loss: 81.739383
epoch: 519, train precision: 0.998511, train loss: 10.360518, valid precision: 0.876200, valid loss: 80.723903
epoch: 520, train precision: 0.998022, train loss: 10.535420, valid precision: 0.873400, valid loss: 81.767171
epoch: 521, train precision: 0.998378, train loss: 10.412466, valid precision: 0.874400, valid loss: 81.719743
epoch: 522, train precision: 0.998178, train loss: 10.410492, valid precision: 0.873000, valid loss: 84.198024
epoch: 523, train precision: 0.997822, train loss: 10.599057, valid precision: 0.872000, valid loss: 81.464767
epoch: 524, train precision: 0.998133, train loss: 10.579348, valid precision: 0.868400, valid loss: 82.583487
epoch: 525, train precision: 0.997911, train loss: 10.598149, valid precision: 0.869800, valid loss: 84.244827
epoch: 526, train precision: 0.997556, train loss: 10.718721, valid precision: 0.871800, valid loss: 83.968931
epoch: 527, train precision: 0.998244, train loss: 10.532243, valid precision: 0.870400, valid loss: 82.758554
epoch: 528, train precision: 0.998133, train loss: 10.475612, valid precision: 0.874000, valid loss: 83.501624
epoch: 529, train precision: 0.997911, train loss: 10.547222, valid precision: 0.871200, valid loss: 83.335309
epoch: 530, train precision: 0.997933, train loss: 10.618099, valid precision: 0.872800, valid loss: 83.517561
epoch: 531, train precision: 0.997422, train loss: 10.723305, valid precision: 0.877000, valid loss: 84.334516
epoch: 532, train precision: 0.998467, train loss: 10.443434, valid precision: 0.875600, valid loss: 80.828193
epoch: 533, train precision: 0.998067, train loss: 10.563514, valid precision: 0.871200, valid loss: 83.877703
epoch: 534, train precision: 0.998622, train loss: 10.364232, valid precision: 0.878200, valid loss: 82.995276
epoch: 535, train precision: 0.998356, train loss: 10.551456, valid precision: 0.870200, valid loss: 84.321705
epoch: 536, train precision: 0.997911, train loss: 10.635022, valid precision: 0.876600, valid loss: 83.665549
epoch: 537, train precision: 0.997200, train loss: 10.771690, valid precision: 0.866000, valid loss: 85.012006
epoch: 538, train precision: 0.998244, train loss: 10.427394, valid precision: 0.873200, valid loss: 82.690570
epoch: 539, train precision: 0.998044, train loss: 10.644731, valid precision: 0.874600, valid loss: 82.396500
epoch: 540, train precision: 0.998289, train loss: 10.516183, valid precision: 0.872600, valid loss: 81.792346
epoch: 541, train precision: 0.998467, train loss: 10.500657, valid precision: 0.872600, valid loss: 82.147584
epoch: 542, train precision: 0.997644, train loss: 10.756000, valid precision: 0.869000, valid loss: 82.891022
epoch: 543, train precision: 0.998000, train loss: 10.582327, valid precision: 0.873800, valid loss: 81.235596
epoch: 544, train precision: 0.998156, train loss: 10.628539, valid precision: 0.871400, valid loss: 82.437675
epoch: 545, train precision: 0.997222, train loss: 10.857956, valid precision: 0.873400, valid loss: 83.583411
epoch: 546, train precision: 0.997733, train loss: 10.621534, valid precision: 0.870800, valid loss: 83.281746
epoch: 547, train precision: 0.997489, train loss: 10.756554, valid precision: 0.872600, valid loss: 81.506870
epoch: 548, train precision: 0.998133, train loss: 10.603562, valid precision: 0.875400, valid loss: 83.134093
epoch: 549, train precision: 0.998778, train loss: 10.368266, valid precision: 0.876800, valid loss: 80.396978
epoch: 550, train precision: 0.997578, train loss: 10.787648, valid precision: 0.872000, valid loss: 84.207924
epoch: 551, train precision: 0.997867, train loss: 10.672765, valid precision: 0.873600, valid loss: 82.196275
epoch: 552, train precision: 0.997800, train loss: 10.677050, valid precision: 0.868600, valid loss: 83.320854
epoch: 553, train precision: 0.997156, train loss: 10.900975, valid precision: 0.872800, valid loss: 84.830062
epoch: 554, train precision: 0.998289, train loss: 10.519387, valid precision: 0.874800, valid loss: 81.581254
epoch: 555, train precision: 0.998044, train loss: 10.585766, valid precision: 0.871400, valid loss: 83.999120
epoch: 556, train precision: 0.998289, train loss: 10.594714, valid precision: 0.874600, valid loss: 84.025524
epoch: 557, train precision: 0.998489, train loss: 10.523476, valid precision: 0.873400, valid loss: 85.095266
epoch: 558, train precision: 0.997889, train loss: 10.618601, valid precision: 0.873000, valid loss: 82.978303
epoch: 559, train precision: 0.997933, train loss: 10.626144, valid precision: 0.870600, valid loss: 82.619776
epoch: 560, train precision: 0.998022, train loss: 10.664105, valid precision: 0.873400, valid loss: 83.173043
epoch: 561, train precision: 0.998222, train loss: 10.537463, valid precision: 0.873800, valid loss: 81.503129
epoch: 562, train precision: 0.998400, train loss: 10.504413, valid precision: 0.874600, valid loss: 81.281417
epoch: 563, train precision: 0.998444, train loss: 10.436143, valid precision: 0.876600, valid loss: 83.110359
epoch: 564, train precision: 0.998000, train loss: 10.567082, valid precision: 0.876200, valid loss: 81.280998
epoch: 565, train precision: 0.998022, train loss: 10.580355, valid precision: 0.876200, valid loss: 81.297753
epoch: 566, train precision: 0.997800, train loss: 10.672182, valid precision: 0.872000, valid loss: 81.853075
epoch: 567, train precision: 0.998311, train loss: 10.600713, valid precision: 0.874000, valid loss: 82.778298
epoch: 568, train precision: 0.998156, train loss: 10.559267, valid precision: 0.872600, valid loss: 84.426035
epoch: 569, train precision: 0.997867, train loss: 10.635773, valid precision: 0.877400, valid loss: 81.810793
epoch: 570, train precision: 0.998311, train loss: 10.497221, valid precision: 0.874400, valid loss: 81.354430
epoch: 571, train precision: 0.998333, train loss: 10.633396, valid precision: 0.873000, valid loss: 83.033397
epoch: 572, train precision: 0.998200, train loss: 10.592403, valid precision: 0.880000, valid loss: 80.836154
epoch: 573, train precision: 0.998289, train loss: 10.518059, valid precision: 0.870800, valid loss: 84.547079
epoch: 574, train precision: 0.998022, train loss: 10.628757, valid precision: 0.871600, valid loss: 83.359662
epoch: 575, train precision: 0.997800, train loss: 10.677184, valid precision: 0.872400, valid loss: 82.275309
epoch: 576, train precision: 0.997756, train loss: 10.717300, valid precision: 0.869000, valid loss: 84.346077
epoch: 577, train precision: 0.998044, train loss: 10.625275, valid precision: 0.873000, valid loss: 82.974816
epoch: 578, train precision: 0.998222, train loss: 10.543884, valid precision: 0.876000, valid loss: 82.443879
epoch: 579, train precision: 0.996978, train loss: 10.959929, valid precision: 0.873600, valid loss: 86.100084
epoch: 580, train precision: 0.998311, train loss: 10.598790, valid precision: 0.872600, valid loss: 83.206280
epoch: 581, train precision: 0.998089, train loss: 10.597680, valid precision: 0.877000, valid loss: 83.669018
epoch: 582, train precision: 0.997933, train loss: 10.721998, valid precision: 0.876000, valid loss: 83.627600
epoch: 583, train precision: 0.997489, train loss: 10.857203, valid precision: 0.873200, valid loss: 82.699389
epoch: 584, train precision: 0.998200, train loss: 10.561700, valid precision: 0.875000, valid loss: 81.133057
epoch: 585, train precision: 0.998422, train loss: 10.519812, valid precision: 0.877600, valid loss: 81.290597
epoch: 586, train precision: 0.998133, train loss: 10.675218, valid precision: 0.876400, valid loss: 81.444246
epoch: 587, train precision: 0.997511, train loss: 10.860771, valid precision: 0.872600, valid loss: 82.770438
epoch: 588, train precision: 0.997911, train loss: 10.734857, valid precision: 0.877800, valid loss: 82.554270
epoch: 589, train precision: 0.998578, train loss: 10.471301, valid precision: 0.879000, valid loss: 81.409777
epoch: 590, train precision: 0.998267, train loss: 10.615726, valid precision: 0.874400, valid loss: 83.434454
epoch: 591, train precision: 0.998244, train loss: 10.685522, valid precision: 0.869800, valid loss: 82.252237
epoch: 592, train precision: 0.998378, train loss: 10.562051, valid precision: 0.875800, valid loss: 81.858167
epoch: 593, train precision: 0.998400, train loss: 10.575990, valid precision: 0.873400, valid loss: 82.245827
epoch: 594, train precision: 0.998311, train loss: 10.559709, valid precision: 0.876600, valid loss: 80.050009
epoch: 595, train precision: 0.997600, train loss: 10.800903, valid precision: 0.876200, valid loss: 82.984498
epoch: 596, train precision: 0.998333, train loss: 10.642783, valid precision: 0.868800, valid loss: 85.047262
epoch: 597, train precision: 0.998556, train loss: 10.542723, valid precision: 0.874400, valid loss: 83.194895
epoch: 598, train precision: 0.998089, train loss: 10.649251, valid precision: 0.873600, valid loss: 81.783918
epoch: 599, train precision: 0.997689, train loss: 10.731166, valid precision: 0.875200, valid loss: 82.340708
epoch: 600, train precision: 0.997156, train loss: 10.918592, valid precision: 0.868400, valid loss: 87.321567
epoch: 601, train precision: 0.998467, train loss: 10.584139, valid precision: 0.875200, valid loss: 83.263222
epoch: 602, train precision: 0.998067, train loss: 10.621274, valid precision: 0.873800, valid loss: 81.708493
epoch: 603, train precision: 0.998022, train loss: 10.618054, valid precision: 0.871400, valid loss: 84.084888
epoch: 604, train precision: 0.997978, train loss: 10.718955, valid precision: 0.875400, valid loss: 82.964693
epoch: 605, train precision: 0.997978, train loss: 10.743297, valid precision: 0.873000, valid loss: 83.028360
epoch: 606, train precision: 0.998667, train loss: 10.465584, valid precision: 0.874000, valid loss: 83.132090
epoch: 607, train precision: 0.998356, train loss: 10.571880, valid precision: 0.874000, valid loss: 83.427634
epoch: 608, train precision: 0.998111, train loss: 10.783847, valid precision: 0.878800, valid loss: 81.089969
epoch: 609, train precision: 0.998067, train loss: 10.667086, valid precision: 0.874600, valid loss: 83.805542
epoch: 610, train precision: 0.997711, train loss: 10.840873, valid precision: 0.874200, valid loss: 84.703680
epoch: 611, train precision: 0.998289, train loss: 10.616417, valid precision: 0.877600, valid loss: 82.092281
epoch: 612, train precision: 0.998756, train loss: 10.487972, valid precision: 0.874200, valid loss: 83.041758
epoch: 613, train precision: 0.998311, train loss: 10.648649, valid precision: 0.871200, valid loss: 82.558511
epoch: 614, train precision: 0.997733, train loss: 10.770045, valid precision: 0.873200, valid loss: 82.958303
epoch: 615, train precision: 0.997600, train loss: 10.804016, valid precision: 0.870200, valid loss: 86.508179
epoch: 616, train precision: 0.997778, train loss: 10.714530, valid precision: 0.875600, valid loss: 82.883996
epoch: 617, train precision: 0.997822, train loss: 10.825115, valid precision: 0.874800, valid loss: 84.801418
epoch: 618, train precision: 0.998400, train loss: 10.593014, valid precision: 0.875000, valid loss: 83.009208
epoch: 619, train precision: 0.998111, train loss: 10.644010, valid precision: 0.871400, valid loss: 84.247625
epoch: 620, train precision: 0.998444, train loss: 10.562613, valid precision: 0.874600, valid loss: 84.356120
epoch: 621, train precision: 0.998378, train loss: 10.546011, valid precision: 0.877800, valid loss: 82.025121
epoch: 622, train precision: 0.998222, train loss: 10.644751, valid precision: 0.875000, valid loss: 84.143267
epoch: 623, train precision: 0.998378, train loss: 10.608794, valid precision: 0.876400, valid loss: 83.623620
epoch: 624, train precision: 0.998511, train loss: 10.562708, valid precision: 0.874000, valid loss: 83.406970
epoch: 625, train precision: 0.998333, train loss: 10.552291, valid precision: 0.875800, valid loss: 82.114757
epoch: 626, train precision: 0.998422, train loss: 10.576512, valid precision: 0.874800, valid loss: 84.658661
epoch: 627, train precision: 0.998311, train loss: 10.602805, valid precision: 0.876800, valid loss: 83.756372
epoch: 628, train precision: 0.998333, train loss: 10.646588, valid precision: 0.877200, valid loss: 83.605308
epoch: 629, train precision: 0.998222, train loss: 10.687546, valid precision: 0.875600, valid loss: 84.282569
epoch: 630, train precision: 0.998356, train loss: 10.663768, valid precision: 0.876000, valid loss: 82.855633
epoch: 631, train precision: 0.997689, train loss: 10.803155, valid precision: 0.877000, valid loss: 84.848410
epoch: 632, train precision: 0.997844, train loss: 10.740649, valid precision: 0.875600, valid loss: 85.191430
epoch: 633, train precision: 0.998578, train loss: 10.578595, valid precision: 0.873000, valid loss: 83.851031
epoch: 634, train precision: 0.997711, train loss: 10.857465, valid precision: 0.874000, valid loss: 85.892493
epoch: 635, train precision: 0.998311, train loss: 10.660821, valid precision: 0.876800, valid loss: 84.250947
epoch: 636, train precision: 0.997600, train loss: 10.872877, valid precision: 0.872800, valid loss: 84.764389
epoch: 637, train precision: 0.998133, train loss: 10.611879, valid precision: 0.876000, valid loss: 83.623901
epoch: 638, train precision: 0.998378, train loss: 10.631176, valid precision: 0.876600, valid loss: 83.977668
epoch: 639, train precision: 0.998444, train loss: 10.626084, valid precision: 0.879400, valid loss: 84.250052
epoch: 640, train precision: 0.998289, train loss: 10.653587, valid precision: 0.874600, valid loss: 83.661579
epoch: 641, train precision: 0.998667, train loss: 10.469193, valid precision: 0.876800, valid loss: 83.551202
epoch: 642, train precision: 0.998311, train loss: 10.673060, valid precision: 0.874400, valid loss: 86.783299
epoch: 643, train precision: 0.997733, train loss: 10.778000, valid precision: 0.871800, valid loss: 86.001091
epoch: 644, train precision: 0.998933, train loss: 10.533126, valid precision: 0.876800, valid loss: 84.054110
epoch: 645, train precision: 0.998178, train loss: 10.749484, valid precision: 0.876200, valid loss: 83.971042
epoch: 646, train precision: 0.998444, train loss: 10.710437, valid precision: 0.877000, valid loss: 82.763116
epoch: 647, train precision: 0.997956, train loss: 10.675802, valid precision: 0.872200, valid loss: 86.566251
epoch: 648, train precision: 0.998178, train loss: 10.731968, valid precision: 0.876000, valid loss: 83.199251
epoch: 649, train precision: 0.998400, train loss: 10.606865, valid precision: 0.874400, valid loss: 82.377307
epoch: 650, train precision: 0.997911, train loss: 10.804787, valid precision: 0.874600, valid loss: 86.218913
epoch: 651, train precision: 0.998644, train loss: 10.645925, valid precision: 0.877000, valid loss: 84.066568
epoch: 652, train precision: 0.998356, train loss: 10.708124, valid precision: 0.868800, valid loss: 86.179789
epoch: 653, train precision: 0.998778, train loss: 10.544539, valid precision: 0.878000, valid loss: 81.800185
epoch: 654, train precision: 0.998822, train loss: 10.544171, valid precision: 0.873600, valid loss: 83.279067
epoch: 655, train precision: 0.998156, train loss: 10.677036, valid precision: 0.877400, valid loss: 83.111549
epoch: 656, train precision: 0.998400, train loss: 10.614982, valid precision: 0.874200, valid loss: 83.451080
epoch: 657, train precision: 0.998289, train loss: 10.635838, valid precision: 0.877000, valid loss: 82.587332
epoch: 658, train precision: 0.998933, train loss: 10.482749, valid precision: 0.875200, valid loss: 83.051632
epoch: 659, train precision: 0.998422, train loss: 10.610168, valid precision: 0.877200, valid loss: 83.063342
epoch: 660, train precision: 0.997422, train loss: 10.944184, valid precision: 0.875600, valid loss: 83.958068
epoch: 661, train precision: 0.998333, train loss: 10.713698, valid precision: 0.874000, valid loss: 83.620760
epoch: 662, train precision: 0.997978, train loss: 10.802946, valid precision: 0.876800, valid loss: 85.608964
epoch: 663, train precision: 0.998511, train loss: 10.607172, valid precision: 0.877400, valid loss: 84.182853
epoch: 664, train precision: 0.998267, train loss: 10.686814, valid precision: 0.876200, valid loss: 85.763282
epoch: 665, train precision: 0.997644, train loss: 10.894557, valid precision: 0.875400, valid loss: 86.484635
epoch: 666, train precision: 0.998556, train loss: 10.599976, valid precision: 0.877800, valid loss: 85.633284
epoch: 667, train precision: 0.998556, train loss: 10.636740, valid precision: 0.873800, valid loss: 85.372337
epoch: 668, train precision: 0.997867, train loss: 10.834166, valid precision: 0.871200, valid loss: 87.202183
epoch: 669, train precision: 0.998333, train loss: 10.634422, valid precision: 0.874000, valid loss: 85.454296
epoch: 670, train precision: 0.997578, train loss: 10.918252, valid precision: 0.872400, valid loss: 85.990156
epoch: 671, train precision: 0.998644, train loss: 10.600848, valid precision: 0.874000, valid loss: 85.629676
epoch: 672, train precision: 0.998444, train loss: 10.578409, valid precision: 0.872000, valid loss: 86.060937
epoch: 673, train precision: 0.997822, train loss: 10.810413, valid precision: 0.873400, valid loss: 85.826562
epoch: 674, train precision: 0.998644, train loss: 10.652189, valid precision: 0.872000, valid loss: 83.891457
epoch: 675, train precision: 0.998867, train loss: 10.544439, valid precision: 0.872600, valid loss: 84.308411
epoch: 676, train precision: 0.997933, train loss: 10.766916, valid precision: 0.873600, valid loss: 85.709636
epoch: 677, train precision: 0.997956, train loss: 10.710868, valid precision: 0.875800, valid loss: 86.054596
epoch: 678, train precision: 0.998667, train loss: 10.628924, valid precision: 0.877400, valid loss: 85.516533
epoch: 679, train precision: 0.998356, train loss: 10.713711, valid precision: 0.875600, valid loss: 85.377003
epoch: 680, train precision: 0.998644, train loss: 10.585639, valid precision: 0.875600, valid loss: 84.523351
epoch: 681, train precision: 0.997889, train loss: 10.808552, valid precision: 0.873800, valid loss: 85.358781
epoch: 682, train precision: 0.998600, train loss: 10.628323, valid precision: 0.878600, valid loss: 84.636285
epoch: 683, train precision: 0.998244, train loss: 10.727884, valid precision: 0.877000, valid loss: 86.096622
epoch: 684, train precision: 0.998489, train loss: 10.700141, valid precision: 0.873400, valid loss: 84.062301
epoch: 685, train precision: 0.998489, train loss: 10.621623, valid precision: 0.875000, valid loss: 84.995561
epoch: 686, train precision: 0.998244, train loss: 10.682084, valid precision: 0.880400, valid loss: 84.983350
epoch: 687, train precision: 0.997911, train loss: 10.816715, valid precision: 0.878200, valid loss: 82.340993
epoch: 688, train precision: 0.998156, train loss: 10.744558, valid precision: 0.878000, valid loss: 83.640564
epoch: 689, train precision: 0.998178, train loss: 10.722664, valid precision: 0.880000, valid loss: 82.785224
epoch: 690, train precision: 0.998578, train loss: 10.627446, valid precision: 0.878400, valid loss: 83.431028
epoch: 691, train precision: 0.998356, train loss: 10.711689, valid precision: 0.874800, valid loss: 84.034648
epoch: 692, train precision: 0.998222, train loss: 10.736319, valid precision: 0.877600, valid loss: 83.401097
epoch: 693, train precision: 0.998711, train loss: 10.626332, valid precision: 0.878400, valid loss: 83.745321
epoch: 694, train precision: 0.998489, train loss: 10.651868, valid precision: 0.877600, valid loss: 83.599645
epoch: 695, train precision: 0.998444, train loss: 10.677372, valid precision: 0.877800, valid loss: 82.609935
epoch: 696, train precision: 0.998311, train loss: 10.740352, valid precision: 0.879600, valid loss: 82.699165
epoch: 697, train precision: 0.998289, train loss: 10.701191, valid precision: 0.874400, valid loss: 84.100098
epoch: 698, train precision: 0.998400, train loss: 10.727758, valid precision: 0.875600, valid loss: 83.419914
epoch: 699, train precision: 0.998400, train loss: 10.724475, valid precision: 0.872600, valid loss: 85.353598
epoch: 700, train precision: 0.998578, train loss: 10.706614, valid precision: 0.878800, valid loss: 84.969426
epoch: 701, train precision: 0.998644, train loss: 10.599296, valid precision: 0.878200, valid loss: 84.014501
epoch: 702, train precision: 0.998200, train loss: 10.694126, valid precision: 0.875800, valid loss: 85.229436
epoch: 703, train precision: 0.997867, train loss: 10.803542, valid precision: 0.874400, valid loss: 85.681896
epoch: 704, train precision: 0.998422, train loss: 10.686006, valid precision: 0.877400, valid loss: 84.256864
epoch: 705, train precision: 0.998578, train loss: 10.685265, valid precision: 0.874600, valid loss: 85.131598
epoch: 706, train precision: 0.998244, train loss: 10.675499, valid precision: 0.882800, valid loss: 85.786116
epoch: 707, train precision: 0.998089, train loss: 10.755384, valid precision: 0.876000, valid loss: 82.704581
epoch: 708, train precision: 0.998800, train loss: 10.600529, valid precision: 0.876800, valid loss: 85.636070
epoch: 709, train precision: 0.998556, train loss: 10.571374, valid precision: 0.876400, valid loss: 84.819151
epoch: 710, train precision: 0.998356, train loss: 10.711174, valid precision: 0.876000, valid loss: 83.883109
epoch: 711, train precision: 0.998133, train loss: 10.757115, valid precision: 0.877000, valid loss: 84.508375
epoch: 712, train precision: 0.997956, train loss: 10.792186, valid precision: 0.876800, valid loss: 85.865602
epoch: 713, train precision: 0.998711, train loss: 10.559693, valid precision: 0.875000, valid loss: 84.069981
epoch: 714, train precision: 0.998378, train loss: 10.687607, valid precision: 0.878600, valid loss: 83.457866
epoch: 715, train precision: 0.998333, train loss: 10.791688, valid precision: 0.874200, valid loss: 82.637947
epoch: 716, train precision: 0.998511, train loss: 10.676188, valid precision: 0.874800, valid loss: 82.888932
epoch: 717, train precision: 0.997867, train loss: 10.837525, valid precision: 0.872800, valid loss: 85.135383
epoch: 718, train precision: 0.998756, train loss: 10.698400, valid precision: 0.872800, valid loss: 82.785365
epoch: 719, train precision: 0.998533, train loss: 10.694238, valid precision: 0.872600, valid loss: 84.194417
epoch: 720, train precision: 0.998044, train loss: 10.832854, valid precision: 0.876000, valid loss: 85.076360
epoch: 721, train precision: 0.998556, train loss: 10.643595, valid precision: 0.877600, valid loss: 86.154799
epoch: 722, train precision: 0.998644, train loss: 10.627717, valid precision: 0.876600, valid loss: 85.447462
epoch: 723, train precision: 0.998800, train loss: 10.594179, valid precision: 0.876800, valid loss: 86.248864
epoch: 724, train precision: 0.998578, train loss: 10.750001, valid precision: 0.874400, valid loss: 85.742088
epoch: 725, train precision: 0.998178, train loss: 10.774101, valid precision: 0.877800, valid loss: 84.332647
epoch: 726, train precision: 0.998178, train loss: 10.785735, valid precision: 0.869200, valid loss: 88.801551
epoch: 727, train precision: 0.998778, train loss: 10.632004, valid precision: 0.873600, valid loss: 87.185721
epoch: 728, train precision: 0.998444, train loss: 10.712342, valid precision: 0.874200, valid loss: 86.253190
epoch: 729, train precision: 0.997956, train loss: 10.868613, valid precision: 0.872000, valid loss: 87.512273
epoch: 730, train precision: 0.998178, train loss: 10.856673, valid precision: 0.873400, valid loss: 86.277939
epoch: 731, train precision: 0.997933, train loss: 10.842223, valid precision: 0.869200, valid loss: 86.318125
epoch: 732, train precision: 0.998933, train loss: 10.561728, valid precision: 0.874600, valid loss: 83.114776
epoch: 733, train precision: 0.998311, train loss: 10.757389, valid precision: 0.878600, valid loss: 85.137074
epoch: 734, train precision: 0.997667, train loss: 10.851902, valid precision: 0.871800, valid loss: 86.528826
epoch: 735, train precision: 0.998378, train loss: 10.691869, valid precision: 0.872400, valid loss: 85.567678
epoch: 736, train precision: 0.998578, train loss: 10.706198, valid precision: 0.873200, valid loss: 84.778748
epoch: 737, train precision: 0.998689, train loss: 10.641003, valid precision: 0.876400, valid loss: 85.943912
epoch: 738, train precision: 0.998067, train loss: 10.769446, valid precision: 0.871200, valid loss: 86.395817
epoch: 739, train precision: 0.998511, train loss: 10.719074, valid precision: 0.867200, valid loss: 86.940598
epoch: 740, train precision: 0.998467, train loss: 10.716002, valid precision: 0.869200, valid loss: 86.004740
epoch: 741, train precision: 0.998222, train loss: 10.782034, valid precision: 0.872400, valid loss: 85.991360
epoch: 742, train precision: 0.998400, train loss: 10.698723, valid precision: 0.870800, valid loss: 85.937120
epoch: 743, train precision: 0.998378, train loss: 10.647877, valid precision: 0.871600, valid loss: 84.928355
epoch: 744, train precision: 0.998267, train loss: 10.717544, valid precision: 0.879200, valid loss: 84.161270
epoch: 745, train precision: 0.998200, train loss: 10.812019, valid precision: 0.875400, valid loss: 83.612982
epoch: 746, train precision: 0.997911, train loss: 10.865044, valid precision: 0.875000, valid loss: 85.970967
epoch: 747, train precision: 0.998778, train loss: 10.639452, valid precision: 0.875400, valid loss: 84.809160
epoch: 748, train precision: 0.998844, train loss: 10.621018, valid precision: 0.877200, valid loss: 84.694923
epoch: 749, train precision: 0.998911, train loss: 10.538855, valid precision: 0.873400, valid loss: 86.935738
epoch: 750, train precision: 0.998400, train loss: 10.723089, valid precision: 0.878200, valid loss: 86.474634
epoch: 751, train precision: 0.998067, train loss: 10.835412, valid precision: 0.871200, valid loss: 90.605980
epoch: 752, train precision: 0.998511, train loss: 10.655953, valid precision: 0.873800, valid loss: 88.590157
epoch: 753, train precision: 0.998378, train loss: 10.711757, valid precision: 0.873800, valid loss: 87.124303
epoch: 754, train precision: 0.998022, train loss: 10.730270, valid precision: 0.874800, valid loss: 87.544123
epoch: 755, train precision: 0.998244, train loss: 10.817102, valid precision: 0.873800, valid loss: 88.280490
epoch: 756, train precision: 0.998489, train loss: 10.751637, valid precision: 0.871200, valid loss: 86.786912
epoch: 757, train precision: 0.998489, train loss: 10.773994, valid precision: 0.871400, valid loss: 88.660235
epoch: 758, train precision: 0.997533, train loss: 11.001096, valid precision: 0.870600, valid loss: 88.200999
epoch: 759, train precision: 0.998044, train loss: 10.783482, valid precision: 0.870800, valid loss: 87.229150
epoch: 760, train precision: 0.998578, train loss: 10.715766, valid precision: 0.877400, valid loss: 86.714889
epoch: 761, train precision: 0.998533, train loss: 10.769036, valid precision: 0.873000, valid loss: 86.838817
epoch: 762, train precision: 0.998644, train loss: 10.663548, valid precision: 0.876800, valid loss: 87.837242
epoch: 763, train precision: 0.998644, train loss: 10.670521, valid precision: 0.870400, valid loss: 86.626666
epoch: 764, train precision: 0.998333, train loss: 10.754992, valid precision: 0.872200, valid loss: 85.970499
epoch: 765, train precision: 0.998222, train loss: 10.842855, valid precision: 0.875000, valid loss: 84.238886
epoch: 766, train precision: 0.998400, train loss: 10.745764, valid precision: 0.873400, valid loss: 85.992463
epoch: 767, train precision: 0.998956, train loss: 10.590790, valid precision: 0.873800, valid loss: 87.412505
epoch: 768, train precision: 0.998467, train loss: 10.690031, valid precision: 0.876400, valid loss: 85.809986
epoch: 769, train precision: 0.998133, train loss: 10.844198, valid precision: 0.877000, valid loss: 85.909163
epoch: 770, train precision: 0.998422, train loss: 10.690487, valid precision: 0.879600, valid loss: 84.066775
epoch: 771, train precision: 0.998289, train loss: 10.848077, valid precision: 0.878600, valid loss: 85.643485
epoch: 772, train precision: 0.998422, train loss: 10.740297, valid precision: 0.880000, valid loss: 84.229115
epoch: 773, train precision: 0.998489, train loss: 10.722820, valid precision: 0.877000, valid loss: 85.992570
epoch: 774, train precision: 0.998622, train loss: 10.716677, valid precision: 0.877000, valid loss: 83.720635
epoch: 775, train precision: 0.998422, train loss: 10.727547, valid precision: 0.870800, valid loss: 86.437782
epoch: 776, train precision: 0.998844, train loss: 10.639961, valid precision: 0.875800, valid loss: 85.668009
epoch: 777, train precision: 0.998556, train loss: 10.703127, valid precision: 0.875400, valid loss: 84.402159
epoch: 778, train precision: 0.998689, train loss: 10.579102, valid precision: 0.876400, valid loss: 86.362796
epoch: 779, train precision: 0.998689, train loss: 10.731079, valid precision: 0.872800, valid loss: 89.453441
epoch: 780, train precision: 0.998000, train loss: 10.841753, valid precision: 0.875800, valid loss: 86.571739
epoch: 781, train precision: 0.998200, train loss: 10.831874, valid precision: 0.873400, valid loss: 87.257452
epoch: 782, train precision: 0.998667, train loss: 10.713297, valid precision: 0.876200, valid loss: 86.578661
epoch: 783, train precision: 0.998489, train loss: 10.695810, valid precision: 0.874400, valid loss: 85.183963
epoch: 784, train precision: 0.998644, train loss: 10.685959, valid precision: 0.874400, valid loss: 86.133624
epoch: 785, train precision: 0.998378, train loss: 10.804768, valid precision: 0.870800, valid loss: 85.693297
epoch: 786, train precision: 0.998311, train loss: 10.774584, valid precision: 0.875200, valid loss: 84.259596
epoch: 787, train precision: 0.998533, train loss: 10.702171, valid precision: 0.873800, valid loss: 85.178712
epoch: 788, train precision: 0.998467, train loss: 10.729036, valid precision: 0.871000, valid loss: 87.426258
epoch: 789, train precision: 0.998044, train loss: 10.856781, valid precision: 0.874000, valid loss: 88.798024
epoch: 790, train precision: 0.998311, train loss: 10.760747, valid precision: 0.872200, valid loss: 88.537299
epoch: 791, train precision: 0.998711, train loss: 10.656943, valid precision: 0.869800, valid loss: 88.812668
epoch: 792, train precision: 0.998244, train loss: 10.822808, valid precision: 0.874600, valid loss: 87.453290
epoch: 793, train precision: 0.998600, train loss: 10.705252, valid precision: 0.873800, valid loss: 86.171990
epoch: 794, train precision: 0.998400, train loss: 10.798652, valid precision: 0.871800, valid loss: 87.835499
epoch: 795, train precision: 0.998222, train loss: 10.788702, valid precision: 0.877800, valid loss: 86.110002
epoch: 796, train precision: 0.998356, train loss: 10.811681, valid precision: 0.870200, valid loss: 85.194607
epoch: 797, train precision: 0.998600, train loss: 10.661118, valid precision: 0.873600, valid loss: 85.173087
epoch: 798, train precision: 0.998533, train loss: 10.716500, valid precision: 0.871600, valid loss: 87.563881
epoch: 799, train precision: 0.998133, train loss: 10.905592, valid precision: 0.872000, valid loss: 87.759438
epoch: 800, train precision: 0.998333, train loss: 10.853407, valid precision: 0.874000, valid loss: 86.944479
epoch: 801, train precision: 0.998533, train loss: 10.732992, valid precision: 0.872800, valid loss: 85.495029
epoch: 802, train precision: 0.998422, train loss: 10.734406, valid precision: 0.873200, valid loss: 86.834368
epoch: 803, train precision: 0.998311, train loss: 10.864396, valid precision: 0.872600, valid loss: 86.865234
epoch: 804, train precision: 0.998333, train loss: 10.801993, valid precision: 0.872400, valid loss: 87.593260
epoch: 805, train precision: 0.998489, train loss: 10.821877, valid precision: 0.872600, valid loss: 88.555344
epoch: 806, train precision: 0.998400, train loss: 10.815981, valid precision: 0.868600, valid loss: 88.448763
epoch: 807, train precision: 0.998000, train loss: 10.815136, valid precision: 0.874400, valid loss: 87.763693
epoch: 808, train precision: 0.998156, train loss: 10.885636, valid precision: 0.869400, valid loss: 88.226749
epoch: 809, train precision: 0.998222, train loss: 10.842380, valid precision: 0.868600, valid loss: 88.695702
epoch: 810, train precision: 0.998667, train loss: 10.713373, valid precision: 0.871800, valid loss: 87.141660
epoch: 811, train precision: 0.998556, train loss: 10.675410, valid precision: 0.868800, valid loss: 90.024640
epoch: 812, train precision: 0.998222, train loss: 10.797314, valid precision: 0.871000, valid loss: 87.409709
epoch: 813, train precision: 0.998267, train loss: 10.806289, valid precision: 0.874000, valid loss: 84.573645
epoch: 814, train precision: 0.998400, train loss: 10.731128, valid precision: 0.875400, valid loss: 87.299554
epoch: 815, train precision: 0.998756, train loss: 10.636400, valid precision: 0.880800, valid loss: 86.532529
epoch: 816, train precision: 0.998489, train loss: 10.732001, valid precision: 0.874200, valid loss: 86.280792
epoch: 817, train precision: 0.998800, train loss: 10.677877, valid precision: 0.874400, valid loss: 85.818924
epoch: 818, train precision: 0.998622, train loss: 10.645047, valid precision: 0.871200, valid loss: 86.901366
epoch: 819, train precision: 0.998244, train loss: 10.767239, valid precision: 0.872000, valid loss: 88.320199
epoch: 820, train precision: 0.998378, train loss: 10.847376, valid precision: 0.874200, valid loss: 86.793564
epoch: 821, train precision: 0.998289, train loss: 10.839025, valid precision: 0.874800, valid loss: 88.018494
epoch: 822, train precision: 0.998600, train loss: 10.728049, valid precision: 0.873000, valid loss: 89.412056
epoch: 823, train precision: 0.998067, train loss: 10.851705, valid precision: 0.872600, valid loss: 86.707258
epoch: 824, train precision: 0.998422, train loss: 10.733191, valid precision: 0.875600, valid loss: 87.383471
epoch: 825, train precision: 0.997511, train loss: 11.074893, valid precision: 0.870800, valid loss: 88.715822
epoch: 826, train precision: 0.998622, train loss: 10.772510, valid precision: 0.874800, valid loss: 85.983860
epoch: 827, train precision: 0.998533, train loss: 10.760494, valid precision: 0.874200, valid loss: 88.381947
epoch: 828, train precision: 0.998267, train loss: 10.843520, valid precision: 0.874800, valid loss: 89.369912
epoch: 829, train precision: 0.998800, train loss: 10.654355, valid precision: 0.874200, valid loss: 87.902050
epoch: 830, train precision: 0.998356, train loss: 10.810785, valid precision: 0.872400, valid loss: 87.841438
epoch: 831, train precision: 0.998733, train loss: 10.690443, valid precision: 0.871800, valid loss: 88.264470
epoch: 832, train precision: 0.998711, train loss: 10.735372, valid precision: 0.868400, valid loss: 90.253911
epoch: 833, train precision: 0.998467, train loss: 10.809831, valid precision: 0.873600, valid loss: 91.920357
epoch: 834, train precision: 0.998556, train loss: 10.708018, valid precision: 0.873000, valid loss: 87.537845
epoch: 835, train precision: 0.998378, train loss: 10.754177, valid precision: 0.871200, valid loss: 89.981728
epoch: 836, train precision: 0.998222, train loss: 10.886300, valid precision: 0.872000, valid loss: 89.785258
epoch: 837, train precision: 0.998978, train loss: 10.648146, valid precision: 0.873800, valid loss: 87.401588
epoch: 838, train precision: 0.998444, train loss: 10.802773, valid precision: 0.872600, valid loss: 88.988028
epoch: 839, train precision: 0.998111, train loss: 10.937706, valid precision: 0.872800, valid loss: 90.251343
epoch: 840, train precision: 0.998311, train loss: 10.829888, valid precision: 0.872600, valid loss: 89.219512
epoch: 841, train precision: 0.998267, train loss: 10.891881, valid precision: 0.870800, valid loss: 87.636406
epoch: 842, train precision: 0.998244, train loss: 10.810825, valid precision: 0.870600, valid loss: 90.262137
epoch: 843, train precision: 0.997733, train loss: 10.941792, valid precision: 0.871000, valid loss: 89.890980
epoch: 844, train precision: 0.998778, train loss: 10.649436, valid precision: 0.874800, valid loss: 88.605288
epoch: 845, train precision: 0.998622, train loss: 10.701766, valid precision: 0.875200, valid loss: 88.463413
epoch: 846, train precision: 0.998956, train loss: 10.598352, valid precision: 0.874000, valid loss: 87.948499
epoch: 847, train precision: 0.998533, train loss: 10.753804, valid precision: 0.872200, valid loss: 89.236986
epoch: 848, train precision: 0.998689, train loss: 10.664933, valid precision: 0.875600, valid loss: 87.888493
epoch: 849, train precision: 0.998667, train loss: 10.733976, valid precision: 0.874000, valid loss: 91.029204
epoch: 850, train precision: 0.998333, train loss: 10.755364, valid precision: 0.870800, valid loss: 89.049899
epoch: 851, train precision: 0.998511, train loss: 10.717204, valid precision: 0.870200, valid loss: 91.362434
epoch: 852, train precision: 0.998778, train loss: 10.636630, valid precision: 0.877000, valid loss: 88.516507
epoch: 853, train precision: 0.998467, train loss: 10.784312, valid precision: 0.871000, valid loss: 89.079871
epoch: 854, train precision: 0.998467, train loss: 10.760405, valid precision: 0.868000, valid loss: 90.074291
epoch: 855, train precision: 0.998444, train loss: 10.759704, valid precision: 0.868200, valid loss: 91.051076
epoch: 856, train precision: 0.998578, train loss: 10.713768, valid precision: 0.872000, valid loss: 87.713128
epoch: 857, train precision: 0.997822, train loss: 11.010829, valid precision: 0.868600, valid loss: 90.043379
epoch: 858, train precision: 0.998422, train loss: 10.890265, valid precision: 0.871800, valid loss: 87.808510
epoch: 859, train precision: 0.998311, train loss: 10.906476, valid precision: 0.872800, valid loss: 88.982665
epoch: 860, train precision: 0.998622, train loss: 10.720556, valid precision: 0.872800, valid loss: 87.670753
epoch: 861, train precision: 0.998200, train loss: 10.785668, valid precision: 0.872600, valid loss: 88.432965
epoch: 862, train precision: 0.998267, train loss: 10.860232, valid precision: 0.867400, valid loss: 91.663124
epoch: 863, train precision: 0.997956, train loss: 10.857425, valid precision: 0.868000, valid loss: 89.161981
epoch: 864, train precision: 0.998511, train loss: 10.808258, valid precision: 0.872000, valid loss: 90.739474
epoch: 865, train precision: 0.998511, train loss: 10.738029, valid precision: 0.870800, valid loss: 88.368024
epoch: 866, train precision: 0.998489, train loss: 10.810527, valid precision: 0.871800, valid loss: 90.922609
epoch: 867, train precision: 0.999156, train loss: 10.618357, valid precision: 0.871200, valid loss: 88.485804
epoch: 868, train precision: 0.998089, train loss: 10.962776, valid precision: 0.866200, valid loss: 90.484446
epoch: 869, train precision: 0.998511, train loss: 10.751442, valid precision: 0.871800, valid loss: 89.957568
epoch: 870, train precision: 0.998222, train loss: 10.860567, valid precision: 0.871000, valid loss: 90.554820
epoch: 871, train precision: 0.998600, train loss: 10.756277, valid precision: 0.873600, valid loss: 90.198832
epoch: 872, train precision: 0.998089, train loss: 10.879679, valid precision: 0.872000, valid loss: 87.910683
epoch: 873, train precision: 0.998667, train loss: 10.783236, valid precision: 0.872600, valid loss: 86.281320
epoch: 874, train precision: 0.998467, train loss: 10.760630, valid precision: 0.871200, valid loss: 86.170206
epoch: 875, train precision: 0.998533, train loss: 10.803295, valid precision: 0.872600, valid loss: 85.236862
epoch: 876, train precision: 0.998822, train loss: 10.726264, valid precision: 0.874200, valid loss: 87.054995
epoch: 877, train precision: 0.998111, train loss: 10.900291, valid precision: 0.872600, valid loss: 88.750717
epoch: 878, train precision: 0.997956, train loss: 10.963728, valid precision: 0.874400, valid loss: 87.539241
epoch: 879, train precision: 0.997844, train loss: 10.994437, valid precision: 0.873800, valid loss: 86.974332
epoch: 880, train precision: 0.998578, train loss: 10.809398, valid precision: 0.871200, valid loss: 88.234579
epoch: 881, train precision: 0.998178, train loss: 10.810450, valid precision: 0.872800, valid loss: 87.386668
epoch: 882, train precision: 0.998556, train loss: 10.782682, valid precision: 0.872000, valid loss: 87.530348
epoch: 883, train precision: 0.998911, train loss: 10.697146, valid precision: 0.877800, valid loss: 86.343767
epoch: 884, train precision: 0.998867, train loss: 10.731320, valid precision: 0.875000, valid loss: 87.244423
epoch: 885, train precision: 0.998733, train loss: 10.716100, valid precision: 0.873600, valid loss: 87.163130
epoch: 886, train precision: 0.998556, train loss: 10.743647, valid precision: 0.875800, valid loss: 86.555045
epoch: 887, train precision: 0.998689, train loss: 10.729183, valid precision: 0.874000, valid loss: 87.047256
epoch: 888, train precision: 0.998200, train loss: 10.844215, valid precision: 0.876200, valid loss: 86.270494
epoch: 889, train precision: 0.998689, train loss: 10.773852, valid precision: 0.872800, valid loss: 88.305036
epoch: 890, train precision: 0.998667, train loss: 10.741679, valid precision: 0.872200, valid loss: 87.084099
epoch: 891, train precision: 0.998422, train loss: 10.863183, valid precision: 0.876200, valid loss: 86.665041
epoch: 892, train precision: 0.998644, train loss: 10.663738, valid precision: 0.871200, valid loss: 86.737531
epoch: 893, train precision: 0.998333, train loss: 10.841032, valid precision: 0.874600, valid loss: 88.425189
epoch: 894, train precision: 0.998822, train loss: 10.716701, valid precision: 0.876800, valid loss: 86.402119
epoch: 895, train precision: 0.999111, train loss: 10.607611, valid precision: 0.875600, valid loss: 87.355603
epoch: 896, train precision: 0.998511, train loss: 10.831694, valid precision: 0.873800, valid loss: 86.668682
epoch: 897, train precision: 0.998756, train loss: 10.683299, valid precision: 0.875600, valid loss: 87.241166
epoch: 898, train precision: 0.998533, train loss: 10.783770, valid precision: 0.877400, valid loss: 87.803069
epoch: 899, train precision: 0.998511, train loss: 10.740348, valid precision: 0.877600, valid loss: 86.479870
epoch: 900, train precision: 0.998111, train loss: 10.838590, valid precision: 0.876200, valid loss: 88.002809
epoch: 901, train precision: 0.998667, train loss: 10.769669, valid precision: 0.880200, valid loss: 86.530048
epoch: 902, train precision: 0.998578, train loss: 10.752629, valid precision: 0.877600, valid loss: 87.144597
epoch: 903, train precision: 0.998778, train loss: 10.743751, valid precision: 0.876600, valid loss: 88.685405
epoch: 904, train precision: 0.998022, train loss: 10.973685, valid precision: 0.876400, valid loss: 89.270495
epoch: 905, train precision: 0.997800, train loss: 10.990957, valid precision: 0.875000, valid loss: 89.373395
epoch: 906, train precision: 0.998400, train loss: 10.794490, valid precision: 0.872600, valid loss: 89.366535
epoch: 907, train precision: 0.998600, train loss: 10.713014, valid precision: 0.873000, valid loss: 88.218353
epoch: 908, train precision: 0.997956, train loss: 10.915133, valid precision: 0.873400, valid loss: 89.062670
epoch: 909, train precision: 0.998289, train loss: 10.780977, valid precision: 0.873200, valid loss: 87.836454
epoch: 910, train precision: 0.998111, train loss: 10.853676, valid precision: 0.871600, valid loss: 89.717225
epoch: 911, train precision: 0.998778, train loss: 10.739035, valid precision: 0.875200, valid loss: 87.555580
epoch: 912, train precision: 0.998756, train loss: 10.758086, valid precision: 0.873600, valid loss: 88.862159
epoch: 913, train precision: 0.998444, train loss: 10.831850, valid precision: 0.874600, valid loss: 85.687444
epoch: 914, train precision: 0.999111, train loss: 10.588514, valid precision: 0.872600, valid loss: 87.199060
epoch: 915, train precision: 0.998378, train loss: 10.855086, valid precision: 0.875000, valid loss: 85.562203
epoch: 916, train precision: 0.998489, train loss: 10.877093, valid precision: 0.875600, valid loss: 86.879178
epoch: 917, train precision: 0.998378, train loss: 10.821526, valid precision: 0.875400, valid loss: 84.836105
epoch: 918, train precision: 0.998356, train loss: 10.836916, valid precision: 0.876200, valid loss: 86.731064
epoch: 919, train precision: 0.998622, train loss: 10.735292, valid precision: 0.876000, valid loss: 86.302425
epoch: 920, train precision: 0.998644, train loss: 10.745490, valid precision: 0.872600, valid loss: 88.743324
epoch: 921, train precision: 0.998889, train loss: 10.652640, valid precision: 0.874000, valid loss: 89.355423
epoch: 922, train precision: 0.998889, train loss: 10.695566, valid precision: 0.873000, valid loss: 86.761432
epoch: 923, train precision: 0.998956, train loss: 10.669843, valid precision: 0.872200, valid loss: 85.778416
epoch: 924, train precision: 0.998600, train loss: 10.691331, valid precision: 0.875800, valid loss: 85.197638
epoch: 925, train precision: 0.998467, train loss: 10.769473, valid precision: 0.873400, valid loss: 87.970335
epoch: 926, train precision: 0.998689, train loss: 10.724045, valid precision: 0.872400, valid loss: 88.815735
epoch: 927, train precision: 0.998711, train loss: 10.711299, valid precision: 0.876800, valid loss: 88.867587
epoch: 928, train precision: 0.998578, train loss: 10.719795, valid precision: 0.875200, valid loss: 86.404031
epoch: 929, train precision: 0.998644, train loss: 10.752188, valid precision: 0.873400, valid loss: 89.215418
epoch: 930, train precision: 0.998511, train loss: 10.768705, valid precision: 0.875400, valid loss: 86.030835
epoch: 931, train precision: 0.998556, train loss: 10.780522, valid precision: 0.873600, valid loss: 86.477290
epoch: 932, train precision: 0.998622, train loss: 10.711536, valid precision: 0.870200, valid loss: 89.818991
epoch: 933, train precision: 0.998289, train loss: 10.830127, valid precision: 0.872400, valid loss: 89.560265
epoch: 934, train precision: 0.998578, train loss: 10.707227, valid precision: 0.876200, valid loss: 90.724172
epoch: 935, train precision: 0.998511, train loss: 10.760896, valid precision: 0.871600, valid loss: 90.191139
epoch: 936, train precision: 0.998689, train loss: 10.749361, valid precision: 0.869600, valid loss: 89.541517
epoch: 937, train precision: 0.998689, train loss: 10.770706, valid precision: 0.872600, valid loss: 89.815699
epoch: 938, train precision: 0.998533, train loss: 10.750769, valid precision: 0.871800, valid loss: 90.357020
epoch: 939, train precision: 0.998067, train loss: 10.894169, valid precision: 0.870400, valid loss: 90.658073
epoch: 940, train precision: 0.998644, train loss: 10.782857, valid precision: 0.874800, valid loss: 89.018237
epoch: 941, train precision: 0.998733, train loss: 10.667437, valid precision: 0.874200, valid loss: 90.784426
epoch: 942, train precision: 0.998400, train loss: 10.833048, valid precision: 0.870800, valid loss: 91.338936
epoch: 943, train precision: 0.998133, train loss: 10.898290, valid precision: 0.871000, valid loss: 92.482576
epoch: 944, train precision: 0.998889, train loss: 10.644130, valid precision: 0.875800, valid loss: 89.533797
epoch: 945, train precision: 0.998444, train loss: 10.843493, valid precision: 0.872400, valid loss: 88.640899
epoch: 946, train precision: 0.998333, train loss: 10.778414, valid precision: 0.870400, valid loss: 91.016468
epoch: 947, train precision: 0.998867, train loss: 10.662564, valid precision: 0.870800, valid loss: 87.966553
epoch: 948, train precision: 0.998800, train loss: 10.698458, valid precision: 0.872600, valid loss: 88.123996
epoch: 949, train precision: 0.998956, train loss: 10.625422, valid precision: 0.870400, valid loss: 90.505014
epoch: 950, train precision: 0.998733, train loss: 10.726130, valid precision: 0.877000, valid loss: 88.124016
epoch: 951, train precision: 0.998556, train loss: 10.759514, valid precision: 0.874400, valid loss: 88.470203
epoch: 952, train precision: 0.998511, train loss: 10.714355, valid precision: 0.875000, valid loss: 89.292663
epoch: 953, train precision: 0.998356, train loss: 10.830283, valid precision: 0.872000, valid loss: 89.096216
epoch: 954, train precision: 0.998467, train loss: 10.807169, valid precision: 0.871800, valid loss: 89.089071
epoch: 955, train precision: 0.998222, train loss: 10.906235, valid precision: 0.869800, valid loss: 91.188231
epoch: 956, train precision: 0.998889, train loss: 10.702786, valid precision: 0.877600, valid loss: 87.026199
epoch: 957, train precision: 0.998822, train loss: 10.692041, valid precision: 0.878200, valid loss: 85.323185
epoch: 958, train precision: 0.998756, train loss: 10.750651, valid precision: 0.873600, valid loss: 86.535642
epoch: 959, train precision: 0.998267, train loss: 10.844104, valid precision: 0.872800, valid loss: 90.112786
epoch: 960, train precision: 0.998800, train loss: 10.678890, valid precision: 0.878600, valid loss: 85.860788
epoch: 961, train precision: 0.998533, train loss: 10.781581, valid precision: 0.873400, valid loss: 88.566519
epoch: 962, train precision: 0.998867, train loss: 10.696239, valid precision: 0.874600, valid loss: 87.966506
epoch: 963, train precision: 0.998444, train loss: 10.802731, valid precision: 0.872000, valid loss: 87.610679
epoch: 964, train precision: 0.998333, train loss: 10.790579, valid precision: 0.874000, valid loss: 85.560540
epoch: 965, train precision: 0.998133, train loss: 10.804445, valid precision: 0.872800, valid loss: 88.202241
epoch: 966, train precision: 0.998600, train loss: 10.761508, valid precision: 0.872400, valid loss: 88.477015
epoch: 967, train precision: 0.998089, train loss: 10.930783, valid precision: 0.873800, valid loss: 90.243634
epoch: 968, train precision: 0.998667, train loss: 10.741367, valid precision: 0.876200, valid loss: 87.037439
epoch: 969, train precision: 0.998378, train loss: 10.819308, valid precision: 0.872000, valid loss: 88.108248
epoch: 970, train precision: 0.998556, train loss: 10.757479, valid precision: 0.873400, valid loss: 88.202573
epoch: 971, train precision: 0.998578, train loss: 10.809487, valid precision: 0.869400, valid loss: 91.478691
epoch: 972, train precision: 0.998378, train loss: 10.736812, valid precision: 0.870400, valid loss: 89.147197
epoch: 973, train precision: 0.998733, train loss: 10.729898, valid precision: 0.872200, valid loss: 88.851756
epoch: 974, train precision: 0.998600, train loss: 10.825236, valid precision: 0.867600, valid loss: 91.485967
epoch: 975, train precision: 0.998667, train loss: 10.800414, valid precision: 0.872200, valid loss: 88.875426
epoch: 976, train precision: 0.998556, train loss: 10.813633, valid precision: 0.867200, valid loss: 90.237753
epoch: 977, train precision: 0.998667, train loss: 10.734039, valid precision: 0.871200, valid loss: 91.184846
epoch: 978, train precision: 0.998622, train loss: 10.831568, valid precision: 0.871800, valid loss: 89.737042
epoch: 979, train precision: 0.998400, train loss: 10.843368, valid precision: 0.871800, valid loss: 90.933198
epoch: 980, train precision: 0.998933, train loss: 10.645401, valid precision: 0.874400, valid loss: 90.796504
epoch: 981, train precision: 0.998689, train loss: 10.669000, valid precision: 0.873000, valid loss: 90.178903
epoch: 982, train precision: 0.998711, train loss: 10.667974, valid precision: 0.870800, valid loss: 91.390178
epoch: 983, train precision: 0.998578, train loss: 10.754707, valid precision: 0.873000, valid loss: 89.758005
epoch: 984, train precision: 0.998556, train loss: 10.732441, valid precision: 0.871200, valid loss: 91.031522
epoch: 985, train precision: 0.998778, train loss: 10.737133, valid precision: 0.868800, valid loss: 91.211841
epoch: 986, train precision: 0.998444, train loss: 10.860119, valid precision: 0.866600, valid loss: 92.661098
epoch: 987, train precision: 0.998578, train loss: 10.790567, valid precision: 0.869600, valid loss: 91.234927
epoch: 988, train precision: 0.998867, train loss: 10.660540, valid precision: 0.869200, valid loss: 91.488316
epoch: 989, train precision: 0.998644, train loss: 10.766399, valid precision: 0.868800, valid loss: 90.108797
epoch: 990, train precision: 0.998556, train loss: 10.722073, valid precision: 0.871200, valid loss: 89.586462
epoch: 991, train precision: 0.998667, train loss: 10.772730, valid precision: 0.871600, valid loss: 89.231460
epoch: 992, train precision: 0.998889, train loss: 10.736600, valid precision: 0.869000, valid loss: 88.292364
epoch: 993, train precision: 0.998911, train loss: 10.664996, valid precision: 0.869800, valid loss: 90.725846
epoch: 994, train precision: 0.998756, train loss: 10.744858, valid precision: 0.868000, valid loss: 89.092298
epoch: 995, train precision: 0.998622, train loss: 10.726269, valid precision: 0.868000, valid loss: 90.914363
epoch: 996, train precision: 0.998467, train loss: 10.846556, valid precision: 0.873600, valid loss: 89.600765
epoch: 997, train precision: 0.998311, train loss: 10.910049, valid precision: 0.873400, valid loss: 89.108628
epoch: 998, train precision: 0.998622, train loss: 10.758715, valid precision: 0.870400, valid loss: 89.330223
epoch: 999, train precision: 0.998667, train loss: 10.728182, valid precision: 0.873600, valid loss: 88.140496
epoch: 1000, train precision: 0.997267, train loss: 11.196806, valid precision: 0.869800, valid loss: 89.510886
epoch: 1001, train precision: 0.998911, train loss: 10.697470, valid precision: 0.874200, valid loss: 88.368654
epoch: 1002, train precision: 0.998822, train loss: 10.685271, valid precision: 0.874200, valid loss: 87.246649
epoch: 1003, train precision: 0.998089, train loss: 10.811418, valid precision: 0.874000, valid loss: 89.725833
epoch: 1004, train precision: 0.998867, train loss: 10.746875, valid precision: 0.872400, valid loss: 89.370369
epoch: 1005, train precision: 0.998711, train loss: 10.665088, valid precision: 0.873600, valid loss: 88.052866
epoch: 1006, train precision: 0.998978, train loss: 10.729724, valid precision: 0.873400, valid loss: 88.797548
epoch: 1007, train precision: 0.998644, train loss: 10.709983, valid precision: 0.874400, valid loss: 89.197882
epoch: 1008, train precision: 0.998933, train loss: 10.689747, valid precision: 0.874000, valid loss: 89.324929
epoch: 1009, train precision: 0.998733, train loss: 10.720672, valid precision: 0.875400, valid loss: 86.749999
epoch: 1010, train precision: 0.998889, train loss: 10.677385, valid precision: 0.873800, valid loss: 90.775879
epoch: 1011, train precision: 0.998200, train loss: 10.952018, valid precision: 0.869400, valid loss: 91.008186
epoch: 1012, train precision: 0.998756, train loss: 10.696982, valid precision: 0.871400, valid loss: 92.245004
epoch: 1013, train precision: 0.998111, train loss: 10.949631, valid precision: 0.870400, valid loss: 90.881159
epoch: 1014, train precision: 0.998889, train loss: 10.703631, valid precision: 0.872200, valid loss: 91.399410
epoch: 1015, train precision: 0.998289, train loss: 10.879352, valid precision: 0.871400, valid loss: 91.002551
epoch: 1016, train precision: 0.998711, train loss: 10.750505, valid precision: 0.875400, valid loss: 89.775533
epoch: 1017, train precision: 0.998933, train loss: 10.617529, valid precision: 0.874800, valid loss: 93.724011
epoch: 1018, train precision: 0.998511, train loss: 10.809930, valid precision: 0.868600, valid loss: 93.074671
epoch: 1019, train precision: 0.998267, train loss: 10.813534, valid precision: 0.873200, valid loss: 90.873279
epoch: 1020, train precision: 0.998244, train loss: 10.924395, valid precision: 0.870400, valid loss: 91.338066
epoch: 1021, train precision: 0.998333, train loss: 10.928386, valid precision: 0.868200, valid loss: 90.452759
epoch: 1022, train precision: 0.998156, train loss: 10.872862, valid precision: 0.872800, valid loss: 89.945378
epoch: 1023, train precision: 0.998644, train loss: 10.823218, valid precision: 0.874400, valid loss: 89.492167
epoch: 1024, train precision: 0.998867, train loss: 10.733361, valid precision: 0.876200, valid loss: 89.745055
epoch: 1025, train precision: 0.998556, train loss: 10.856288, valid precision: 0.874600, valid loss: 89.453403
epoch: 1026, train precision: 0.998422, train loss: 10.863474, valid precision: 0.867600, valid loss: 93.488152
epoch: 1027, train precision: 0.998333, train loss: 10.862491, valid precision: 0.872600, valid loss: 91.275551
epoch: 1028, train precision: 0.998822, train loss: 10.784021, valid precision: 0.871600, valid loss: 88.996256
epoch: 1029, train precision: 0.998778, train loss: 10.723304, valid precision: 0.871400, valid loss: 88.955561
epoch: 1030, train precision: 0.998400, train loss: 10.828439, valid precision: 0.868000, valid loss: 90.929029
epoch: 1031, train precision: 0.998800, train loss: 10.751576, valid precision: 0.868800, valid loss: 91.080706
epoch: 1032, train precision: 0.998756, train loss: 10.731879, valid precision: 0.871000, valid loss: 91.010395
epoch: 1033, train precision: 0.998022, train loss: 10.927532, valid precision: 0.872600, valid loss: 92.931969
epoch: 1034, train precision: 0.999111, train loss: 10.611678, valid precision: 0.875200, valid loss: 89.862582
epoch: 1035, train precision: 0.998822, train loss: 10.754588, valid precision: 0.874400, valid loss: 88.826408
epoch: 1036, train precision: 0.998867, train loss: 10.740076, valid precision: 0.873600, valid loss: 88.894925
epoch: 1037, train precision: 0.998422, train loss: 10.799594, valid precision: 0.874400, valid loss: 90.405204
epoch: 1038, train precision: 0.998644, train loss: 10.812286, valid precision: 0.875200, valid loss: 88.029759
epoch: 1039, train precision: 0.998400, train loss: 10.830178, valid precision: 0.870600, valid loss: 90.985392
epoch: 1040, train precision: 0.998156, train loss: 10.939394, valid precision: 0.872200, valid loss: 91.309524
epoch: 1041, train precision: 0.998822, train loss: 10.663848, valid precision: 0.873600, valid loss: 91.868291
epoch: 1042, train precision: 0.998244, train loss: 10.868572, valid precision: 0.870800, valid loss: 92.318434
epoch: 1043, train precision: 0.998756, train loss: 10.728920, valid precision: 0.874000, valid loss: 92.301020
epoch: 1044, train precision: 0.998600, train loss: 10.884237, valid precision: 0.870600, valid loss: 92.202235
epoch: 1045, train precision: 0.998778, train loss: 10.729988, valid precision: 0.869400, valid loss: 91.781625
epoch: 1046, train precision: 0.998578, train loss: 10.796860, valid precision: 0.871400, valid loss: 92.135769
epoch: 1047, train precision: 0.998578, train loss: 10.854575, valid precision: 0.871400, valid loss: 90.152675
epoch: 1048, train precision: 0.998444, train loss: 10.753033, valid precision: 0.872200, valid loss: 89.926457
epoch: 1049, train precision: 0.998933, train loss: 10.713876, valid precision: 0.871800, valid loss: 90.262446
epoch: 1050, train precision: 0.998200, train loss: 10.871202, valid precision: 0.871800, valid loss: 88.353661
epoch: 1051, train precision: 0.998822, train loss: 10.691118, valid precision: 0.871800, valid loss: 91.339674
epoch: 1052, train precision: 0.998711, train loss: 10.726850, valid precision: 0.873200, valid loss: 91.794428
epoch: 1053, train precision: 0.998511, train loss: 10.810118, valid precision: 0.874400, valid loss: 88.609396
epoch: 1054, train precision: 0.998933, train loss: 10.693158, valid precision: 0.874600, valid loss: 88.987602
epoch: 1055, train precision: 0.998644, train loss: 10.796528, valid precision: 0.878800, valid loss: 89.820949
epoch: 1056, train precision: 0.998022, train loss: 10.936374, valid precision: 0.870600, valid loss: 90.985932
epoch: 1057, train precision: 0.999089, train loss: 10.626675, valid precision: 0.875000, valid loss: 88.458525
epoch: 1058, train precision: 0.998511, train loss: 10.888642, valid precision: 0.874000, valid loss: 88.828786
epoch: 1059, train precision: 0.998444, train loss: 10.817456, valid precision: 0.874400, valid loss: 89.389210
epoch: 1060, train precision: 0.999111, train loss: 10.584861, valid precision: 0.872200, valid loss: 89.492695
epoch: 1061, train precision: 0.998667, train loss: 10.765007, valid precision: 0.876200, valid loss: 86.898466
epoch: 1062, train precision: 0.998911, train loss: 10.681552, valid precision: 0.872400, valid loss: 89.972286
epoch: 1063, train precision: 0.998400, train loss: 10.853088, valid precision: 0.874600, valid loss: 89.950898
epoch: 1064, train precision: 0.998889, train loss: 10.733587, valid precision: 0.875000, valid loss: 90.914630
epoch: 1065, train precision: 0.998800, train loss: 10.700791, valid precision: 0.871200, valid loss: 88.762435
epoch: 1066, train precision: 0.998067, train loss: 10.893530, valid precision: 0.869800, valid loss: 92.071121
epoch: 1067, train precision: 0.998378, train loss: 10.828622, valid precision: 0.872600, valid loss: 91.178524
epoch: 1068, train precision: 0.998556, train loss: 10.781501, valid precision: 0.871600, valid loss: 90.899914
epoch: 1069, train precision: 0.999178, train loss: 10.697790, valid precision: 0.869200, valid loss: 89.407663
epoch: 1070, train precision: 0.999044, train loss: 10.659596, valid precision: 0.867400, valid loss: 90.115060
epoch: 1071, train precision: 0.998733, train loss: 10.759007, valid precision: 0.875200, valid loss: 87.678261
epoch: 1072, train precision: 0.998711, train loss: 10.731503, valid precision: 0.873200, valid loss: 91.626716
epoch: 1073, train precision: 0.998689, train loss: 10.708500, valid precision: 0.872400, valid loss: 91.506961
epoch: 1074, train precision: 0.998533, train loss: 10.811938, valid precision: 0.870000, valid loss: 90.488342
epoch: 1075, train precision: 0.998956, train loss: 10.655646, valid precision: 0.873200, valid loss: 91.410058
epoch: 1076, train precision: 0.998756, train loss: 10.781385, valid precision: 0.874600, valid loss: 90.338583
epoch: 1077, train precision: 0.998622, train loss: 10.772130, valid precision: 0.868800, valid loss: 91.296180
epoch: 1078, train precision: 0.998756, train loss: 10.760802, valid precision: 0.870200, valid loss: 91.798890
epoch: 1079, train precision: 0.998511, train loss: 10.866328, valid precision: 0.872000, valid loss: 91.585959
epoch: 1080, train precision: 0.998556, train loss: 10.807586, valid precision: 0.872800, valid loss: 89.338246
epoch: 1081, train precision: 0.998622, train loss: 10.782428, valid precision: 0.871600, valid loss: 90.702241
epoch: 1082, train precision: 0.998422, train loss: 10.829541, valid precision: 0.869000, valid loss: 90.781121
epoch: 1083, train precision: 0.999000, train loss: 10.672215, valid precision: 0.871800, valid loss: 90.973313
epoch: 1084, train precision: 0.998689, train loss: 10.743785, valid precision: 0.871400, valid loss: 91.566433
epoch: 1085, train precision: 0.998467, train loss: 10.839634, valid precision: 0.867600, valid loss: 91.875412
epoch: 1086, train precision: 0.998467, train loss: 10.833425, valid precision: 0.870000, valid loss: 89.721491
epoch: 1087, train precision: 0.998267, train loss: 10.910962, valid precision: 0.869000, valid loss: 89.908068
epoch: 1088, train precision: 0.998756, train loss: 10.757622, valid precision: 0.870400, valid loss: 90.992743
epoch: 1089, train precision: 0.998956, train loss: 10.679543, valid precision: 0.870000, valid loss: 89.929361
epoch: 1090, train precision: 0.999044, train loss: 10.621089, valid precision: 0.868000, valid loss: 90.446293
epoch: 1091, train precision: 0.998444, train loss: 10.866065, valid precision: 0.872000, valid loss: 89.051887
epoch: 1092, train precision: 0.998711, train loss: 10.786018, valid precision: 0.866000, valid loss: 89.704361
epoch: 1093, train precision: 0.998778, train loss: 10.724217, valid precision: 0.871400, valid loss: 88.902899
epoch: 1094, train precision: 0.998978, train loss: 10.651077, valid precision: 0.868400, valid loss: 91.984362
epoch: 1095, train precision: 0.998778, train loss: 10.686118, valid precision: 0.868200, valid loss: 90.383684
epoch: 1096, train precision: 0.998822, train loss: 10.743391, valid precision: 0.872000, valid loss: 89.200588
epoch: 1097, train precision: 0.998378, train loss: 10.863811, valid precision: 0.870800, valid loss: 88.067370
epoch: 1098, train precision: 0.998600, train loss: 10.809907, valid precision: 0.870000, valid loss: 90.807594
epoch: 1099, train precision: 0.998756, train loss: 10.753842, valid precision: 0.874600, valid loss: 88.348042
epoch: 1100, train precision: 0.998889, train loss: 10.733963, valid precision: 0.870600, valid loss: 90.359102
epoch: 1101, train precision: 0.998889, train loss: 10.738402, valid precision: 0.871800, valid loss: 90.329931
epoch: 1102, train precision: 0.998622, train loss: 10.782954, valid precision: 0.872400, valid loss: 91.087524
epoch: 1103, train precision: 0.998844, train loss: 10.747937, valid precision: 0.873800, valid loss: 85.755314
epoch: 1104, train precision: 0.998756, train loss: 10.754290, valid precision: 0.872800, valid loss: 87.869859
epoch: 1105, train precision: 0.998178, train loss: 10.962231, valid precision: 0.871200, valid loss: 90.422648
epoch: 1106, train precision: 0.998867, train loss: 10.664120, valid precision: 0.870400, valid loss: 89.826399
epoch: 1107, train precision: 0.998156, train loss: 10.980940, valid precision: 0.873800, valid loss: 90.674084
epoch: 1108, train precision: 0.999067, train loss: 10.667143, valid precision: 0.873000, valid loss: 89.277239
epoch: 1109, train precision: 0.998756, train loss: 10.751777, valid precision: 0.872000, valid loss: 89.453789
epoch: 1110, train precision: 0.998711, train loss: 10.744306, valid precision: 0.873200, valid loss: 90.651546
epoch: 1111, train precision: 0.998444, train loss: 10.842471, valid precision: 0.877600, valid loss: 87.803457
epoch: 1112, train precision: 0.998622, train loss: 10.790915, valid precision: 0.869400, valid loss: 90.081603
epoch: 1113, train precision: 0.998733, train loss: 10.793929, valid precision: 0.871200, valid loss: 88.713230
epoch: 1114, train precision: 0.998933, train loss: 10.737024, valid precision: 0.871800, valid loss: 91.532608
epoch: 1115, train precision: 0.997956, train loss: 10.974698, valid precision: 0.872200, valid loss: 90.817253
epoch: 1116, train precision: 0.998600, train loss: 10.804135, valid precision: 0.873800, valid loss: 89.654717
epoch: 1117, train precision: 0.998978, train loss: 10.705705, valid precision: 0.873800, valid loss: 90.630347
epoch: 1118, train precision: 0.998444, train loss: 10.908232, valid precision: 0.870600, valid loss: 91.477732
epoch: 1119, train precision: 0.998333, train loss: 10.852577, valid precision: 0.870200, valid loss: 92.415540
epoch: 1120, train precision: 0.998889, train loss: 10.701223, valid precision: 0.872600, valid loss: 90.643775
epoch: 1121, train precision: 0.998711, train loss: 10.728863, valid precision: 0.874400, valid loss: 92.086141
epoch: 1122, train precision: 0.998733, train loss: 10.802636, valid precision: 0.876800, valid loss: 90.178945
epoch: 1123, train precision: 0.998667, train loss: 10.716012, valid precision: 0.874400, valid loss: 91.211947
epoch: 1124, train precision: 0.998911, train loss: 10.628654, valid precision: 0.877000, valid loss: 90.780015
epoch: 1125, train precision: 0.998733, train loss: 10.734744, valid precision: 0.874400, valid loss: 91.402650
epoch: 1126, train precision: 0.998800, train loss: 10.719918, valid precision: 0.870600, valid loss: 89.664908
epoch: 1127, train precision: 0.998400, train loss: 10.831704, valid precision: 0.870000, valid loss: 92.374853
epoch: 1128, train precision: 0.999022, train loss: 10.670991, valid precision: 0.875400, valid loss: 90.268187
epoch: 1129, train precision: 0.998733, train loss: 10.731150, valid precision: 0.879800, valid loss: 89.768423
epoch: 1130, train precision: 0.998889, train loss: 10.715228, valid precision: 0.877200, valid loss: 89.417880
epoch: 1131, train precision: 0.998933, train loss: 10.716212, valid precision: 0.877800, valid loss: 88.803630
epoch: 1132, train precision: 0.998911, train loss: 10.672978, valid precision: 0.874200, valid loss: 89.354342
epoch: 1133, train precision: 0.998111, train loss: 10.869044, valid precision: 0.873000, valid loss: 90.591180
epoch: 1134, train precision: 0.999067, train loss: 10.691539, valid precision: 0.875000, valid loss: 92.272872
epoch: 1135, train precision: 0.998600, train loss: 10.781156, valid precision: 0.871000, valid loss: 88.826692
epoch: 1136, train precision: 0.998511, train loss: 10.864384, valid precision: 0.875600, valid loss: 89.362487
epoch: 1137, train precision: 0.998667, train loss: 10.769623, valid precision: 0.872000, valid loss: 91.367282
epoch: 1138, train precision: 0.999222, train loss: 10.641682, valid precision: 0.870800, valid loss: 91.885295
epoch: 1139, train precision: 0.998133, train loss: 10.916426, valid precision: 0.872400, valid loss: 89.845885
epoch: 1140, train precision: 0.998867, train loss: 10.735025, valid precision: 0.872200, valid loss: 90.514037
epoch: 1141, train precision: 0.998867, train loss: 10.709179, valid precision: 0.873800, valid loss: 89.747457
epoch: 1142, train precision: 0.998533, train loss: 10.808064, valid precision: 0.874600, valid loss: 89.178427
epoch: 1143, train precision: 0.998689, train loss: 10.838610, valid precision: 0.871600, valid loss: 92.315559
epoch: 1144, train precision: 0.998867, train loss: 10.716986, valid precision: 0.874400, valid loss: 89.910110
epoch: 1145, train precision: 0.999067, train loss: 10.719597, valid precision: 0.873600, valid loss: 88.707842
epoch: 1146, train precision: 0.998644, train loss: 10.788252, valid precision: 0.871200, valid loss: 87.947892
epoch: 1147, train precision: 0.998378, train loss: 10.853954, valid precision: 0.871800, valid loss: 87.284115
epoch: 1148, train precision: 0.998178, train loss: 10.935729, valid precision: 0.869800, valid loss: 86.615279
epoch: 1149, train precision: 0.998800, train loss: 10.739359, valid precision: 0.875400, valid loss: 86.238827
epoch: 1150, train precision: 0.999067, train loss: 10.671935, valid precision: 0.873800, valid loss: 87.879934
epoch: 1151, train precision: 0.998600, train loss: 10.818815, valid precision: 0.872600, valid loss: 88.134861
epoch: 1152, train precision: 0.998578, train loss: 10.751143, valid precision: 0.873800, valid loss: 90.061740
epoch: 1153, train precision: 0.998756, train loss: 10.728425, valid precision: 0.873200, valid loss: 87.915927
epoch: 1154, train precision: 0.998933, train loss: 10.684138, valid precision: 0.870400, valid loss: 87.547013
epoch: 1155, train precision: 0.999067, train loss: 10.703089, valid precision: 0.872800, valid loss: 88.972152
epoch: 1156, train precision: 0.998956, train loss: 10.694924, valid precision: 0.873200, valid loss: 86.981859
epoch: 1157, train precision: 0.998844, train loss: 10.699620, valid precision: 0.873600, valid loss: 88.949876
epoch: 1158, train precision: 0.998333, train loss: 10.926632, valid precision: 0.878000, valid loss: 87.971905
epoch: 1159, train precision: 0.998711, train loss: 10.758260, valid precision: 0.874800, valid loss: 89.904084
epoch: 1160, train precision: 0.998844, train loss: 10.768782, valid precision: 0.874600, valid loss: 91.439086
epoch: 1161, train precision: 0.998378, train loss: 10.821279, valid precision: 0.875600, valid loss: 90.524135
epoch: 1162, train precision: 0.998444, train loss: 10.807033, valid precision: 0.874800, valid loss: 88.950106
epoch: 1163, train precision: 0.998533, train loss: 10.825818, valid precision: 0.872800, valid loss: 90.622904
epoch: 1164, train precision: 0.998889, train loss: 10.695492, valid precision: 0.874800, valid loss: 87.807897
epoch: 1165, train precision: 0.998822, train loss: 10.764499, valid precision: 0.874600, valid loss: 89.496242
epoch: 1166, train precision: 0.998511, train loss: 10.856339, valid precision: 0.873600, valid loss: 89.310396
epoch: 1167, train precision: 0.998844, train loss: 10.727451, valid precision: 0.878200, valid loss: 87.397844
epoch: 1168, train precision: 0.998622, train loss: 10.774364, valid precision: 0.875200, valid loss: 89.590686
epoch: 1169, train precision: 0.998644, train loss: 10.777184, valid precision: 0.871200, valid loss: 90.279798
epoch: 1170, train precision: 0.999111, train loss: 10.683044, valid precision: 0.874600, valid loss: 88.866517
epoch: 1171, train precision: 0.998178, train loss: 10.920865, valid precision: 0.880200, valid loss: 87.815482
epoch: 1172, train precision: 0.998889, train loss: 10.677714, valid precision: 0.878800, valid loss: 89.481340
epoch: 1173, train precision: 0.998911, train loss: 10.666263, valid precision: 0.879000, valid loss: 88.636369
epoch: 1174, train precision: 0.998778, train loss: 10.743261, valid precision: 0.877200, valid loss: 89.414634
epoch: 1175, train precision: 0.998556, train loss: 10.774157, valid precision: 0.874800, valid loss: 90.079304
epoch: 1176, train precision: 0.998378, train loss: 10.856019, valid precision: 0.876200, valid loss: 89.787360
epoch: 1177, train precision: 0.998778, train loss: 10.761045, valid precision: 0.878800, valid loss: 89.137215
epoch: 1178, train precision: 0.998733, train loss: 10.725690, valid precision: 0.875600, valid loss: 89.516809
epoch: 1179, train precision: 0.998400, train loss: 10.827596, valid precision: 0.878800, valid loss: 88.319547
epoch: 1180, train precision: 0.999178, train loss: 10.592592, valid precision: 0.879800, valid loss: 87.417741
epoch: 1181, train precision: 0.998667, train loss: 10.709071, valid precision: 0.875200, valid loss: 88.483432
epoch: 1182, train precision: 0.998756, train loss: 10.726435, valid precision: 0.879400, valid loss: 88.231656
epoch: 1183, train precision: 0.998956, train loss: 10.703296, valid precision: 0.876200, valid loss: 88.021091
epoch: 1184, train precision: 0.998844, train loss: 10.751727, valid precision: 0.876400, valid loss: 88.694229
epoch: 1185, train precision: 0.998933, train loss: 10.685057, valid precision: 0.876400, valid loss: 86.294432
epoch: 1186, train precision: 0.998933, train loss: 10.731768, valid precision: 0.877000, valid loss: 86.626586
epoch: 1187, train precision: 0.998711, train loss: 10.739786, valid precision: 0.879400, valid loss: 86.853033
epoch: 1188, train precision: 0.998622, train loss: 10.839616, valid precision: 0.876600, valid loss: 88.182785
epoch: 1189, train precision: 0.998533, train loss: 10.881887, valid precision: 0.875800, valid loss: 88.610702
epoch: 1190, train precision: 0.998644, train loss: 10.796698, valid precision: 0.878800, valid loss: 86.940264
epoch: 1191, train precision: 0.998578, train loss: 10.722032, valid precision: 0.878000, valid loss: 87.879359
epoch: 1192, train precision: 0.998822, train loss: 10.693575, valid precision: 0.879000, valid loss: 87.587185
epoch: 1193, train precision: 0.998489, train loss: 10.850105, valid precision: 0.876000, valid loss: 88.008562
epoch: 1194, train precision: 0.998511, train loss: 10.779153, valid precision: 0.877200, valid loss: 87.724318
epoch: 1195, train precision: 0.998511, train loss: 10.871399, valid precision: 0.875800, valid loss: 89.476045
epoch: 1196, train precision: 0.998511, train loss: 10.795118, valid precision: 0.877400, valid loss: 87.564678
epoch: 1197, train precision: 0.998200, train loss: 10.877968, valid precision: 0.875600, valid loss: 89.702665
epoch: 1198, train precision: 0.998800, train loss: 10.767860, valid precision: 0.869800, valid loss: 90.051685
epoch: 1199, train precision: 0.998844, train loss: 10.766960, valid precision: 0.874600, valid loss: 89.187134
epoch: 1200, train precision: 0.998489, train loss: 10.815710, valid precision: 0.874400, valid loss: 87.569452
epoch: 1201, train precision: 0.998800, train loss: 10.736729, valid precision: 0.876600, valid loss: 89.405972
epoch: 1202, train precision: 0.998911, train loss: 10.788273, valid precision: 0.872600, valid loss: 90.290359
epoch: 1203, train precision: 0.998578, train loss: 10.790533, valid precision: 0.872800, valid loss: 89.297486
epoch: 1204, train precision: 0.998089, train loss: 11.025142, valid precision: 0.867200, valid loss: 92.216485
epoch: 1205, train precision: 0.998689, train loss: 10.791323, valid precision: 0.872200, valid loss: 89.660460
epoch: 1206, train precision: 0.998844, train loss: 10.701106, valid precision: 0.872600, valid loss: 89.099596
epoch: 1207, train precision: 0.998889, train loss: 10.706284, valid precision: 0.872400, valid loss: 91.317415
epoch: 1208, train precision: 0.998622, train loss: 10.720924, valid precision: 0.876400, valid loss: 90.732765
epoch: 1209, train precision: 0.998622, train loss: 10.816123, valid precision: 0.874200, valid loss: 90.905703
epoch: 1210, train precision: 0.998733, train loss: 10.718463, valid precision: 0.875400, valid loss: 91.439715
epoch: 1211, train precision: 0.998867, train loss: 10.725730, valid precision: 0.873000, valid loss: 90.496102
epoch: 1212, train precision: 0.998644, train loss: 10.790561, valid precision: 0.872600, valid loss: 90.033469
epoch: 1213, train precision: 0.998800, train loss: 10.729732, valid precision: 0.880000, valid loss: 88.621353
epoch: 1214, train precision: 0.998533, train loss: 10.754867, valid precision: 0.875400, valid loss: 88.729375
epoch: 1215, train precision: 0.998778, train loss: 10.714915, valid precision: 0.877000, valid loss: 91.995523
epoch: 1216, train precision: 0.998533, train loss: 10.802625, valid precision: 0.873600, valid loss: 91.495743
epoch: 1217, train precision: 0.998778, train loss: 10.712840, valid precision: 0.875600, valid loss: 90.890621
epoch: 1218, train precision: 0.999067, train loss: 10.624460, valid precision: 0.876600, valid loss: 91.379207
epoch: 1219, train precision: 0.998933, train loss: 10.669082, valid precision: 0.871800, valid loss: 91.898255
epoch: 1220, train precision: 0.998244, train loss: 10.943612, valid precision: 0.876200, valid loss: 90.507066
epoch: 1221, train precision: 0.998222, train loss: 10.855738, valid precision: 0.875000, valid loss: 89.852694
epoch: 1222, train precision: 0.998911, train loss: 10.697959, valid precision: 0.874400, valid loss: 89.252444
epoch: 1223, train precision: 0.998956, train loss: 10.712912, valid precision: 0.874000, valid loss: 89.443999
epoch: 1224, train precision: 0.998778, train loss: 10.657139, valid precision: 0.876200, valid loss: 89.600035
epoch: 1225, train precision: 0.998844, train loss: 10.743240, valid precision: 0.876200, valid loss: 88.336007
epoch: 1226, train precision: 0.998956, train loss: 10.730747, valid precision: 0.879200, valid loss: 89.169821
epoch: 1227, train precision: 0.998844, train loss: 10.760150, valid precision: 0.873800, valid loss: 88.316076
epoch: 1228, train precision: 0.998822, train loss: 10.725199, valid precision: 0.874200, valid loss: 88.275901
epoch: 1229, train precision: 0.998867, train loss: 10.727038, valid precision: 0.875800, valid loss: 88.166432
epoch: 1230, train precision: 0.998711, train loss: 10.697824, valid precision: 0.878800, valid loss: 88.489092
epoch: 1231, train precision: 0.998667, train loss: 10.851938, valid precision: 0.876000, valid loss: 90.654534
epoch: 1232, train precision: 0.998667, train loss: 10.854187, valid precision: 0.874400, valid loss: 88.751205
epoch: 1233, train precision: 0.999044, train loss: 10.644371, valid precision: 0.875400, valid loss: 88.334109
epoch: 1234, train precision: 0.998911, train loss: 10.710629, valid precision: 0.874000, valid loss: 89.769056
epoch: 1235, train precision: 0.998800, train loss: 10.778452, valid precision: 0.872200, valid loss: 89.469132
epoch: 1236, train precision: 0.998844, train loss: 10.686066, valid precision: 0.872600, valid loss: 87.553683
epoch: 1237, train precision: 0.999133, train loss: 10.595781, valid precision: 0.875600, valid loss: 87.377460
epoch: 1238, train precision: 0.999067, train loss: 10.705409, valid precision: 0.874200, valid loss: 88.162608
epoch: 1239, train precision: 0.998800, train loss: 10.718095, valid precision: 0.874200, valid loss: 90.445390
epoch: 1240, train precision: 0.998978, train loss: 10.682059, valid precision: 0.876800, valid loss: 88.289759
epoch: 1241, train precision: 0.998578, train loss: 10.733750, valid precision: 0.878200, valid loss: 87.089476
epoch: 1242, train precision: 0.998711, train loss: 10.739133, valid precision: 0.875200, valid loss: 88.725075
epoch: 1243, train precision: 0.998578, train loss: 10.809495, valid precision: 0.875000, valid loss: 90.261396
epoch: 1244, train precision: 0.998733, train loss: 10.713273, valid precision: 0.871600, valid loss: 89.388907
epoch: 1245, train precision: 0.998733, train loss: 10.785430, valid precision: 0.874600, valid loss: 89.878384
epoch: 1246, train precision: 0.998889, train loss: 10.733197, valid precision: 0.875200, valid loss: 89.257212
epoch: 1247, train precision: 0.998756, train loss: 10.783888, valid precision: 0.869600, valid loss: 88.522141
epoch: 1248, train precision: 0.998933, train loss: 10.764812, valid precision: 0.873200, valid loss: 87.548247
epoch: 1249, train precision: 0.998622, train loss: 10.722051, valid precision: 0.871800, valid loss: 89.283601
epoch: 1250, train precision: 0.998733, train loss: 10.726984, valid precision: 0.873600, valid loss: 89.807846
epoch: 1251, train precision: 0.998800, train loss: 10.737857, valid precision: 0.872600, valid loss: 91.525749
epoch: 1252, train precision: 0.999089, train loss: 10.605911, valid precision: 0.875000, valid loss: 88.965099
epoch: 1253, train precision: 0.998800, train loss: 10.676185, valid precision: 0.879400, valid loss: 89.170896
epoch: 1254, train precision: 0.998867, train loss: 10.732804, valid precision: 0.874200, valid loss: 89.613857
epoch: 1255, train precision: 0.998600, train loss: 10.790092, valid precision: 0.872000, valid loss: 91.642963
epoch: 1256, train precision: 0.998867, train loss: 10.691485, valid precision: 0.870200, valid loss: 90.300819
epoch: 1257, train precision: 0.998911, train loss: 10.695491, valid precision: 0.874600, valid loss: 89.194334
epoch: 1258, train precision: 0.998511, train loss: 10.853869, valid precision: 0.870800, valid loss: 91.794865
epoch: 1259, train precision: 0.998911, train loss: 10.750459, valid precision: 0.878600, valid loss: 88.155899
epoch: 1260, train precision: 0.999044, train loss: 10.644418, valid precision: 0.871600, valid loss: 89.876922
epoch: 1261, train precision: 0.998378, train loss: 10.809990, valid precision: 0.876000, valid loss: 90.693947
epoch: 1262, train precision: 0.999111, train loss: 10.641849, valid precision: 0.872600, valid loss: 89.285682
epoch: 1263, train precision: 0.998689, train loss: 10.773382, valid precision: 0.866400, valid loss: 92.661057
epoch: 1264, train precision: 0.998622, train loss: 10.811573, valid precision: 0.875400, valid loss: 89.399419
epoch: 1265, train precision: 0.998644, train loss: 10.779684, valid precision: 0.872800, valid loss: 92.697228
epoch: 1266, train precision: 0.998667, train loss: 10.824276, valid precision: 0.872000, valid loss: 92.418376
epoch: 1267, train precision: 0.998444, train loss: 10.881828, valid precision: 0.875000, valid loss: 92.734566
epoch: 1268, train precision: 0.998822, train loss: 10.753853, valid precision: 0.876400, valid loss: 89.096378
epoch: 1269, train precision: 0.998800, train loss: 10.813746, valid precision: 0.873800, valid loss: 89.715502
epoch: 1270, train precision: 0.998422, train loss: 10.939815, valid precision: 0.874000, valid loss: 90.969803
epoch: 1271, train precision: 0.999000, train loss: 10.711558, valid precision: 0.876400, valid loss: 90.624305
epoch: 1272, train precision: 0.999089, train loss: 10.727171, valid precision: 0.873400, valid loss: 89.837434
epoch: 1273, train precision: 0.998844, train loss: 10.712214, valid precision: 0.871600, valid loss: 90.428026
epoch: 1274, train precision: 0.997844, train loss: 10.965587, valid precision: 0.873400, valid loss: 90.077917
epoch: 1275, train precision: 0.998756, train loss: 10.794393, valid precision: 0.876600, valid loss: 89.057342
epoch: 1276, train precision: 0.998667, train loss: 10.837543, valid precision: 0.875200, valid loss: 91.754599
epoch: 1277, train precision: 0.998889, train loss: 10.697831, valid precision: 0.875000, valid loss: 89.196728
epoch: 1278, train precision: 0.998333, train loss: 10.979041, valid precision: 0.870600, valid loss: 90.072390
epoch: 1279, train precision: 0.998844, train loss: 10.661092, valid precision: 0.874600, valid loss: 89.339015
epoch: 1280, train precision: 0.998778, train loss: 10.693623, valid precision: 0.873800, valid loss: 88.964084
epoch: 1281, train precision: 0.998622, train loss: 10.831386, valid precision: 0.869400, valid loss: 89.146932
epoch: 1282, train precision: 0.998511, train loss: 10.791053, valid precision: 0.875000, valid loss: 88.911443
epoch: 1283, train precision: 0.998044, train loss: 10.888298, valid precision: 0.870000, valid loss: 91.412479
epoch: 1284, train precision: 0.998711, train loss: 10.762104, valid precision: 0.872600, valid loss: 89.339710
epoch: 1285, train precision: 0.998578, train loss: 10.749090, valid precision: 0.872800, valid loss: 90.130277
epoch: 1286, train precision: 0.998556, train loss: 10.765312, valid precision: 0.872000, valid loss: 89.076139
epoch: 1287, train precision: 0.998911, train loss: 10.691897, valid precision: 0.872400, valid loss: 89.649103
epoch: 1288, train precision: 0.998800, train loss: 10.736760, valid precision: 0.873200, valid loss: 88.798676
epoch: 1289, train precision: 0.998289, train loss: 10.902857, valid precision: 0.871600, valid loss: 89.775431
epoch: 1290, train precision: 0.999000, train loss: 10.641270, valid precision: 0.876400, valid loss: 88.146879
epoch: 1291, train precision: 0.998889, train loss: 10.714116, valid precision: 0.877200, valid loss: 85.702038
epoch: 1292, train precision: 0.998511, train loss: 10.804209, valid precision: 0.874800, valid loss: 90.095776
epoch: 1293, train precision: 0.998644, train loss: 10.720202, valid precision: 0.873800, valid loss: 88.117523
epoch: 1294, train precision: 0.998933, train loss: 10.681995, valid precision: 0.874000, valid loss: 88.574097
epoch: 1295, train precision: 0.998711, train loss: 10.795382, valid precision: 0.872800, valid loss: 89.087120
epoch: 1296, train precision: 0.998822, train loss: 10.735897, valid precision: 0.875600, valid loss: 90.845940
epoch: 1297, train precision: 0.998822, train loss: 10.731723, valid precision: 0.869200, valid loss: 91.148337
epoch: 1298, train precision: 0.998689, train loss: 10.768404, valid precision: 0.872200, valid loss: 90.828843
epoch: 1299, train precision: 0.999133, train loss: 10.594179, valid precision: 0.875000, valid loss: 89.409586
epoch: 1300, train precision: 0.998489, train loss: 10.848065, valid precision: 0.871000, valid loss: 91.952434
epoch: 1301, train precision: 0.998956, train loss: 10.619412, valid precision: 0.874200, valid loss: 90.837595
epoch: 1302, train precision: 0.998822, train loss: 10.705337, valid precision: 0.872400, valid loss: 92.094141
epoch: 1303, train precision: 0.998400, train loss: 10.933235, valid precision: 0.874800, valid loss: 90.868642
epoch: 1304, train precision: 0.998667, train loss: 10.799734, valid precision: 0.871800, valid loss: 92.103111
epoch: 1305, train precision: 0.998778, train loss: 10.701393, valid precision: 0.876800, valid loss: 91.080234
epoch: 1306, train precision: 0.998689, train loss: 10.734438, valid precision: 0.875400, valid loss: 93.067814
epoch: 1307, train precision: 0.998956, train loss: 10.731470, valid precision: 0.874200, valid loss: 92.676465
epoch: 1308, train precision: 0.998867, train loss: 10.633732, valid precision: 0.874800, valid loss: 91.916845
epoch: 1309, train precision: 0.998867, train loss: 10.743061, valid precision: 0.872400, valid loss: 94.037060
epoch: 1310, train precision: 0.998800, train loss: 10.708389, valid precision: 0.872000, valid loss: 90.650770
epoch: 1311, train precision: 0.998644, train loss: 10.727090, valid precision: 0.872400, valid loss: 91.328518
epoch: 1312, train precision: 0.998800, train loss: 10.721710, valid precision: 0.872200, valid loss: 91.953400
epoch: 1313, train precision: 0.998822, train loss: 10.690735, valid precision: 0.873000, valid loss: 89.379102
epoch: 1314, train precision: 0.998933, train loss: 10.702592, valid precision: 0.873600, valid loss: 88.994600
epoch: 1315, train precision: 0.998689, train loss: 10.686645, valid precision: 0.875400, valid loss: 89.202415
epoch: 1316, train precision: 0.998844, train loss: 10.686076, valid precision: 0.872400, valid loss: 91.791393
epoch: 1317, train precision: 0.998933, train loss: 10.708541, valid precision: 0.877400, valid loss: 89.424375
epoch: 1318, train precision: 0.998311, train loss: 10.930050, valid precision: 0.872400, valid loss: 90.359992
epoch: 1319, train precision: 0.999133, train loss: 10.625265, valid precision: 0.874200, valid loss: 91.517489
epoch: 1320, train precision: 0.998022, train loss: 10.888697, valid precision: 0.867600, valid loss: 92.527335
epoch: 1321, train precision: 0.998600, train loss: 10.762108, valid precision: 0.871800, valid loss: 90.362518
epoch: 1322, train precision: 0.998867, train loss: 10.694206, valid precision: 0.869000, valid loss: 93.203885
epoch: 1323, train precision: 0.998289, train loss: 10.869117, valid precision: 0.872800, valid loss: 92.623775
epoch: 1324, train precision: 0.998000, train loss: 10.888789, valid precision: 0.870800, valid loss: 90.459947
epoch: 1325, train precision: 0.999089, train loss: 10.646274, valid precision: 0.870800, valid loss: 91.327692
epoch: 1326, train precision: 0.998733, train loss: 10.740951, valid precision: 0.872400, valid loss: 92.351626
epoch: 1327, train precision: 0.998600, train loss: 10.764727, valid precision: 0.870200, valid loss: 91.184313
epoch: 1328, train precision: 0.998600, train loss: 10.801199, valid precision: 0.874600, valid loss: 86.787944
epoch: 1329, train precision: 0.998533, train loss: 10.854946, valid precision: 0.875200, valid loss: 88.835024
epoch: 1330, train precision: 0.998756, train loss: 10.722592, valid precision: 0.872400, valid loss: 87.855847
epoch: 1331, train precision: 0.998556, train loss: 10.781471, valid precision: 0.873800, valid loss: 90.221608
epoch: 1332, train precision: 0.998756, train loss: 10.749089, valid precision: 0.871600, valid loss: 88.857035
epoch: 1333, train precision: 0.998756, train loss: 10.785487, valid precision: 0.870000, valid loss: 89.434312
epoch: 1334, train precision: 0.999089, train loss: 10.657744, valid precision: 0.874200, valid loss: 90.617809
epoch: 1335, train precision: 0.998956, train loss: 10.709343, valid precision: 0.876600, valid loss: 89.714612
epoch: 1336, train precision: 0.998644, train loss: 10.770566, valid precision: 0.876400, valid loss: 89.537257
epoch: 1337, train precision: 0.998933, train loss: 10.680694, valid precision: 0.875400, valid loss: 88.247901
epoch: 1338, train precision: 0.999156, train loss: 10.608792, valid precision: 0.875600, valid loss: 88.107770
epoch: 1339, train precision: 0.998667, train loss: 10.801699, valid precision: 0.877200, valid loss: 88.376065
epoch: 1340, train precision: 0.998600, train loss: 10.774754, valid precision: 0.877600, valid loss: 89.806233
epoch: 1341, train precision: 0.998422, train loss: 10.961859, valid precision: 0.871800, valid loss: 88.038279
epoch: 1342, train precision: 0.998756, train loss: 10.712226, valid precision: 0.875200, valid loss: 88.784031
epoch: 1343, train precision: 0.998933, train loss: 10.628090, valid precision: 0.875600, valid loss: 90.763554
epoch: 1344, train precision: 0.998978, train loss: 10.631160, valid precision: 0.876800, valid loss: 88.514362
epoch: 1345, train precision: 0.998800, train loss: 10.742607, valid precision: 0.871600, valid loss: 91.415565
epoch: 1346, train precision: 0.998711, train loss: 10.751298, valid precision: 0.872600, valid loss: 92.676031
epoch: 1347, train precision: 0.998711, train loss: 10.752711, valid precision: 0.873800, valid loss: 91.926856
epoch: 1348, train precision: 0.998622, train loss: 10.808475, valid precision: 0.874800, valid loss: 89.012519
epoch: 1349, train precision: 0.999044, train loss: 10.608348, valid precision: 0.873600, valid loss: 92.293119
epoch: 1350, train precision: 0.999111, train loss: 10.605846, valid precision: 0.871600, valid loss: 92.162477
epoch: 1351, train precision: 0.998622, train loss: 10.689782, valid precision: 0.873600, valid loss: 91.203548
epoch: 1352, train precision: 0.998711, train loss: 10.722000, valid precision: 0.870600, valid loss: 93.884074
epoch: 1353, train precision: 0.998667, train loss: 10.757376, valid precision: 0.871800, valid loss: 90.631604
epoch: 1354, train precision: 0.998644, train loss: 10.728784, valid precision: 0.871800, valid loss: 93.313072
epoch: 1355, train precision: 0.998711, train loss: 10.771940, valid precision: 0.873400, valid loss: 91.390057
epoch: 1356, train precision: 0.998511, train loss: 10.822202, valid precision: 0.873800, valid loss: 93.620215
epoch: 1357, train precision: 0.998578, train loss: 10.730707, valid precision: 0.871000, valid loss: 91.274893
epoch: 1358, train precision: 0.998889, train loss: 10.750729, valid precision: 0.872000, valid loss: 91.879770
epoch: 1359, train precision: 0.998867, train loss: 10.694854, valid precision: 0.869800, valid loss: 90.256945
epoch: 1360, train precision: 0.999156, train loss: 10.625626, valid precision: 0.875400, valid loss: 91.110439
epoch: 1361, train precision: 0.998111, train loss: 10.928590, valid precision: 0.869000, valid loss: 92.144730
epoch: 1362, train precision: 0.999200, train loss: 10.556839, valid precision: 0.873600, valid loss: 93.658184
epoch: 1363, train precision: 0.999200, train loss: 10.641574, valid precision: 0.872200, valid loss: 91.042686
epoch: 1364, train precision: 0.998689, train loss: 10.727347, valid precision: 0.866800, valid loss: 93.356351
epoch: 1365, train precision: 0.999289, train loss: 10.549962, valid precision: 0.876000, valid loss: 89.503604
epoch: 1366, train precision: 0.999200, train loss: 10.588101, valid precision: 0.873800, valid loss: 89.504557
epoch: 1367, train precision: 0.999022, train loss: 10.663552, valid precision: 0.874200, valid loss: 88.536602
epoch: 1368, train precision: 0.998711, train loss: 10.716195, valid precision: 0.874000, valid loss: 91.363910
epoch: 1369, train precision: 0.998578, train loss: 10.755064, valid precision: 0.873600, valid loss: 90.529882
epoch: 1370, train precision: 0.999044, train loss: 10.655015, valid precision: 0.873800, valid loss: 93.518343
epoch: 1371, train precision: 0.998533, train loss: 10.804384, valid precision: 0.874400, valid loss: 90.405179
epoch: 1372, train precision: 0.998889, train loss: 10.720093, valid precision: 0.875000, valid loss: 90.848617
epoch: 1373, train precision: 0.998911, train loss: 10.705923, valid precision: 0.875200, valid loss: 91.242322
epoch: 1374, train precision: 0.998422, train loss: 10.864937, valid precision: 0.872200, valid loss: 93.424155
epoch: 1375, train precision: 0.999022, train loss: 10.675148, valid precision: 0.873600, valid loss: 93.072239
epoch: 1376, train precision: 0.998356, train loss: 10.843834, valid precision: 0.868600, valid loss: 93.759570
epoch: 1377, train precision: 0.998822, train loss: 10.706953, valid precision: 0.874000, valid loss: 90.301071
epoch: 1378, train precision: 0.998578, train loss: 10.840076, valid precision: 0.871800, valid loss: 91.249097
epoch: 1379, train precision: 0.998911, train loss: 10.688815, valid precision: 0.872000, valid loss: 92.070198
epoch: 1380, train precision: 0.999156, train loss: 10.639457, valid precision: 0.876200, valid loss: 88.805987
epoch: 1381, train precision: 0.998800, train loss: 10.725999, valid precision: 0.870400, valid loss: 91.769970
epoch: 1382, train precision: 0.998778, train loss: 10.703705, valid precision: 0.870000, valid loss: 91.596475
epoch: 1383, train precision: 0.998978, train loss: 10.660798, valid precision: 0.874800, valid loss: 89.655020
epoch: 1384, train precision: 0.998933, train loss: 10.684894, valid precision: 0.869200, valid loss: 90.818674
epoch: 1385, train precision: 0.998778, train loss: 10.763737, valid precision: 0.873200, valid loss: 90.561481
epoch: 1386, train precision: 0.998667, train loss: 10.693109, valid precision: 0.873600, valid loss: 89.300462
epoch: 1387, train precision: 0.998867, train loss: 10.731777, valid precision: 0.871400, valid loss: 91.602505
epoch: 1388, train precision: 0.998533, train loss: 10.778293, valid precision: 0.871600, valid loss: 91.614266
epoch: 1389, train precision: 0.998800, train loss: 10.697746, valid precision: 0.873200, valid loss: 90.747843
epoch: 1390, train precision: 0.998756, train loss: 10.680230, valid precision: 0.876600, valid loss: 90.564808
epoch: 1391, train precision: 0.998644, train loss: 10.726838, valid precision: 0.873600, valid loss: 90.180790
epoch: 1392, train precision: 0.998889, train loss: 10.649912, valid precision: 0.878400, valid loss: 88.465964
epoch: 1393, train precision: 0.998867, train loss: 10.666372, valid precision: 0.879000, valid loss: 90.377383
epoch: 1394, train precision: 0.998844, train loss: 10.680762, valid precision: 0.873400, valid loss: 90.671919
epoch: 1395, train precision: 0.998600, train loss: 10.720933, valid precision: 0.873200, valid loss: 89.253708
epoch: 1396, train precision: 0.998800, train loss: 10.710228, valid precision: 0.875400, valid loss: 90.477539
epoch: 1397, train precision: 0.999311, train loss: 10.597916, valid precision: 0.873600, valid loss: 89.763580
epoch: 1398, train precision: 0.998911, train loss: 10.740884, valid precision: 0.875400, valid loss: 89.972211
epoch: 1399, train precision: 0.998822, train loss: 10.693211, valid precision: 0.876000, valid loss: 91.716678
epoch: 1400, train precision: 0.998911, train loss: 10.699303, valid precision: 0.869200, valid loss: 91.084188
epoch: 1401, train precision: 0.999000, train loss: 10.707738, valid precision: 0.872600, valid loss: 90.295881
epoch: 1402, train precision: 0.998800, train loss: 10.676643, valid precision: 0.871800, valid loss: 91.597078
epoch: 1403, train precision: 0.999178, train loss: 10.627137, valid precision: 0.871800, valid loss: 92.309650
epoch: 1404, train precision: 0.998689, train loss: 10.774640, valid precision: 0.873600, valid loss: 90.623936
epoch: 1405, train precision: 0.998578, train loss: 10.744400, valid precision: 0.872800, valid loss: 90.565664
epoch: 1406, train precision: 0.998822, train loss: 10.674858, valid precision: 0.875000, valid loss: 91.860879
epoch: 1407, train precision: 0.998844, train loss: 10.650307, valid precision: 0.873000, valid loss: 91.816608
epoch: 1408, train precision: 0.998756, train loss: 10.754348, valid precision: 0.875400, valid loss: 91.101797
epoch: 1409, train precision: 0.998156, train loss: 10.918612, valid precision: 0.869200, valid loss: 92.273906
epoch: 1410, train precision: 0.998711, train loss: 10.673747, valid precision: 0.873600, valid loss: 93.179083
epoch: 1411, train precision: 0.998600, train loss: 10.822362, valid precision: 0.868800, valid loss: 94.113834
epoch: 1412, train precision: 0.998756, train loss: 10.759685, valid precision: 0.868400, valid loss: 92.479509
epoch: 1413, train precision: 0.998622, train loss: 10.729167, valid precision: 0.872000, valid loss: 90.250093
epoch: 1414, train precision: 0.999044, train loss: 10.690298, valid precision: 0.871000, valid loss: 90.921007
epoch: 1415, train precision: 0.999133, train loss: 10.672728, valid precision: 0.869400, valid loss: 92.074244
epoch: 1416, train precision: 0.998733, train loss: 10.706191, valid precision: 0.870600, valid loss: 94.128235
epoch: 1417, train precision: 0.998711, train loss: 10.729481, valid precision: 0.869600, valid loss: 94.342312
epoch: 1418, train precision: 0.998622, train loss: 10.791708, valid precision: 0.872800, valid loss: 92.915416
epoch: 1419, train precision: 0.998933, train loss: 10.692583, valid precision: 0.872800, valid loss: 90.692087
epoch: 1420, train precision: 0.998711, train loss: 10.704089, valid precision: 0.874600, valid loss: 92.382575
epoch: 1421, train precision: 0.998467, train loss: 10.835138, valid precision: 0.870800, valid loss: 92.330905
epoch: 1422, train precision: 0.998911, train loss: 10.705826, valid precision: 0.870000, valid loss: 92.930234
epoch: 1423, train precision: 0.998644, train loss: 10.761174, valid precision: 0.875600, valid loss: 93.006856
epoch: 1424, train precision: 0.998689, train loss: 10.815426, valid precision: 0.874200, valid loss: 94.181633
epoch: 1425, train precision: 0.999089, train loss: 10.658542, valid precision: 0.873000, valid loss: 93.471390
epoch: 1426, train precision: 0.998778, train loss: 10.755999, valid precision: 0.875400, valid loss: 91.492650
epoch: 1427, train precision: 0.998867, train loss: 10.692377, valid precision: 0.872800, valid loss: 91.858057
epoch: 1428, train precision: 0.998600, train loss: 10.764943, valid precision: 0.872200, valid loss: 90.481207
epoch: 1429, train precision: 0.999089, train loss: 10.626979, valid precision: 0.874800, valid loss: 89.951173
epoch: 1430, train precision: 0.998556, train loss: 10.799524, valid precision: 0.873800, valid loss: 89.722708
epoch: 1431, train precision: 0.998800, train loss: 10.736611, valid precision: 0.874000, valid loss: 88.830274
epoch: 1432, train precision: 0.998800, train loss: 10.796411, valid precision: 0.872200, valid loss: 91.044677
epoch: 1433, train precision: 0.998844, train loss: 10.729635, valid precision: 0.871600, valid loss: 91.004780
epoch: 1434, train precision: 0.998311, train loss: 10.845932, valid precision: 0.873800, valid loss: 90.869433
epoch: 1435, train precision: 0.999089, train loss: 10.684264, valid precision: 0.874800, valid loss: 88.092233
epoch: 1436, train precision: 0.998711, train loss: 10.788436, valid precision: 0.871800, valid loss: 92.677999
epoch: 1437, train precision: 0.998867, train loss: 10.715994, valid precision: 0.870800, valid loss: 92.540902
epoch: 1438, train precision: 0.998667, train loss: 10.752046, valid precision: 0.871200, valid loss: 93.541300
epoch: 1439, train precision: 0.998778, train loss: 10.780308, valid precision: 0.876400, valid loss: 90.624546
epoch: 1440, train precision: 0.998600, train loss: 10.731769, valid precision: 0.868800, valid loss: 91.825991
epoch: 1441, train precision: 0.998889, train loss: 10.667751, valid precision: 0.874200, valid loss: 92.511760
epoch: 1442, train precision: 0.998711, train loss: 10.741219, valid precision: 0.876200, valid loss: 91.291247
epoch: 1443, train precision: 0.998311, train loss: 10.822935, valid precision: 0.876000, valid loss: 92.721366
epoch: 1444, train precision: 0.998889, train loss: 10.587031, valid precision: 0.877200, valid loss: 90.818240
epoch: 1445, train precision: 0.998756, train loss: 10.749388, valid precision: 0.874200, valid loss: 92.170690
epoch: 1446, train precision: 0.998644, train loss: 10.747432, valid precision: 0.869600, valid loss: 93.665334
epoch: 1447, train precision: 0.999000, train loss: 10.679488, valid precision: 0.875800, valid loss: 92.075869
epoch: 1448, train precision: 0.998689, train loss: 10.772122, valid precision: 0.874400, valid loss: 92.631059
epoch: 1449, train precision: 0.998822, train loss: 10.707633, valid precision: 0.869400, valid loss: 93.510777
epoch: 1450, train precision: 0.998844, train loss: 10.675373, valid precision: 0.872000, valid loss: 91.672667
epoch: 1451, train precision: 0.998956, train loss: 10.677294, valid precision: 0.878200, valid loss: 90.226309
epoch: 1452, train precision: 0.998800, train loss: 10.654058, valid precision: 0.878200, valid loss: 91.041879
epoch: 1453, train precision: 0.999000, train loss: 10.670580, valid precision: 0.876400, valid loss: 90.944760
epoch: 1454, train precision: 0.999067, train loss: 10.632829, valid precision: 0.874200, valid loss: 91.513370
epoch: 1455, train precision: 0.999000, train loss: 10.620895, valid precision: 0.876800, valid loss: 90.993593
epoch: 1456, train precision: 0.998533, train loss: 10.767145, valid precision: 0.877200, valid loss: 89.984615
epoch: 1457, train precision: 0.999022, train loss: 10.725147, valid precision: 0.872400, valid loss: 92.126150
epoch: 1458, train precision: 0.998911, train loss: 10.644402, valid precision: 0.879800, valid loss: 88.025616
epoch: 1459, train precision: 0.998867, train loss: 10.751207, valid precision: 0.874600, valid loss: 89.878180
epoch: 1460, train precision: 0.998578, train loss: 10.782066, valid precision: 0.871800, valid loss: 91.063945
epoch: 1461, train precision: 0.998756, train loss: 10.720128, valid precision: 0.877800, valid loss: 89.982366
epoch: 1462, train precision: 0.999067, train loss: 10.656087, valid precision: 0.875000, valid loss: 88.634444
epoch: 1463, train precision: 0.998378, train loss: 10.808534, valid precision: 0.873000, valid loss: 91.093634
epoch: 1464, train precision: 0.998756, train loss: 10.735111, valid precision: 0.874800, valid loss: 87.662855
epoch: 1465, train precision: 0.998800, train loss: 10.704875, valid precision: 0.873600, valid loss: 89.913563
epoch: 1466, train precision: 0.998889, train loss: 10.695902, valid precision: 0.877400, valid loss: 87.790521
epoch: 1467, train precision: 0.998889, train loss: 10.716614, valid precision: 0.876400, valid loss: 88.097009
epoch: 1468, train precision: 0.998556, train loss: 10.843624, valid precision: 0.879000, valid loss: 88.300732
epoch: 1469, train precision: 0.998556, train loss: 10.774272, valid precision: 0.875400, valid loss: 89.255149
epoch: 1470, train precision: 0.998756, train loss: 10.693887, valid precision: 0.875000, valid loss: 91.791934
epoch: 1471, train precision: 0.998489, train loss: 10.791324, valid precision: 0.878400, valid loss: 91.587617
epoch: 1472, train precision: 0.998356, train loss: 10.893294, valid precision: 0.869800, valid loss: 93.226996
epoch: 1473, train precision: 0.999178, train loss: 10.603120, valid precision: 0.875800, valid loss: 90.095706
epoch: 1474, train precision: 0.998578, train loss: 10.781118, valid precision: 0.878800, valid loss: 91.224949
epoch: 1475, train precision: 0.998978, train loss: 10.681443, valid precision: 0.872800, valid loss: 91.957706
epoch: 1476, train precision: 0.998511, train loss: 10.744930, valid precision: 0.870200, valid loss: 91.195044
epoch: 1477, train precision: 0.998889, train loss: 10.693243, valid precision: 0.868200, valid loss: 94.639313
epoch: 1478, train precision: 0.998889, train loss: 10.692076, valid precision: 0.869800, valid loss: 93.429493
epoch: 1479, train precision: 0.998911, train loss: 10.706166, valid precision: 0.871400, valid loss: 93.048019
epoch: 1480, train precision: 0.998933, train loss: 10.662556, valid precision: 0.869000, valid loss: 93.222054
epoch: 1481, train precision: 0.998689, train loss: 10.752945, valid precision: 0.869200, valid loss: 92.123411
epoch: 1482, train precision: 0.998644, train loss: 10.769869, valid precision: 0.869800, valid loss: 95.086685
epoch: 1483, train precision: 0.998956, train loss: 10.689111, valid precision: 0.878800, valid loss: 90.576194
epoch: 1484, train precision: 0.999111, train loss: 10.658005, valid precision: 0.874200, valid loss: 89.483374
epoch: 1485, train precision: 0.998844, train loss: 10.690493, valid precision: 0.875200, valid loss: 89.178499
epoch: 1486, train precision: 0.998933, train loss: 10.634026, valid precision: 0.877200, valid loss: 87.667966
epoch: 1487, train precision: 0.998556, train loss: 10.787192, valid precision: 0.875200, valid loss: 90.121313
epoch: 1488, train precision: 0.998778, train loss: 10.727950, valid precision: 0.874600, valid loss: 87.687121
epoch: 1489, train precision: 0.998444, train loss: 10.794960, valid precision: 0.875400, valid loss: 89.688784
epoch: 1490, train precision: 0.998978, train loss: 10.740159, valid precision: 0.875600, valid loss: 89.856365
epoch: 1491, train precision: 0.998978, train loss: 10.645869, valid precision: 0.873600, valid loss: 91.143826
epoch: 1492, train precision: 0.998756, train loss: 10.679265, valid precision: 0.873200, valid loss: 93.223036
epoch: 1493, train precision: 0.998600, train loss: 10.792885, valid precision: 0.874800, valid loss: 90.748576
epoch: 1494, train precision: 0.999133, train loss: 10.639927, valid precision: 0.874600, valid loss: 93.195816
epoch: 1495, train precision: 0.998889, train loss: 10.710761, valid precision: 0.875000, valid loss: 91.742785
epoch: 1496, train precision: 0.998756, train loss: 10.685674, valid precision: 0.874600, valid loss: 92.584516
epoch: 1497, train precision: 0.998978, train loss: 10.654454, valid precision: 0.877800, valid loss: 92.787071
epoch: 1498, train precision: 0.998667, train loss: 10.757195, valid precision: 0.876600, valid loss: 92.654423
epoch: 1499, train precision: 0.998644, train loss: 10.773874, valid precision: 0.879200, valid loss: 90.702440
epoch: 1500, train precision: 0.998800, train loss: 10.671203, valid precision: 0.879800, valid loss: 91.070224
epoch: 1501, train precision: 0.998689, train loss: 10.780606, valid precision: 0.875600, valid loss: 91.399132
epoch: 1502, train precision: 0.998733, train loss: 10.691076, valid precision: 0.874200, valid loss: 91.510071
epoch: 1503, train precision: 0.999089, train loss: 10.651776, valid precision: 0.874600, valid loss: 92.081450
epoch: 1504, train precision: 0.998556, train loss: 10.830867, valid precision: 0.875400, valid loss: 92.483032
epoch: 1505, train precision: 0.998556, train loss: 10.772604, valid precision: 0.877000, valid loss: 89.314172
epoch: 1506, train precision: 0.999067, train loss: 10.608074, valid precision: 0.873800, valid loss: 93.578352
epoch: 1507, train precision: 0.999022, train loss: 10.628435, valid precision: 0.873600, valid loss: 94.106673
epoch: 1508, train precision: 0.999000, train loss: 10.633816, valid precision: 0.873200, valid loss: 91.952642
epoch: 1509, train precision: 0.999067, train loss: 10.676002, valid precision: 0.874800, valid loss: 92.012810
epoch: 1510, train precision: 0.998911, train loss: 10.684106, valid precision: 0.873600, valid loss: 92.891185
epoch: 1511, train precision: 0.998689, train loss: 10.767457, valid precision: 0.874200, valid loss: 89.895808
epoch: 1512, train precision: 0.998844, train loss: 10.707946, valid precision: 0.876200, valid loss: 89.466254
epoch: 1513, train precision: 0.998844, train loss: 10.711543, valid precision: 0.878000, valid loss: 88.934475
epoch: 1514, train precision: 0.998978, train loss: 10.666832, valid precision: 0.876000, valid loss: 91.634837
epoch: 1515, train precision: 0.998800, train loss: 10.691930, valid precision: 0.876800, valid loss: 90.523316
epoch: 1516, train precision: 0.999044, train loss: 10.673702, valid precision: 0.879800, valid loss: 87.593149
epoch: 1517, train precision: 0.998844, train loss: 10.711878, valid precision: 0.874200, valid loss: 90.279462
epoch: 1518, train precision: 0.998822, train loss: 10.723734, valid precision: 0.877000, valid loss: 91.465466
epoch: 1519, train precision: 0.998756, train loss: 10.736206, valid precision: 0.877600, valid loss: 91.981904
epoch: 1520, train precision: 0.998622, train loss: 10.755691, valid precision: 0.870000, valid loss: 94.008755
epoch: 1521, train precision: 0.999000, train loss: 10.641331, valid precision: 0.874600, valid loss: 92.899201
epoch: 1522, train precision: 0.998822, train loss: 10.650219, valid precision: 0.872600, valid loss: 94.446797
epoch: 1523, train precision: 0.998711, train loss: 10.785001, valid precision: 0.875800, valid loss: 92.758853
epoch: 1524, train precision: 0.999022, train loss: 10.652866, valid precision: 0.873000, valid loss: 92.205973
epoch: 1525, train precision: 0.998533, train loss: 10.814911, valid precision: 0.874200, valid loss: 91.510072
epoch: 1526, train precision: 0.998933, train loss: 10.672014, valid precision: 0.874400, valid loss: 91.033431
epoch: 1527, train precision: 0.998956, train loss: 10.625899, valid precision: 0.873600, valid loss: 90.863110
epoch: 1528, train precision: 0.998311, train loss: 10.896594, valid precision: 0.876400, valid loss: 91.080854
epoch: 1529, train precision: 0.998400, train loss: 10.857865, valid precision: 0.875400, valid loss: 89.242724
epoch: 1530, train precision: 0.999133, train loss: 10.674618, valid precision: 0.871600, valid loss: 90.184434
epoch: 1531, train precision: 0.999000, train loss: 10.654415, valid precision: 0.874000, valid loss: 91.932569
epoch: 1532, train precision: 0.998689, train loss: 10.695154, valid precision: 0.877200, valid loss: 89.840567
epoch: 1533, train precision: 0.998578, train loss: 10.827319, valid precision: 0.872400, valid loss: 91.839516
epoch: 1534, train precision: 0.998644, train loss: 10.789172, valid precision: 0.874400, valid loss: 91.638845
epoch: 1535, train precision: 0.998489, train loss: 10.790931, valid precision: 0.873200, valid loss: 91.404739
epoch: 1536, train precision: 0.999244, train loss: 10.561246, valid precision: 0.873000, valid loss: 92.038085
epoch: 1537, train precision: 0.998778, train loss: 10.724290, valid precision: 0.873600, valid loss: 92.535433
epoch: 1538, train precision: 0.998711, train loss: 10.672449, valid precision: 0.874400, valid loss: 89.839623
epoch: 1539, train precision: 0.998933, train loss: 10.742747, valid precision: 0.875800, valid loss: 89.498851
epoch: 1540, train precision: 0.998533, train loss: 10.805069, valid precision: 0.872800, valid loss: 90.001683
epoch: 1541, train precision: 0.999289, train loss: 10.591900, valid precision: 0.873600, valid loss: 93.108836
epoch: 1542, train precision: 0.998844, train loss: 10.714242, valid precision: 0.874400, valid loss: 90.642995
epoch: 1543, train precision: 0.999089, train loss: 10.684951, valid precision: 0.876000, valid loss: 92.280968
epoch: 1544, train precision: 0.998800, train loss: 10.720980, valid precision: 0.877200, valid loss: 91.181439
epoch: 1545, train precision: 0.998511, train loss: 10.789243, valid precision: 0.873400, valid loss: 91.173346
epoch: 1546, train precision: 0.998667, train loss: 10.760057, valid precision: 0.877400, valid loss: 88.526738
epoch: 1547, train precision: 0.998711, train loss: 10.751755, valid precision: 0.879000, valid loss: 88.859604
epoch: 1548, train precision: 0.999022, train loss: 10.643652, valid precision: 0.880600, valid loss: 87.944378
epoch: 1549, train precision: 0.998933, train loss: 10.664795, valid precision: 0.880000, valid loss: 88.519401
epoch: 1550, train precision: 0.998844, train loss: 10.673640, valid precision: 0.878200, valid loss: 89.806019
epoch: 1551, train precision: 0.999000, train loss: 10.622983, valid precision: 0.877600, valid loss: 88.673504
epoch: 1552, train precision: 0.998756, train loss: 10.691672, valid precision: 0.873400, valid loss: 92.339514
epoch: 1553, train precision: 0.998378, train loss: 10.802017, valid precision: 0.876800, valid loss: 91.913048
epoch: 1554, train precision: 0.998422, train loss: 10.832245, valid precision: 0.879200, valid loss: 89.622636
epoch: 1555, train precision: 0.999022, train loss: 10.684071, valid precision: 0.877600, valid loss: 90.180068
epoch: 1556, train precision: 0.999267, train loss: 10.618981, valid precision: 0.880000, valid loss: 89.429635
epoch: 1557, train precision: 0.998956, train loss: 10.622097, valid precision: 0.876200, valid loss: 92.261796
epoch: 1558, train precision: 0.998933, train loss: 10.665470, valid precision: 0.881000, valid loss: 89.294817
epoch: 1559, train precision: 0.998667, train loss: 10.690019, valid precision: 0.874000, valid loss: 91.257055
epoch: 1560, train precision: 0.998556, train loss: 10.736745, valid precision: 0.877800, valid loss: 91.147454
epoch: 1561, train precision: 0.998956, train loss: 10.632656, valid precision: 0.876800, valid loss: 92.908672
epoch: 1562, train precision: 0.998689, train loss: 10.913205, valid precision: 0.875000, valid loss: 90.383325
epoch: 1563, train precision: 0.998889, train loss: 10.707828, valid precision: 0.879800, valid loss: 89.402746
epoch: 1564, train precision: 0.998889, train loss: 10.645017, valid precision: 0.879000, valid loss: 89.947661
epoch: 1565, train precision: 0.999156, train loss: 10.609836, valid precision: 0.876000, valid loss: 90.400625
epoch: 1566, train precision: 0.999111, train loss: 10.647292, valid precision: 0.873800, valid loss: 89.909319
epoch: 1567, train precision: 0.998889, train loss: 10.665814, valid precision: 0.877200, valid loss: 89.314521
epoch: 1568, train precision: 0.998867, train loss: 10.705967, valid precision: 0.879600, valid loss: 90.099782
epoch: 1569, train precision: 0.998622, train loss: 10.811804, valid precision: 0.876000, valid loss: 90.025786
epoch: 1570, train precision: 0.999156, train loss: 10.578160, valid precision: 0.877000, valid loss: 89.264932
epoch: 1571, train precision: 0.998711, train loss: 10.709807, valid precision: 0.878200, valid loss: 92.167060
epoch: 1572, train precision: 0.998867, train loss: 10.707180, valid precision: 0.872400, valid loss: 92.792500
epoch: 1573, train precision: 0.999000, train loss: 10.632683, valid precision: 0.877800, valid loss: 89.334699
epoch: 1574, train precision: 0.998911, train loss: 10.707857, valid precision: 0.879000, valid loss: 87.291892
epoch: 1575, train precision: 0.998933, train loss: 10.642606, valid precision: 0.876600, valid loss: 89.006994
epoch: 1576, train precision: 0.998778, train loss: 10.681493, valid precision: 0.874600, valid loss: 89.289225
epoch: 1577, train precision: 0.999044, train loss: 10.634346, valid precision: 0.877800, valid loss: 88.697023
epoch: 1578, train precision: 0.999067, train loss: 10.587859, valid precision: 0.874800, valid loss: 89.367849
epoch: 1579, train precision: 0.998667, train loss: 10.768100, valid precision: 0.879400, valid loss: 87.937314
epoch: 1580, train precision: 0.998778, train loss: 10.718952, valid precision: 0.876600, valid loss: 89.004464
epoch: 1581, train precision: 0.998578, train loss: 10.774678, valid precision: 0.876600, valid loss: 90.892200
epoch: 1582, train precision: 0.998889, train loss: 10.709899, valid precision: 0.875800, valid loss: 89.290864
epoch: 1583, train precision: 0.998511, train loss: 10.821696, valid precision: 0.870800, valid loss: 92.443442
epoch: 1584, train precision: 0.999022, train loss: 10.649010, valid precision: 0.874600, valid loss: 92.534307
epoch: 1585, train precision: 0.998667, train loss: 10.735305, valid precision: 0.874600, valid loss: 89.692715
epoch: 1586, train precision: 0.999067, train loss: 10.630019, valid precision: 0.874600, valid loss: 89.361163
epoch: 1587, train precision: 0.998756, train loss: 10.690383, valid precision: 0.873600, valid loss: 90.016249
epoch: 1588, train precision: 0.998800, train loss: 10.709633, valid precision: 0.876200, valid loss: 88.044980
epoch: 1589, train precision: 0.998578, train loss: 10.755599, valid precision: 0.876000, valid loss: 90.818684
epoch: 1590, train precision: 0.998911, train loss: 10.654059, valid precision: 0.879200, valid loss: 90.607439
epoch: 1591, train precision: 0.998978, train loss: 10.619967, valid precision: 0.875600, valid loss: 89.905766
epoch: 1592, train precision: 0.999044, train loss: 10.620804, valid precision: 0.875200, valid loss: 90.347969
epoch: 1593, train precision: 0.998933, train loss: 10.665653, valid precision: 0.875200, valid loss: 89.623936
epoch: 1594, train precision: 0.999044, train loss: 10.649495, valid precision: 0.876200, valid loss: 90.470203
epoch: 1595, train precision: 0.998756, train loss: 10.657910, valid precision: 0.873800, valid loss: 91.490027
epoch: 1596, train precision: 0.998622, train loss: 10.721073, valid precision: 0.875200, valid loss: 92.882902
epoch: 1597, train precision: 0.998400, train loss: 10.818580, valid precision: 0.875800, valid loss: 93.665958
epoch: 1598, train precision: 0.998756, train loss: 10.661550, valid precision: 0.871200, valid loss: 93.037058
epoch: 1599, train precision: 0.998844, train loss: 10.673867, valid precision: 0.876000, valid loss: 92.168513
epoch: 1600, train precision: 0.998956, train loss: 10.595240, valid precision: 0.873800, valid loss: 92.070933
epoch: 1601, train precision: 0.998978, train loss: 10.640799, valid precision: 0.874400, valid loss: 95.650688
epoch: 1602, train precision: 0.998600, train loss: 10.790846, valid precision: 0.872200, valid loss: 93.514333
epoch: 1603, train precision: 0.999289, train loss: 10.532632, valid precision: 0.876400, valid loss: 92.162698
epoch: 1604, train precision: 0.998378, train loss: 10.795571, valid precision: 0.873200, valid loss: 93.935707
epoch: 1605, train precision: 0.999044, train loss: 10.680077, valid precision: 0.878600, valid loss: 92.400063
epoch: 1606, train precision: 0.999022, train loss: 10.690196, valid precision: 0.879600, valid loss: 91.358976
epoch: 1607, train precision: 0.998978, train loss: 10.669554, valid precision: 0.877800, valid loss: 91.988575
epoch: 1608, train precision: 0.999067, train loss: 10.627643, valid precision: 0.877200, valid loss: 89.895570
epoch: 1609, train precision: 0.998978, train loss: 10.604898, valid precision: 0.880800, valid loss: 89.699531
epoch: 1610, train precision: 0.998867, train loss: 10.621772, valid precision: 0.875400, valid loss: 92.269171
epoch: 1611, train precision: 0.998889, train loss: 10.701947, valid precision: 0.878400, valid loss: 91.062817
epoch: 1612, train precision: 0.998978, train loss: 10.584923, valid precision: 0.878400, valid loss: 92.002172
epoch: 1613, train precision: 0.998844, train loss: 10.754137, valid precision: 0.876400, valid loss: 93.229808
epoch: 1614, train precision: 0.998733, train loss: 10.727749, valid precision: 0.874600, valid loss: 91.427155
epoch: 1615, train precision: 0.999089, train loss: 10.616312, valid precision: 0.877800, valid loss: 89.483374
epoch: 1616, train precision: 0.999044, train loss: 10.631594, valid precision: 0.877000, valid loss: 90.051171
epoch: 1617, train precision: 0.999244, train loss: 10.604282, valid precision: 0.872400, valid loss: 90.645937
epoch: 1618, train precision: 0.999067, train loss: 10.638023, valid precision: 0.875800, valid loss: 89.338864
epoch: 1619, train precision: 0.999089, train loss: 10.595640, valid precision: 0.878000, valid loss: 90.340878
epoch: 1620, train precision: 0.998533, train loss: 10.829281, valid precision: 0.875000, valid loss: 93.257150
epoch: 1621, train precision: 0.998867, train loss: 10.645381, valid precision: 0.876600, valid loss: 88.497767
epoch: 1622, train precision: 0.998844, train loss: 10.667831, valid precision: 0.877800, valid loss: 90.854042
epoch: 1623, train precision: 0.998267, train loss: 10.824056, valid precision: 0.878600, valid loss: 90.518103
epoch: 1624, train precision: 0.998956, train loss: 10.633132, valid precision: 0.877400, valid loss: 88.402682
epoch: 1625, train precision: 0.998644, train loss: 10.765532, valid precision: 0.877800, valid loss: 92.114002
epoch: 1626, train precision: 0.998800, train loss: 10.694070, valid precision: 0.876400, valid loss: 92.211561
epoch: 1627, train precision: 0.999133, train loss: 10.611129, valid precision: 0.880400, valid loss: 88.850703
epoch: 1628, train precision: 0.998644, train loss: 10.811442, valid precision: 0.878600, valid loss: 90.740366
epoch: 1629, train precision: 0.998822, train loss: 10.668984, valid precision: 0.878800, valid loss: 88.866186
epoch: 1630, train precision: 0.998644, train loss: 10.738302, valid precision: 0.878200, valid loss: 89.393015
epoch: 1631, train precision: 0.999178, train loss: 10.586889, valid precision: 0.879800, valid loss: 88.182844
epoch: 1632, train precision: 0.998311, train loss: 10.866406, valid precision: 0.876800, valid loss: 89.019426
epoch: 1633, train precision: 0.998667, train loss: 10.758303, valid precision: 0.877400, valid loss: 87.638185
epoch: 1634, train precision: 0.998422, train loss: 10.806302, valid precision: 0.879000, valid loss: 89.758564
epoch: 1635, train precision: 0.998956, train loss: 10.676580, valid precision: 0.878600, valid loss: 86.934874
epoch: 1636, train precision: 0.999156, train loss: 10.605983, valid precision: 0.881200, valid loss: 88.183067
epoch: 1637, train precision: 0.998956, train loss: 10.664248, valid precision: 0.877800, valid loss: 88.431633
epoch: 1638, train precision: 0.998911, train loss: 10.717111, valid precision: 0.877400, valid loss: 89.615680
epoch: 1639, train precision: 0.998978, train loss: 10.653389, valid precision: 0.879000, valid loss: 87.146446
epoch: 1640, train precision: 0.998956, train loss: 10.654965, valid precision: 0.875200, valid loss: 89.226464
epoch: 1641, train precision: 0.998733, train loss: 10.716666, valid precision: 0.874200, valid loss: 88.922594
epoch: 1642, train precision: 0.998822, train loss: 10.636624, valid precision: 0.879200, valid loss: 89.217909
epoch: 1643, train precision: 0.998067, train loss: 10.841187, valid precision: 0.876200, valid loss: 91.996475
epoch: 1644, train precision: 0.999022, train loss: 10.653668, valid precision: 0.878000, valid loss: 90.496720
epoch: 1645, train precision: 0.998489, train loss: 10.814733, valid precision: 0.882400, valid loss: 89.568600
epoch: 1646, train precision: 0.998933, train loss: 10.687362, valid precision: 0.875400, valid loss: 90.593909
epoch: 1647, train precision: 0.998911, train loss: 10.690056, valid precision: 0.881000, valid loss: 90.378339
epoch: 1648, train precision: 0.998133, train loss: 10.859727, valid precision: 0.875000, valid loss: 93.369016
epoch: 1649, train precision: 0.998867, train loss: 10.645029, valid precision: 0.879200, valid loss: 89.845302
epoch: 1650, train precision: 0.998267, train loss: 10.902521, valid precision: 0.870200, valid loss: 89.898272
epoch: 1651, train precision: 0.998889, train loss: 10.655203, valid precision: 0.875000, valid loss: 89.151957
epoch: 1652, train precision: 0.998733, train loss: 10.697130, valid precision: 0.873400, valid loss: 89.019653
epoch: 1653, train precision: 0.999089, train loss: 10.525170, valid precision: 0.876200, valid loss: 91.449040
epoch: 1654, train precision: 0.998733, train loss: 10.742861, valid precision: 0.874400, valid loss: 92.127112
epoch: 1655, train precision: 0.998489, train loss: 10.842809, valid precision: 0.874000, valid loss: 93.724892
epoch: 1656, train precision: 0.998867, train loss: 10.627478, valid precision: 0.876000, valid loss: 90.054918
epoch: 1657, train precision: 0.998067, train loss: 10.990628, valid precision: 0.872200, valid loss: 91.677546
epoch: 1658, train precision: 0.998978, train loss: 10.697665, valid precision: 0.877000, valid loss: 90.299167
epoch: 1659, train precision: 0.998800, train loss: 10.705626, valid precision: 0.875000, valid loss: 92.712336
epoch: 1660, train precision: 0.998933, train loss: 10.642396, valid precision: 0.878400, valid loss: 91.387009
epoch: 1661, train precision: 0.998711, train loss: 10.659773, valid precision: 0.878000, valid loss: 89.469297
epoch: 1662, train precision: 0.998244, train loss: 10.833486, valid precision: 0.872800, valid loss: 93.283068
epoch: 1663, train precision: 0.998778, train loss: 10.705989, valid precision: 0.874800, valid loss: 89.230470
epoch: 1664, train precision: 0.999156, train loss: 10.597873, valid precision: 0.878200, valid loss: 89.317620
epoch: 1665, train precision: 0.998267, train loss: 10.913037, valid precision: 0.874400, valid loss: 90.835286
epoch: 1666, train precision: 0.998556, train loss: 10.705081, valid precision: 0.874200, valid loss: 92.543772
epoch: 1667, train precision: 0.998622, train loss: 10.718427, valid precision: 0.875200, valid loss: 90.744524
epoch: 1668, train precision: 0.998467, train loss: 10.742917, valid precision: 0.874400, valid loss: 93.304072
epoch: 1669, train precision: 0.998667, train loss: 10.674946, valid precision: 0.876000, valid loss: 93.367932
epoch: 1670, train precision: 0.998978, train loss: 10.627664, valid precision: 0.874400, valid loss: 90.784165
epoch: 1671, train precision: 0.998978, train loss: 10.627361, valid precision: 0.873200, valid loss: 89.758007
epoch: 1672, train precision: 0.999267, train loss: 10.555782, valid precision: 0.874000, valid loss: 92.204053
epoch: 1673, train precision: 0.998822, train loss: 10.641287, valid precision: 0.877400, valid loss: 90.298451
epoch: 1674, train precision: 0.998933, train loss: 10.624484, valid precision: 0.879600, valid loss: 89.190283
epoch: 1675, train precision: 0.999111, train loss: 10.640542, valid precision: 0.879400, valid loss: 88.924013
epoch: 1676, train precision: 0.998689, train loss: 10.775327, valid precision: 0.875400, valid loss: 89.622758
epoch: 1677, train precision: 0.998667, train loss: 10.715941, valid precision: 0.879800, valid loss: 88.034476
epoch: 1678, train precision: 0.999000, train loss: 10.589531, valid precision: 0.875400, valid loss: 90.758755
epoch: 1679, train precision: 0.998800, train loss: 10.674688, valid precision: 0.874000, valid loss: 91.006542
epoch: 1680, train precision: 0.998444, train loss: 10.832924, valid precision: 0.874200, valid loss: 90.844820
epoch: 1681, train precision: 0.998889, train loss: 10.638413, valid precision: 0.876200, valid loss: 88.787023
epoch: 1682, train precision: 0.999044, train loss: 10.696009, valid precision: 0.876000, valid loss: 87.958968
epoch: 1683, train precision: 0.998889, train loss: 10.656646, valid precision: 0.876000, valid loss: 90.005772
epoch: 1684, train precision: 0.998733, train loss: 10.716072, valid precision: 0.873200, valid loss: 88.980318
epoch: 1685, train precision: 0.998933, train loss: 10.652142, valid precision: 0.874000, valid loss: 88.089435
epoch: 1686, train precision: 0.998933, train loss: 10.608675, valid precision: 0.878400, valid loss: 88.054862
epoch: 1687, train precision: 0.998889, train loss: 10.689629, valid precision: 0.870200, valid loss: 92.661056
epoch: 1688, train precision: 0.998933, train loss: 10.619384, valid precision: 0.870200, valid loss: 93.008925
epoch: 1689, train precision: 0.998844, train loss: 10.616258, valid precision: 0.873200, valid loss: 91.080478
epoch: 1690, train precision: 0.999067, train loss: 10.630459, valid precision: 0.872400, valid loss: 90.497079
epoch: 1691, train precision: 0.998844, train loss: 10.622922, valid precision: 0.880000, valid loss: 90.274372
epoch: 1692, train precision: 0.999022, train loss: 10.595511, valid precision: 0.876000, valid loss: 90.401524
epoch: 1693, train precision: 0.998889, train loss: 10.676074, valid precision: 0.879000, valid loss: 89.736798
epoch: 1694, train precision: 0.998689, train loss: 10.716799, valid precision: 0.876200, valid loss: 91.856067
epoch: 1695, train precision: 0.998689, train loss: 10.692204, valid precision: 0.875600, valid loss: 89.766808
epoch: 1696, train precision: 0.999111, train loss: 10.589446, valid precision: 0.871800, valid loss: 93.499245
epoch: 1697, train precision: 0.998578, train loss: 10.706547, valid precision: 0.870800, valid loss: 91.151242
epoch: 1698, train precision: 0.998711, train loss: 10.735800, valid precision: 0.872000, valid loss: 90.825388
epoch: 1699, train precision: 0.999111, train loss: 10.609052, valid precision: 0.876200, valid loss: 90.309481
epoch: 1700, train precision: 0.999089, train loss: 10.581953, valid precision: 0.875000, valid loss: 89.752889
epoch: 1701, train precision: 0.998956, train loss: 10.627254, valid precision: 0.873600, valid loss: 92.413585
epoch: 1702, train precision: 0.998844, train loss: 10.682761, valid precision: 0.870600, valid loss: 92.450427
epoch: 1703, train precision: 0.998600, train loss: 10.735100, valid precision: 0.870000, valid loss: 92.961691
epoch: 1704, train precision: 0.998533, train loss: 10.714654, valid precision: 0.877000, valid loss: 89.730669
epoch: 1705, train precision: 0.998756, train loss: 10.676873, valid precision: 0.878000, valid loss: 90.943389
epoch: 1706, train precision: 0.999200, train loss: 10.548251, valid precision: 0.873600, valid loss: 91.781643
epoch: 1707, train precision: 0.999178, train loss: 10.546712, valid precision: 0.874800, valid loss: 92.155632
epoch: 1708, train precision: 0.998778, train loss: 10.637330, valid precision: 0.875200, valid loss: 93.340994
epoch: 1709, train precision: 0.998844, train loss: 10.643273, valid precision: 0.876200, valid loss: 92.334121
epoch: 1710, train precision: 0.998956, train loss: 10.647343, valid precision: 0.873600, valid loss: 91.605881
epoch: 1711, train precision: 0.998889, train loss: 10.609110, valid precision: 0.875200, valid loss: 91.239993
epoch: 1712, train precision: 0.998711, train loss: 10.697677, valid precision: 0.875600, valid loss: 90.449318
epoch: 1713, train precision: 0.998911, train loss: 10.620275, valid precision: 0.877800, valid loss: 90.011137
epoch: 1714, train precision: 0.998800, train loss: 10.621937, valid precision: 0.876600, valid loss: 92.086714
epoch: 1715, train precision: 0.998844, train loss: 10.683215, valid precision: 0.878200, valid loss: 90.949476
epoch: 1716, train precision: 0.999111, train loss: 10.601105, valid precision: 0.877400, valid loss: 90.860056
epoch: 1717, train precision: 0.998289, train loss: 10.764279, valid precision: 0.873000, valid loss: 93.093350
epoch: 1718, train precision: 0.999156, train loss: 10.574278, valid precision: 0.876800, valid loss: 90.571813
epoch: 1719, train precision: 0.999200, train loss: 10.562356, valid precision: 0.879400, valid loss: 88.977411
epoch: 1720, train precision: 0.998978, train loss: 10.599839, valid precision: 0.875400, valid loss: 90.597097
epoch: 1721, train precision: 0.999022, train loss: 10.605383, valid precision: 0.877000, valid loss: 90.756070
epoch: 1722, train precision: 0.998644, train loss: 10.692508, valid precision: 0.874000, valid loss: 92.215232
epoch: 1723, train precision: 0.998756, train loss: 10.700911, valid precision: 0.875600, valid loss: 91.963076
epoch: 1724, train precision: 0.999067, train loss: 10.630426, valid precision: 0.879200, valid loss: 91.978928
epoch: 1725, train precision: 0.998333, train loss: 10.805271, valid precision: 0.873400, valid loss: 95.824378
epoch: 1726, train precision: 0.998889, train loss: 10.568655, valid precision: 0.877200, valid loss: 93.697271
epoch: 1727, train precision: 0.998911, train loss: 10.670769, valid precision: 0.870400, valid loss: 95.854829
epoch: 1728, train precision: 0.998933, train loss: 10.574751, valid precision: 0.876600, valid loss: 93.969826
epoch: 1729, train precision: 0.999111, train loss: 10.565485, valid precision: 0.873800, valid loss: 93.891453
epoch: 1730, train precision: 0.998533, train loss: 10.769416, valid precision: 0.871200, valid loss: 93.269576
epoch: 1731, train precision: 0.998911, train loss: 10.616497, valid precision: 0.873400, valid loss: 93.821987
epoch: 1732, train precision: 0.998822, train loss: 10.619917, valid precision: 0.872400, valid loss: 94.192691
epoch: 1733, train precision: 0.998822, train loss: 10.699022, valid precision: 0.875400, valid loss: 92.598766
epoch: 1734, train precision: 0.998600, train loss: 10.713863, valid precision: 0.876800, valid loss: 91.778993
epoch: 1735, train precision: 0.998889, train loss: 10.636594, valid precision: 0.875000, valid loss: 92.685092
epoch: 1736, train precision: 0.999244, train loss: 10.565496, valid precision: 0.872200, valid loss: 95.266799
epoch: 1737, train precision: 0.999022, train loss: 10.626913, valid precision: 0.871600, valid loss: 93.147942
epoch: 1738, train precision: 0.998822, train loss: 10.641946, valid precision: 0.875200, valid loss: 94.460272
epoch: 1739, train precision: 0.998089, train loss: 10.788849, valid precision: 0.872200, valid loss: 95.519533
epoch: 1740, train precision: 0.999067, train loss: 10.565220, valid precision: 0.872800, valid loss: 94.279433
epoch: 1741, train precision: 0.998756, train loss: 10.699204, valid precision: 0.871800, valid loss: 95.564742
epoch: 1742, train precision: 0.998711, train loss: 10.632932, valid precision: 0.872000, valid loss: 97.023969
epoch: 1743, train precision: 0.999000, train loss: 10.547186, valid precision: 0.874800, valid loss: 93.299093
epoch: 1744, train precision: 0.998556, train loss: 10.733704, valid precision: 0.874200, valid loss: 94.913466
epoch: 1745, train precision: 0.998733, train loss: 10.689825, valid precision: 0.873000, valid loss: 95.149086
epoch: 1746, train precision: 0.999067, train loss: 10.569449, valid precision: 0.876600, valid loss: 93.736621
epoch: 1747, train precision: 0.998889, train loss: 10.624125, valid precision: 0.873000, valid loss: 97.035984
epoch: 1748, train precision: 0.998111, train loss: 10.880500, valid precision: 0.871600, valid loss: 98.889709
epoch: 1749, train precision: 0.998844, train loss: 10.603798, valid precision: 0.874000, valid loss: 93.449415
epoch: 1750, train precision: 0.999000, train loss: 10.653922, valid precision: 0.873000, valid loss: 92.097582
epoch: 1751, train precision: 0.999044, train loss: 10.624992, valid precision: 0.873600, valid loss: 93.969369
epoch: 1752, train precision: 0.998889, train loss: 10.629192, valid precision: 0.876000, valid loss: 93.068749
epoch: 1753, train precision: 0.998733, train loss: 10.666372, valid precision: 0.872200, valid loss: 94.826802
epoch: 1754, train precision: 0.998956, train loss: 10.649315, valid precision: 0.875400, valid loss: 93.431653
epoch: 1755, train precision: 0.998844, train loss: 10.634395, valid precision: 0.876400, valid loss: 95.656662
epoch: 1756, train precision: 0.998889, train loss: 10.595267, valid precision: 0.871400, valid loss: 93.976040
epoch: 1757, train precision: 0.998933, train loss: 10.592382, valid precision: 0.875400, valid loss: 93.788664
epoch: 1758, train precision: 0.999178, train loss: 10.603705, valid precision: 0.875600, valid loss: 95.596516
epoch: 1759, train precision: 0.998933, train loss: 10.643533, valid precision: 0.872800, valid loss: 94.096225
epoch: 1760, train precision: 0.998444, train loss: 10.791781, valid precision: 0.868000, valid loss: 95.356982
epoch: 1761, train precision: 0.999044, train loss: 10.613801, valid precision: 0.876000, valid loss: 92.524019
epoch: 1762, train precision: 0.998867, train loss: 10.603044, valid precision: 0.873600, valid loss: 92.906410
epoch: 1763, train precision: 0.998800, train loss: 10.637625, valid precision: 0.876600, valid loss: 91.054816
epoch: 1764, train precision: 0.998800, train loss: 10.679071, valid precision: 0.874200, valid loss: 91.300979
epoch: 1765, train precision: 0.998978, train loss: 10.585210, valid precision: 0.878000, valid loss: 91.948533
epoch: 1766, train precision: 0.998578, train loss: 10.767699, valid precision: 0.873600, valid loss: 91.079538
epoch: 1767, train precision: 0.998844, train loss: 10.679838, valid precision: 0.875400, valid loss: 91.706448
epoch: 1768, train precision: 0.998956, train loss: 10.605226, valid precision: 0.873400, valid loss: 92.568220
epoch: 1769, train precision: 0.998778, train loss: 10.625937, valid precision: 0.872200, valid loss: 92.391320
epoch: 1770, train precision: 0.998489, train loss: 10.735118, valid precision: 0.873400, valid loss: 92.844037
epoch: 1771, train precision: 0.998622, train loss: 10.673146, valid precision: 0.875800, valid loss: 91.152338
epoch: 1772, train precision: 0.998467, train loss: 10.729116, valid precision: 0.873200, valid loss: 92.380480
epoch: 1773, train precision: 0.999067, train loss: 10.650538, valid precision: 0.875800, valid loss: 94.567154
epoch: 1774, train precision: 0.998600, train loss: 10.720703, valid precision: 0.874400, valid loss: 92.531456
epoch: 1775, train precision: 0.998889, train loss: 10.638661, valid precision: 0.879200, valid loss: 92.504360
epoch: 1776, train precision: 0.998889, train loss: 10.641732, valid precision: 0.878000, valid loss: 92.609436
epoch: 1777, train precision: 0.998933, train loss: 10.639940, valid precision: 0.869400, valid loss: 94.246480
epoch: 1778, train precision: 0.998956, train loss: 10.609101, valid precision: 0.875600, valid loss: 93.872459
epoch: 1779, train precision: 0.999044, train loss: 10.556906, valid precision: 0.875200, valid loss: 94.075861
epoch: 1780, train precision: 0.998444, train loss: 10.746829, valid precision: 0.877200, valid loss: 93.299213
epoch: 1781, train precision: 0.999067, train loss: 10.583857, valid precision: 0.873600, valid loss: 95.559599
epoch: 1782, train precision: 0.999067, train loss: 10.590796, valid precision: 0.874600, valid loss: 94.448018
epoch: 1783, train precision: 0.998822, train loss: 10.683123, valid precision: 0.875400, valid loss: 96.101002
epoch: 1784, train precision: 0.998867, train loss: 10.621496, valid precision: 0.876400, valid loss: 94.880490
epoch: 1785, train precision: 0.999022, train loss: 10.566858, valid precision: 0.874600, valid loss: 93.885224
epoch: 1786, train precision: 0.998911, train loss: 10.629758, valid precision: 0.874200, valid loss: 95.397200
epoch: 1787, train precision: 0.998378, train loss: 10.754457, valid precision: 0.875000, valid loss: 94.247035
epoch: 1788, train precision: 0.998956, train loss: 10.625441, valid precision: 0.876400, valid loss: 93.289486
epoch: 1789, train precision: 0.998889, train loss: 10.612373, valid precision: 0.875000, valid loss: 95.034088
epoch: 1790, train precision: 0.998844, train loss: 10.597333, valid precision: 0.875800, valid loss: 92.676700
epoch: 1791, train precision: 0.998600, train loss: 10.812628, valid precision: 0.875200, valid loss: 91.982188
epoch: 1792, train precision: 0.999089, train loss: 10.593183, valid precision: 0.874200, valid loss: 93.241322
epoch: 1793, train precision: 0.998933, train loss: 10.663444, valid precision: 0.876000, valid loss: 91.044085
epoch: 1794, train precision: 0.999000, train loss: 10.571874, valid precision: 0.875000, valid loss: 91.015561
epoch: 1795, train precision: 0.998889, train loss: 10.638991, valid precision: 0.874400, valid loss: 92.699908
epoch: 1796, train precision: 0.998622, train loss: 10.674707, valid precision: 0.873600, valid loss: 92.633665
epoch: 1797, train precision: 0.998844, train loss: 10.636263, valid precision: 0.876600, valid loss: 90.822972
epoch: 1798, train precision: 0.998556, train loss: 10.743160, valid precision: 0.865800, valid loss: 94.488002
epoch: 1799, train precision: 0.998889, train loss: 10.636631, valid precision: 0.872200, valid loss: 91.266485
epoch: 1800, train precision: 0.998578, train loss: 10.757472, valid precision: 0.873600, valid loss: 92.821804
epoch: 1801, train precision: 0.999289, train loss: 10.517888, valid precision: 0.870600, valid loss: 95.239582
epoch: 1802, train precision: 0.998356, train loss: 10.820368, valid precision: 0.871200, valid loss: 95.537837
epoch: 1803, train precision: 0.998867, train loss: 10.613222, valid precision: 0.873800, valid loss: 92.881354
epoch: 1804, train precision: 0.999000, train loss: 10.626814, valid precision: 0.871600, valid loss: 93.707241
epoch: 1805, train precision: 0.998533, train loss: 10.776311, valid precision: 0.871600, valid loss: 93.558111
epoch: 1806, train precision: 0.998489, train loss: 10.731274, valid precision: 0.872800, valid loss: 95.895422
epoch: 1807, train precision: 0.999089, train loss: 10.544650, valid precision: 0.874000, valid loss: 91.453283
epoch: 1808, train precision: 0.998933, train loss: 10.663217, valid precision: 0.868800, valid loss: 94.717840
epoch: 1809, train precision: 0.998956, train loss: 10.606986, valid precision: 0.876200, valid loss: 93.124899
epoch: 1810, train precision: 0.998733, train loss: 10.650342, valid precision: 0.875400, valid loss: 92.411366
epoch: 1811, train precision: 0.998844, train loss: 10.696664, valid precision: 0.871400, valid loss: 92.313372
epoch: 1812, train precision: 0.998400, train loss: 10.751932, valid precision: 0.873200, valid loss: 92.756299
epoch: 1813, train precision: 0.998756, train loss: 10.687878, valid precision: 0.872600, valid loss: 90.090324
epoch: 1814, train precision: 0.998689, train loss: 10.751156, valid precision: 0.875400, valid loss: 91.062874
epoch: 1815, train precision: 0.998889, train loss: 10.595360, valid precision: 0.873000, valid loss: 91.893391
epoch: 1816, train precision: 0.998489, train loss: 10.736681, valid precision: 0.876000, valid loss: 91.759219
epoch: 1817, train precision: 0.999022, train loss: 10.575905, valid precision: 0.876400, valid loss: 90.807265
epoch: 1818, train precision: 0.998933, train loss: 10.591890, valid precision: 0.874200, valid loss: 91.393051
epoch: 1819, train precision: 0.999133, train loss: 10.517055, valid precision: 0.872800, valid loss: 90.856688
epoch: 1820, train precision: 0.999022, train loss: 10.608364, valid precision: 0.872800, valid loss: 93.777454
epoch: 1821, train precision: 0.999022, train loss: 10.560463, valid precision: 0.874600, valid loss: 92.501515
epoch: 1822, train precision: 0.999089, train loss: 10.601705, valid precision: 0.875200, valid loss: 93.163764
epoch: 1823, train precision: 0.998800, train loss: 10.652573, valid precision: 0.875600, valid loss: 93.130681
epoch: 1824, train precision: 0.998844, train loss: 10.699187, valid precision: 0.875600, valid loss: 92.319329
epoch: 1825, train precision: 0.999089, train loss: 10.539919, valid precision: 0.873800, valid loss: 92.491998
epoch: 1826, train precision: 0.998044, train loss: 10.824987, valid precision: 0.876000, valid loss: 93.064651
epoch: 1827, train precision: 0.999178, train loss: 10.506513, valid precision: 0.876200, valid loss: 93.884212
epoch: 1828, train precision: 0.998889, train loss: 10.645003, valid precision: 0.878600, valid loss: 92.152490
epoch: 1829, train precision: 0.998911, train loss: 10.541810, valid precision: 0.877600, valid loss: 92.846844
epoch: 1830, train precision: 0.998311, train loss: 10.861595, valid precision: 0.873800, valid loss: 91.634480
epoch: 1831, train precision: 0.998867, train loss: 10.619305, valid precision: 0.878400, valid loss: 89.957544
epoch: 1832, train precision: 0.998911, train loss: 10.620876, valid precision: 0.875400, valid loss: 90.915493
epoch: 1833, train precision: 0.999022, train loss: 10.638891, valid precision: 0.873800, valid loss: 91.912757
epoch: 1834, train precision: 0.999000, train loss: 10.642158, valid precision: 0.875800, valid loss: 90.235037
epoch: 1835, train precision: 0.998711, train loss: 10.687951, valid precision: 0.872600, valid loss: 92.306674
epoch: 1836, train precision: 0.998644, train loss: 10.654939, valid precision: 0.875200, valid loss: 93.602975
epoch: 1837, train precision: 0.999044, train loss: 10.598703, valid precision: 0.873400, valid loss: 92.603131
epoch: 1838, train precision: 0.999089, train loss: 10.622362, valid precision: 0.872800, valid loss: 92.248296
epoch: 1839, train precision: 0.998978, train loss: 10.593648, valid precision: 0.875200, valid loss: 93.270507
epoch: 1840, train precision: 0.999089, train loss: 10.564706, valid precision: 0.877200, valid loss: 91.904803
epoch: 1841, train precision: 0.998733, train loss: 10.619911, valid precision: 0.875600, valid loss: 92.983814
epoch: 1842, train precision: 0.998822, train loss: 10.645322, valid precision: 0.875800, valid loss: 92.909516
epoch: 1843, train precision: 0.998778, train loss: 10.649334, valid precision: 0.878000, valid loss: 92.648873
epoch: 1844, train precision: 0.998889, train loss: 10.609029, valid precision: 0.875200, valid loss: 95.972028
epoch: 1845, train precision: 0.998889, train loss: 10.553408, valid precision: 0.877000, valid loss: 93.158991
epoch: 1846, train precision: 0.999244, train loss: 10.522400, valid precision: 0.876000, valid loss: 92.801140
epoch: 1847, train precision: 0.999200, train loss: 10.560887, valid precision: 0.876600, valid loss: 93.589779
epoch: 1848, train precision: 0.998933, train loss: 10.641705, valid precision: 0.876200, valid loss: 93.726508
epoch: 1849, train precision: 0.998844, train loss: 10.670560, valid precision: 0.877400, valid loss: 91.846877
epoch: 1850, train precision: 0.998422, train loss: 10.788378, valid precision: 0.876400, valid loss: 92.081543
epoch: 1851, train precision: 0.998867, train loss: 10.591069, valid precision: 0.874800, valid loss: 92.854649
epoch: 1852, train precision: 0.998556, train loss: 10.656391, valid precision: 0.871800, valid loss: 92.350831
epoch: 1853, train precision: 0.998867, train loss: 10.654668, valid precision: 0.872400, valid loss: 92.951820
epoch: 1854, train precision: 0.998778, train loss: 10.661440, valid precision: 0.869400, valid loss: 93.534717
epoch: 1855, train precision: 0.999067, train loss: 10.561958, valid precision: 0.875800, valid loss: 92.857936
epoch: 1856, train precision: 0.998644, train loss: 10.770751, valid precision: 0.872200, valid loss: 94.908275
epoch: 1857, train precision: 0.998822, train loss: 10.664251, valid precision: 0.878000, valid loss: 92.829217
epoch: 1858, train precision: 0.998600, train loss: 10.757226, valid precision: 0.870400, valid loss: 94.957502
epoch: 1859, train precision: 0.998644, train loss: 10.678427, valid precision: 0.874000, valid loss: 94.103253
epoch: 1860, train precision: 0.998778, train loss: 10.659616, valid precision: 0.876600, valid loss: 91.709962
epoch: 1861, train precision: 0.998711, train loss: 10.656990, valid precision: 0.875800, valid loss: 93.904636
epoch: 1862, train precision: 0.999000, train loss: 10.599003, valid precision: 0.875000, valid loss: 91.504146
epoch: 1863, train precision: 0.998533, train loss: 10.728767, valid precision: 0.874600, valid loss: 91.972331
epoch: 1864, train precision: 0.998933, train loss: 10.559099, valid precision: 0.877000, valid loss: 89.228128
epoch: 1865, train precision: 0.998778, train loss: 10.711461, valid precision: 0.876400, valid loss: 90.308455
epoch: 1866, train precision: 0.999067, train loss: 10.555283, valid precision: 0.879200, valid loss: 87.274543
epoch: 1867, train precision: 0.998644, train loss: 10.681540, valid precision: 0.877600, valid loss: 90.017142
epoch: 1868, train precision: 0.998622, train loss: 10.693373, valid precision: 0.877600, valid loss: 91.892925
epoch: 1869, train precision: 0.998733, train loss: 10.690058, valid precision: 0.880800, valid loss: 88.201255
epoch: 1870, train precision: 0.998956, train loss: 10.655109, valid precision: 0.873600, valid loss: 91.163302
epoch: 1871, train precision: 0.999133, train loss: 10.558161, valid precision: 0.878800, valid loss: 89.207075
epoch: 1872, train precision: 0.998956, train loss: 10.636186, valid precision: 0.877000, valid loss: 91.693322
epoch: 1873, train precision: 0.999022, train loss: 10.537025, valid precision: 0.875800, valid loss: 90.880790
epoch: 1874, train precision: 0.998667, train loss: 10.749196, valid precision: 0.874200, valid loss: 92.392741
epoch: 1875, train precision: 0.998911, train loss: 10.623067, valid precision: 0.877000, valid loss: 94.248599
epoch: 1876, train precision: 0.998711, train loss: 10.697197, valid precision: 0.875800, valid loss: 92.292878
epoch: 1877, train precision: 0.998889, train loss: 10.610246, valid precision: 0.874600, valid loss: 91.499858
epoch: 1878, train precision: 0.999089, train loss: 10.602123, valid precision: 0.875600, valid loss: 91.889404
epoch: 1879, train precision: 0.998644, train loss: 10.626571, valid precision: 0.875000, valid loss: 91.938535
epoch: 1880, train precision: 0.998822, train loss: 10.712999, valid precision: 0.873800, valid loss: 92.797562
epoch: 1881, train precision: 0.998622, train loss: 10.668187, valid precision: 0.879200, valid loss: 93.929296
epoch: 1882, train precision: 0.998444, train loss: 10.818121, valid precision: 0.878200, valid loss: 93.224800
epoch: 1883, train precision: 0.998867, train loss: 10.631357, valid precision: 0.876400, valid loss: 94.406488
epoch: 1884, train precision: 0.998933, train loss: 10.630561, valid precision: 0.872600, valid loss: 93.083389
epoch: 1885, train precision: 0.998911, train loss: 10.618034, valid precision: 0.875800, valid loss: 92.278998
epoch: 1886, train precision: 0.998689, train loss: 10.627275, valid precision: 0.875600, valid loss: 93.856902
epoch: 1887, train precision: 0.998444, train loss: 10.726185, valid precision: 0.876800, valid loss: 94.344032
epoch: 1888, train precision: 0.999022, train loss: 10.574590, valid precision: 0.876400, valid loss: 93.407292
epoch: 1889, train precision: 0.998733, train loss: 10.673887, valid precision: 0.877600, valid loss: 91.560151
epoch: 1890, train precision: 0.999089, train loss: 10.545116, valid precision: 0.873400, valid loss: 94.062976
epoch: 1891, train precision: 0.998733, train loss: 10.704400, valid precision: 0.872200, valid loss: 94.134222
epoch: 1892, train precision: 0.998756, train loss: 10.642632, valid precision: 0.876200, valid loss: 95.274805
epoch: 1893, train precision: 0.998800, train loss: 10.624048, valid precision: 0.872600, valid loss: 91.267522
epoch: 1894, train precision: 0.998689, train loss: 10.650750, valid precision: 0.876000, valid loss: 91.270708
epoch: 1895, train precision: 0.998733, train loss: 10.671782, valid precision: 0.873200, valid loss: 92.478503
epoch: 1896, train precision: 0.998778, train loss: 10.621615, valid precision: 0.876000, valid loss: 91.580510
epoch: 1897, train precision: 0.998978, train loss: 10.559964, valid precision: 0.879800, valid loss: 94.144906
epoch: 1898, train precision: 0.999067, train loss: 10.612027, valid precision: 0.874600, valid loss: 94.414457
epoch: 1899, train precision: 0.999022, train loss: 10.616459, valid precision: 0.878000, valid loss: 92.328125
epoch: 1900, train precision: 0.998844, train loss: 10.585502, valid precision: 0.877200, valid loss: 91.741884
epoch: 1901, train precision: 0.998889, train loss: 10.675266, valid precision: 0.878600, valid loss: 92.259098
epoch: 1902, train precision: 0.999333, train loss: 10.493963, valid precision: 0.879800, valid loss: 91.706460
epoch: 1903, train precision: 0.999022, train loss: 10.618118, valid precision: 0.875200, valid loss: 90.976268
epoch: 1904, train precision: 0.998622, train loss: 10.710667, valid precision: 0.874000, valid loss: 92.924364
epoch: 1905, train precision: 0.998311, train loss: 10.827118, valid precision: 0.870400, valid loss: 94.319223
epoch: 1906, train precision: 0.999156, train loss: 10.483848, valid precision: 0.875600, valid loss: 92.884022
epoch: 1907, train precision: 0.998978, train loss: 10.574726, valid precision: 0.874000, valid loss: 93.117207
epoch: 1908, train precision: 0.998978, train loss: 10.594956, valid precision: 0.878200, valid loss: 92.501410
epoch: 1909, train precision: 0.998956, train loss: 10.495587, valid precision: 0.871000, valid loss: 94.177508
epoch: 1910, train precision: 0.998533, train loss: 10.734448, valid precision: 0.872200, valid loss: 95.739431
epoch: 1911, train precision: 0.999089, train loss: 10.568483, valid precision: 0.871200, valid loss: 93.423745
epoch: 1912, train precision: 0.998733, train loss: 10.726100, valid precision: 0.873000, valid loss: 96.043920
epoch: 1913, train precision: 0.999067, train loss: 10.526286, valid precision: 0.874200, valid loss: 93.861633
epoch: 1914, train precision: 0.999022, train loss: 10.564528, valid precision: 0.873400, valid loss: 90.432422
epoch: 1915, train precision: 0.998911, train loss: 10.599623, valid precision: 0.876000, valid loss: 92.325309
epoch: 1916, train precision: 0.998644, train loss: 10.630396, valid precision: 0.872600, valid loss: 95.116427
epoch: 1917, train precision: 0.999111, train loss: 10.554313, valid precision: 0.875000, valid loss: 94.336457
epoch: 1918, train precision: 0.998889, train loss: 10.609147, valid precision: 0.869200, valid loss: 92.347043
epoch: 1919, train precision: 0.999044, train loss: 10.547712, valid precision: 0.876400, valid loss: 91.506034
epoch: 1920, train precision: 0.998933, train loss: 10.578411, valid precision: 0.874800, valid loss: 93.262672
epoch: 1921, train precision: 0.998889, train loss: 10.626806, valid precision: 0.875800, valid loss: 92.279055
epoch: 1922, train precision: 0.998644, train loss: 10.637208, valid precision: 0.878400, valid loss: 93.879041
epoch: 1923, train precision: 0.998689, train loss: 10.596625, valid precision: 0.873800, valid loss: 93.547153
epoch: 1924, train precision: 0.998444, train loss: 10.749649, valid precision: 0.876800, valid loss: 94.165146
epoch: 1925, train precision: 0.998933, train loss: 10.564484, valid precision: 0.872600, valid loss: 93.161363
epoch: 1926, train precision: 0.998956, train loss: 10.599359, valid precision: 0.870800, valid loss: 91.725385
epoch: 1927, train precision: 0.999200, train loss: 10.500583, valid precision: 0.878800, valid loss: 91.618676
epoch: 1928, train precision: 0.999044, train loss: 10.574962, valid precision: 0.873200, valid loss: 94.241917
epoch: 1929, train precision: 0.998756, train loss: 10.621136, valid precision: 0.874000, valid loss: 95.192215
epoch: 1930, train precision: 0.999000, train loss: 10.609961, valid precision: 0.873600, valid loss: 95.967035
epoch: 1931, train precision: 0.998911, train loss: 10.615844, valid precision: 0.868800, valid loss: 93.971490
epoch: 1932, train precision: 0.998622, train loss: 10.674744, valid precision: 0.874200, valid loss: 93.345036
epoch: 1933, train precision: 0.999200, train loss: 10.549009, valid precision: 0.874200, valid loss: 92.558040
epoch: 1934, train precision: 0.998667, train loss: 10.679354, valid precision: 0.875200, valid loss: 92.516288
epoch: 1935, train precision: 0.999022, train loss: 10.609099, valid precision: 0.870400, valid loss: 93.685822
epoch: 1936, train precision: 0.998867, train loss: 10.586480, valid precision: 0.875800, valid loss: 97.505431
epoch: 1937, train precision: 0.998933, train loss: 10.623272, valid precision: 0.878800, valid loss: 93.752333
epoch: 1938, train precision: 0.999222, train loss: 10.491184, valid precision: 0.874200, valid loss: 94.756701
epoch: 1939, train precision: 0.998356, train loss: 10.765618, valid precision: 0.871400, valid loss: 96.583616
epoch: 1940, train precision: 0.998933, train loss: 10.569192, valid precision: 0.874400, valid loss: 94.585217
epoch: 1941, train precision: 0.998889, train loss: 10.667124, valid precision: 0.873400, valid loss: 95.432390
epoch: 1942, train precision: 0.999156, train loss: 10.588085, valid precision: 0.874800, valid loss: 96.118482
epoch: 1943, train precision: 0.998978, train loss: 10.575704, valid precision: 0.871600, valid loss: 94.538406
epoch: 1944, train precision: 0.998689, train loss: 10.642482, valid precision: 0.876600, valid loss: 95.205442
epoch: 1945, train precision: 0.999133, train loss: 10.494597, valid precision: 0.875000, valid loss: 95.039325
epoch: 1946, train precision: 0.999133, train loss: 10.514494, valid precision: 0.877000, valid loss: 93.100244
epoch: 1947, train precision: 0.998711, train loss: 10.633343, valid precision: 0.876000, valid loss: 95.612451
epoch: 1948, train precision: 0.998844, train loss: 10.608528, valid precision: 0.874800, valid loss: 95.248070
epoch: 1949, train precision: 0.998489, train loss: 10.705195, valid precision: 0.873600, valid loss: 94.664241
epoch: 1950, train precision: 0.998889, train loss: 10.588630, valid precision: 0.875200, valid loss: 92.211568
epoch: 1951, train precision: 0.998933, train loss: 10.610083, valid precision: 0.876600, valid loss: 92.498819
epoch: 1952, train precision: 0.999044, train loss: 10.560177, valid precision: 0.876000, valid loss: 93.629951
epoch: 1953, train precision: 0.998867, train loss: 10.585706, valid precision: 0.875200, valid loss: 92.178033
epoch: 1954, train precision: 0.999133, train loss: 10.459995, valid precision: 0.876400, valid loss: 93.453275
epoch: 1955, train precision: 0.998622, train loss: 10.714750, valid precision: 0.876800, valid loss: 94.610985
epoch: 1956, train precision: 0.999244, train loss: 10.487807, valid precision: 0.875400, valid loss: 90.982384
epoch: 1957, train precision: 0.998733, train loss: 10.635502, valid precision: 0.877600, valid loss: 90.629185
epoch: 1958, train precision: 0.998711, train loss: 10.728548, valid precision: 0.873000, valid loss: 91.985418
epoch: 1959, train precision: 0.999000, train loss: 10.532778, valid precision: 0.878000, valid loss: 93.826786
epoch: 1960, train precision: 0.998956, train loss: 10.519475, valid precision: 0.877200, valid loss: 93.992306
epoch: 1961, train precision: 0.998844, train loss: 10.560702, valid precision: 0.874600, valid loss: 93.024767
epoch: 1962, train precision: 0.999133, train loss: 10.525443, valid precision: 0.878200, valid loss: 94.664606
epoch: 1963, train precision: 0.998733, train loss: 10.648176, valid precision: 0.875600, valid loss: 95.847403
epoch: 1964, train precision: 0.998867, train loss: 10.614758, valid precision: 0.873200, valid loss: 94.245497
epoch: 1965, train precision: 0.999000, train loss: 10.612214, valid precision: 0.877600, valid loss: 92.785527
epoch: 1966, train precision: 0.999111, train loss: 10.543458, valid precision: 0.873400, valid loss: 92.596016
epoch: 1967, train precision: 0.999000, train loss: 10.614998, valid precision: 0.875000, valid loss: 93.368776
epoch: 1968, train precision: 0.999244, train loss: 10.529277, valid precision: 0.871200, valid loss: 95.232053
epoch: 1969, train precision: 0.998844, train loss: 10.562217, valid precision: 0.874800, valid loss: 94.653878
epoch: 1970, train precision: 0.999311, train loss: 10.468027, valid precision: 0.874400, valid loss: 92.489166
epoch: 1971, train precision: 0.998800, train loss: 10.589478, valid precision: 0.874400, valid loss: 94.950921
epoch: 1972, train precision: 0.998556, train loss: 10.685598, valid precision: 0.870600, valid loss: 95.523111
epoch: 1973, train precision: 0.998867, train loss: 10.566223, valid precision: 0.868000, valid loss: 97.210683
epoch: 1974, train precision: 0.998889, train loss: 10.649139, valid precision: 0.874400, valid loss: 94.898373
epoch: 1975, train precision: 0.998978, train loss: 10.608454, valid precision: 0.875600, valid loss: 92.292232
epoch: 1976, train precision: 0.998756, train loss: 10.587262, valid precision: 0.876000, valid loss: 93.384836
epoch: 1977, train precision: 0.998800, train loss: 10.623261, valid precision: 0.876200, valid loss: 91.890035
epoch: 1978, train precision: 0.999022, train loss: 10.563705, valid precision: 0.875000, valid loss: 92.800473
epoch: 1979, train precision: 0.999133, train loss: 10.523516, valid precision: 0.869800, valid loss: 94.482880
epoch: 1980, train precision: 0.998689, train loss: 10.667590, valid precision: 0.870800, valid loss: 94.011647
epoch: 1981, train precision: 0.999044, train loss: 10.554028, valid precision: 0.876200, valid loss: 94.713218
epoch: 1982, train precision: 0.998844, train loss: 10.617123, valid precision: 0.875400, valid loss: 95.854591
epoch: 1983, train precision: 0.999089, train loss: 10.504021, valid precision: 0.871000, valid loss: 94.646382
epoch: 1984, train precision: 0.999178, train loss: 10.508862, valid precision: 0.873000, valid loss: 92.862018
epoch: 1985, train precision: 0.998756, train loss: 10.563175, valid precision: 0.874800, valid loss: 92.897709
epoch: 1986, train precision: 0.998978, train loss: 10.551783, valid precision: 0.875600, valid loss: 93.509236
epoch: 1987, train precision: 0.998489, train loss: 10.721807, valid precision: 0.876400, valid loss: 94.381199
epoch: 1988, train precision: 0.998889, train loss: 10.576521, valid precision: 0.875400, valid loss: 95.813665
epoch: 1989, train precision: 0.998889, train loss: 10.566593, valid precision: 0.874000, valid loss: 93.532458
epoch: 1990, train precision: 0.998956, train loss: 10.529274, valid precision: 0.875600, valid loss: 93.152058
epoch: 1991, train precision: 0.998822, train loss: 10.652494, valid precision: 0.875600, valid loss: 95.025498
epoch: 1992, train precision: 0.998689, train loss: 10.675433, valid precision: 0.873400, valid loss: 94.181540
epoch: 1993, train precision: 0.999067, train loss: 10.512599, valid precision: 0.876200, valid loss: 93.817576
epoch: 1994, train precision: 0.998689, train loss: 10.663560, valid precision: 0.870800, valid loss: 96.001077
epoch: 1995, train precision: 0.998867, train loss: 10.550989, valid precision: 0.875000, valid loss: 94.166753
epoch: 1996, train precision: 0.998933, train loss: 10.618510, valid precision: 0.873600, valid loss: 95.257150
epoch: 1997, train precision: 0.998933, train loss: 10.545780, valid precision: 0.874600, valid loss: 96.449284
epoch: 1998, train precision: 0.999067, train loss: 10.571850, valid precision: 0.874200, valid loss: 94.949677
epoch: 1999, train precision: 0.998889, train loss: 10.572803, valid precision: 0.875000, valid loss: 95.093233
epoch: 2000, train precision: 0.999133, train loss: 10.530123, valid precision: 0.873400, valid loss: 95.734364
epoch: 2001, train precision: 0.999000, train loss: 10.558382, valid precision: 0.878200, valid loss: 94.085889
epoch: 2002, train precision: 0.998978, train loss: 10.530324, valid precision: 0.876000, valid loss: 95.936442
epoch: 2003, train precision: 0.999156, train loss: 10.521278, valid precision: 0.873600, valid loss: 96.326459
epoch: 2004, train precision: 0.998778, train loss: 10.584179, valid precision: 0.875600, valid loss: 95.452819
epoch: 2005, train precision: 0.998822, train loss: 10.535622, valid precision: 0.875600, valid loss: 95.626052
epoch: 2006, train precision: 0.999089, train loss: 10.539286, valid precision: 0.874800, valid loss: 96.811053
epoch: 2007, train precision: 0.999156, train loss: 10.561374, valid precision: 0.871200, valid loss: 98.012159
epoch: 2008, train precision: 0.998844, train loss: 10.642624, valid precision: 0.874000, valid loss: 94.344157
epoch: 2009, train precision: 0.999000, train loss: 10.498383, valid precision: 0.872000, valid loss: 94.000414
epoch: 2010, train precision: 0.998844, train loss: 10.573150, valid precision: 0.876200, valid loss: 93.805080
epoch: 2011, train precision: 0.999200, train loss: 10.563258, valid precision: 0.874000, valid loss: 92.266027
epoch: 2012, train precision: 0.998889, train loss: 10.657587, valid precision: 0.874200, valid loss: 92.827250
epoch: 2013, train precision: 0.998867, train loss: 10.580869, valid precision: 0.876400, valid loss: 92.620289
epoch: 2014, train precision: 0.998711, train loss: 10.587608, valid precision: 0.872600, valid loss: 92.689764
epoch: 2015, train precision: 0.998778, train loss: 10.626395, valid precision: 0.873600, valid loss: 93.241319
epoch: 2016, train precision: 0.998800, train loss: 10.691193, valid precision: 0.874800, valid loss: 90.194935
epoch: 2017, train precision: 0.998911, train loss: 10.563517, valid precision: 0.872000, valid loss: 93.771941
epoch: 2018, train precision: 0.998756, train loss: 10.600172, valid precision: 0.873000, valid loss: 94.829168
epoch: 2019, train precision: 0.998778, train loss: 10.588528, valid precision: 0.874600, valid loss: 94.345432
epoch: 2020, train precision: 0.998889, train loss: 10.562815, valid precision: 0.873000, valid loss: 95.060939
epoch: 2021, train precision: 0.998844, train loss: 10.610636, valid precision: 0.871200, valid loss: 95.204059
epoch: 2022, train precision: 0.999000, train loss: 10.522164, valid precision: 0.876600, valid loss: 93.626636
epoch: 2023, train precision: 0.998867, train loss: 10.648962, valid precision: 0.870600, valid loss: 93.559321
epoch: 2024, train precision: 0.999356, train loss: 10.457918, valid precision: 0.873800, valid loss: 93.613011
epoch: 2025, train precision: 0.998911, train loss: 10.539925, valid precision: 0.874000, valid loss: 94.144465
epoch: 2026, train precision: 0.998733, train loss: 10.601082, valid precision: 0.871400, valid loss: 98.159943
epoch: 2027, train precision: 0.998778, train loss: 10.614974, valid precision: 0.871800, valid loss: 99.265161
epoch: 2028, train precision: 0.998822, train loss: 10.594320, valid precision: 0.873400, valid loss: 96.646054
epoch: 2029, train precision: 0.998778, train loss: 10.606666, valid precision: 0.871600, valid loss: 95.605547
epoch: 2030, train precision: 0.998711, train loss: 10.653551, valid precision: 0.869000, valid loss: 97.525151
epoch: 2031, train precision: 0.998689, train loss: 10.628279, valid precision: 0.872000, valid loss: 94.701611
epoch: 2032, train precision: 0.998800, train loss: 10.590734, valid precision: 0.874400, valid loss: 93.443484
epoch: 2033, train precision: 0.998822, train loss: 10.622460, valid precision: 0.871000, valid loss: 94.650723
epoch: 2034, train precision: 0.999000, train loss: 10.536646, valid precision: 0.875000, valid loss: 95.388798
epoch: 2035, train precision: 0.998844, train loss: 10.621686, valid precision: 0.873000, valid loss: 97.049027
epoch: 2036, train precision: 0.999044, train loss: 10.531960, valid precision: 0.876200, valid loss: 93.161780
epoch: 2037, train precision: 0.999111, train loss: 10.507931, valid precision: 0.872800, valid loss: 95.737433
epoch: 2038, train precision: 0.999089, train loss: 10.490835, valid precision: 0.871400, valid loss: 95.119073
epoch: 2039, train precision: 0.999222, train loss: 10.437966, valid precision: 0.876400, valid loss: 94.363193
epoch: 2040, train precision: 0.999133, train loss: 10.483089, valid precision: 0.875200, valid loss: 93.666555
epoch: 2041, train precision: 0.998911, train loss: 10.584720, valid precision: 0.873200, valid loss: 95.415239
epoch: 2042, train precision: 0.998511, train loss: 10.644472, valid precision: 0.871000, valid loss: 97.695113
epoch: 2043, train precision: 0.998644, train loss: 10.689426, valid precision: 0.874200, valid loss: 95.167125
epoch: 2044, train precision: 0.998800, train loss: 10.585675, valid precision: 0.873600, valid loss: 94.920956
epoch: 2045, train precision: 0.998800, train loss: 10.599405, valid precision: 0.875800, valid loss: 95.213095
epoch: 2046, train precision: 0.998911, train loss: 10.616760, valid precision: 0.872600, valid loss: 95.277258
epoch: 2047, train precision: 0.997978, train loss: 10.847727, valid precision: 0.872600, valid loss: 96.613555
epoch: 2048, train precision: 0.998822, train loss: 10.589546, valid precision: 0.872400, valid loss: 94.852042
epoch: 2049, train precision: 0.999067, train loss: 10.552023, valid precision: 0.873200, valid loss: 94.330445
epoch: 2050, train precision: 0.999200, train loss: 10.478642, valid precision: 0.877400, valid loss: 92.570319
epoch: 2051, train precision: 0.999111, train loss: 10.553930, valid precision: 0.875400, valid loss: 93.463945
epoch: 2052, train precision: 0.998667, train loss: 10.701814, valid precision: 0.874600, valid loss: 94.537437
epoch: 2053, train precision: 0.999133, train loss: 10.537479, valid precision: 0.879000, valid loss: 94.758521
epoch: 2054, train precision: 0.999067, train loss: 10.535663, valid precision: 0.878600, valid loss: 91.737656
epoch: 2055, train precision: 0.999133, train loss: 10.544138, valid precision: 0.881200, valid loss: 88.861689
epoch: 2056, train precision: 0.998933, train loss: 10.567002, valid precision: 0.878400, valid loss: 93.224201
epoch: 2057, train precision: 0.999022, train loss: 10.515534, valid precision: 0.878200, valid loss: 94.257260
epoch: 2058, train precision: 0.998844, train loss: 10.510709, valid precision: 0.876800, valid loss: 92.692025
epoch: 2059, train precision: 0.998889, train loss: 10.561806, valid precision: 0.874400, valid loss: 92.794859
epoch: 2060, train precision: 0.998956, train loss: 10.587088, valid precision: 0.873000, valid loss: 95.095248
epoch: 2061, train precision: 0.999089, train loss: 10.556770, valid precision: 0.877800, valid loss: 91.969458
epoch: 2062, train precision: 0.998956, train loss: 10.531948, valid precision: 0.874800, valid loss: 93.687175
epoch: 2063, train precision: 0.999244, train loss: 10.493163, valid precision: 0.875200, valid loss: 92.636657
epoch: 2064, train precision: 0.998378, train loss: 10.715321, valid precision: 0.874600, valid loss: 94.298974
epoch: 2065, train precision: 0.998756, train loss: 10.637654, valid precision: 0.875400, valid loss: 93.600212
epoch: 2066, train precision: 0.998978, train loss: 10.561140, valid precision: 0.877800, valid loss: 90.258183
epoch: 2067, train precision: 0.999044, train loss: 10.507921, valid precision: 0.870800, valid loss: 91.958800
epoch: 2068, train precision: 0.998956, train loss: 10.567657, valid precision: 0.871000, valid loss: 93.583450
epoch: 2069, train precision: 0.999022, train loss: 10.579131, valid precision: 0.870800, valid loss: 92.050738
epoch: 2070, train precision: 0.998956, train loss: 10.529764, valid precision: 0.870200, valid loss: 92.332735
epoch: 2071, train precision: 0.999244, train loss: 10.483204, valid precision: 0.873600, valid loss: 91.837044
epoch: 2072, train precision: 0.999133, train loss: 10.535535, valid precision: 0.873800, valid loss: 91.668888
epoch: 2073, train precision: 0.998911, train loss: 10.562238, valid precision: 0.872000, valid loss: 93.379525
epoch: 2074, train precision: 0.998689, train loss: 10.635003, valid precision: 0.874800, valid loss: 93.465791
epoch: 2075, train precision: 0.998600, train loss: 10.640250, valid precision: 0.871200, valid loss: 94.225651
epoch: 2076, train precision: 0.998800, train loss: 10.605585, valid precision: 0.871200, valid loss: 93.826622
epoch: 2077, train precision: 0.999089, train loss: 10.505149, valid precision: 0.873000, valid loss: 91.526057
epoch: 2078, train precision: 0.998956, train loss: 10.602280, valid precision: 0.876200, valid loss: 93.384091
epoch: 2079, train precision: 0.998622, train loss: 10.676076, valid precision: 0.869200, valid loss: 95.621945
epoch: 2080, train precision: 0.998911, train loss: 10.564653, valid precision: 0.873800, valid loss: 94.666802
epoch: 2081, train precision: 0.999111, train loss: 10.479820, valid precision: 0.872800, valid loss: 95.264089
epoch: 2082, train precision: 0.999267, train loss: 10.529896, valid precision: 0.870600, valid loss: 95.349514
epoch: 2083, train precision: 0.998689, train loss: 10.619279, valid precision: 0.869200, valid loss: 99.745105
epoch: 2084, train precision: 0.999089, train loss: 10.510305, valid precision: 0.872400, valid loss: 96.500939
epoch: 2085, train precision: 0.999044, train loss: 10.523735, valid precision: 0.873000, valid loss: 96.180812
epoch: 2086, train precision: 0.999044, train loss: 10.534935, valid precision: 0.873200, valid loss: 93.804808
epoch: 2087, train precision: 0.998533, train loss: 10.641163, valid precision: 0.870000, valid loss: 96.821669
epoch: 2088, train precision: 0.999000, train loss: 10.567703, valid precision: 0.874600, valid loss: 94.559789
epoch: 2089, train precision: 0.999156, train loss: 10.488301, valid precision: 0.876000, valid loss: 93.159819
epoch: 2090, train precision: 0.998711, train loss: 10.652913, valid precision: 0.871400, valid loss: 95.441681
epoch: 2091, train precision: 0.998889, train loss: 10.531755, valid precision: 0.874000, valid loss: 94.500233
epoch: 2092, train precision: 0.998733, train loss: 10.574515, valid precision: 0.876000, valid loss: 91.758029
epoch: 2093, train precision: 0.998844, train loss: 10.608420, valid precision: 0.875400, valid loss: 94.888602
epoch: 2094, train precision: 0.999222, train loss: 10.463315, valid precision: 0.879200, valid loss: 92.557769
epoch: 2095, train precision: 0.998844, train loss: 10.551818, valid precision: 0.876800, valid loss: 93.466352
epoch: 2096, train precision: 0.999000, train loss: 10.531903, valid precision: 0.869000, valid loss: 94.995973
epoch: 2097, train precision: 0.998489, train loss: 10.796699, valid precision: 0.869600, valid loss: 96.687696
epoch: 2098, train precision: 0.998933, train loss: 10.519550, valid precision: 0.871800, valid loss: 94.419603
epoch: 2099, train precision: 0.998733, train loss: 10.691112, valid precision: 0.877400, valid loss: 92.081047
epoch: 2100, train precision: 0.998556, train loss: 10.656965, valid precision: 0.873200, valid loss: 95.711468
epoch: 2101, train precision: 0.998933, train loss: 10.543571, valid precision: 0.874000, valid loss: 94.079759
epoch: 2102, train precision: 0.998489, train loss: 10.725497, valid precision: 0.870400, valid loss: 93.929222
epoch: 2103, train precision: 0.998933, train loss: 10.620905, valid precision: 0.874000, valid loss: 92.031813
epoch: 2104, train precision: 0.998933, train loss: 10.534251, valid precision: 0.871200, valid loss: 95.613101
epoch: 2105, train precision: 0.999200, train loss: 10.469248, valid precision: 0.871800, valid loss: 95.926852
epoch: 2106, train precision: 0.998844, train loss: 10.565032, valid precision: 0.869800, valid loss: 97.331489
epoch: 2107, train precision: 0.998711, train loss: 10.606951, valid precision: 0.870400, valid loss: 97.270751
epoch: 2108, train precision: 0.999200, train loss: 10.515447, valid precision: 0.869400, valid loss: 95.782055
epoch: 2109, train precision: 0.998244, train loss: 10.727985, valid precision: 0.868200, valid loss: 99.438849
epoch: 2110, train precision: 0.998667, train loss: 10.611088, valid precision: 0.867600, valid loss: 98.344016
epoch: 2111, train precision: 0.998822, train loss: 10.584553, valid precision: 0.873200, valid loss: 97.898662
epoch: 2112, train precision: 0.998867, train loss: 10.567217, valid precision: 0.869400, valid loss: 96.719306
epoch: 2113, train precision: 0.998822, train loss: 10.623306, valid precision: 0.870400, valid loss: 96.321215
epoch: 2114, train precision: 0.998489, train loss: 10.629756, valid precision: 0.874800, valid loss: 95.634716
epoch: 2115, train precision: 0.999044, train loss: 10.570744, valid precision: 0.869200, valid loss: 97.103008
epoch: 2116, train precision: 0.999200, train loss: 10.478599, valid precision: 0.872000, valid loss: 93.207600
epoch: 2117, train precision: 0.999200, train loss: 10.485153, valid precision: 0.870000, valid loss: 93.747805
epoch: 2118, train precision: 0.999222, train loss: 10.520825, valid precision: 0.874400, valid loss: 94.179453
epoch: 2119, train precision: 0.998778, train loss: 10.615911, valid precision: 0.871400, valid loss: 96.725540
epoch: 2120, train precision: 0.998467, train loss: 10.674624, valid precision: 0.871000, valid loss: 95.593591
epoch: 2121, train precision: 0.999222, train loss: 10.479989, valid precision: 0.876000, valid loss: 94.726747
epoch: 2122, train precision: 0.998889, train loss: 10.579972, valid precision: 0.875400, valid loss: 96.227863
epoch: 2123, train precision: 0.998867, train loss: 10.576283, valid precision: 0.874800, valid loss: 92.601567
epoch: 2124, train precision: 0.998822, train loss: 10.587062, valid precision: 0.871600, valid loss: 95.730852
epoch: 2125, train precision: 0.998933, train loss: 10.562698, valid precision: 0.875000, valid loss: 94.184011
epoch: 2126, train precision: 0.998867, train loss: 10.597198, valid precision: 0.875600, valid loss: 93.573126
epoch: 2127, train precision: 0.999156, train loss: 10.514681, valid precision: 0.873000, valid loss: 94.968829
epoch: 2128, train precision: 0.998778, train loss: 10.626555, valid precision: 0.872800, valid loss: 94.533869
epoch: 2129, train precision: 0.999044, train loss: 10.491666, valid precision: 0.874800, valid loss: 93.867791
epoch: 2130, train precision: 0.999267, train loss: 10.543742, valid precision: 0.871400, valid loss: 93.405378
epoch: 2131, train precision: 0.998956, train loss: 10.578337, valid precision: 0.874800, valid loss: 93.062988
epoch: 2132, train precision: 0.998533, train loss: 10.687990, valid precision: 0.872400, valid loss: 95.284123
epoch: 2133, train precision: 0.999022, train loss: 10.531759, valid precision: 0.874400, valid loss: 94.297466
epoch: 2134, train precision: 0.998867, train loss: 10.571981, valid precision: 0.868400, valid loss: 97.352658
epoch: 2135, train precision: 0.999489, train loss: 10.373825, valid precision: 0.876800, valid loss: 95.177683
epoch: 2136, train precision: 0.999222, train loss: 10.458543, valid precision: 0.875800, valid loss: 93.449372
epoch: 2137, train precision: 0.999133, train loss: 10.523446, valid precision: 0.876400, valid loss: 93.607570
epoch: 2138, train precision: 0.998800, train loss: 10.543193, valid precision: 0.878800, valid loss: 92.351364
epoch: 2139, train precision: 0.998889, train loss: 10.541712, valid precision: 0.875000, valid loss: 94.153567
epoch: 2140, train precision: 0.999000, train loss: 10.507363, valid precision: 0.875200, valid loss: 94.655772
epoch: 2141, train precision: 0.999378, train loss: 10.401390, valid precision: 0.870200, valid loss: 94.937519
epoch: 2142, train precision: 0.998956, train loss: 10.547506, valid precision: 0.870200, valid loss: 96.580423
epoch: 2143, train precision: 0.998933, train loss: 10.589408, valid precision: 0.876000, valid loss: 94.206917
epoch: 2144, train precision: 0.998867, train loss: 10.562595, valid precision: 0.874200, valid loss: 92.030612
epoch: 2145, train precision: 0.999111, train loss: 10.539518, valid precision: 0.875200, valid loss: 92.873743
epoch: 2146, train precision: 0.998600, train loss: 10.734783, valid precision: 0.874000, valid loss: 93.827652
epoch: 2147, train precision: 0.998733, train loss: 10.638896, valid precision: 0.875200, valid loss: 91.484255
epoch: 2148, train precision: 0.999089, train loss: 10.531813, valid precision: 0.878400, valid loss: 91.967820
epoch: 2149, train precision: 0.999156, train loss: 10.454377, valid precision: 0.874200, valid loss: 94.059342
epoch: 2150, train precision: 0.998778, train loss: 10.607638, valid precision: 0.878600, valid loss: 92.949352
epoch: 2151, train precision: 0.998578, train loss: 10.622418, valid precision: 0.877600, valid loss: 95.765745
epoch: 2152, train precision: 0.999067, train loss: 10.495476, valid precision: 0.877000, valid loss: 93.316568
epoch: 2153, train precision: 0.999111, train loss: 10.541239, valid precision: 0.880800, valid loss: 92.163269
epoch: 2154, train precision: 0.999022, train loss: 10.521749, valid precision: 0.877800, valid loss: 90.708423
epoch: 2155, train precision: 0.999111, train loss: 10.521552, valid precision: 0.877600, valid loss: 91.398662
epoch: 2156, train precision: 0.999044, train loss: 10.523370, valid precision: 0.878200, valid loss: 90.722779
epoch: 2157, train precision: 0.999133, train loss: 10.507003, valid precision: 0.873200, valid loss: 93.646051
epoch: 2158, train precision: 0.998844, train loss: 10.611648, valid precision: 0.876600, valid loss: 91.955939
epoch: 2159, train precision: 0.998911, train loss: 10.557893, valid precision: 0.880000, valid loss: 93.502257
epoch: 2160, train precision: 0.999000, train loss: 10.484468, valid precision: 0.880800, valid loss: 93.046468
epoch: 2161, train precision: 0.999178, train loss: 10.461286, valid precision: 0.878400, valid loss: 91.638866
epoch: 2162, train precision: 0.999200, train loss: 10.441305, valid precision: 0.878800, valid loss: 93.254232
epoch: 2163, train precision: 0.998844, train loss: 10.538620, valid precision: 0.877400, valid loss: 94.496872
epoch: 2164, train precision: 0.998956, train loss: 10.525339, valid precision: 0.873000, valid loss: 95.136090
epoch: 2165, train precision: 0.998844, train loss: 10.577930, valid precision: 0.874000, valid loss: 96.426460
epoch: 2166, train precision: 0.999089, train loss: 10.447390, valid precision: 0.875200, valid loss: 94.991686
epoch: 2167, train precision: 0.999022, train loss: 10.499586, valid precision: 0.872600, valid loss: 97.399234
epoch: 2168, train precision: 0.998978, train loss: 10.524134, valid precision: 0.872400, valid loss: 97.370844
epoch: 2169, train precision: 0.998956, train loss: 10.519639, valid precision: 0.874200, valid loss: 93.938286
epoch: 2170, train precision: 0.998800, train loss: 10.590512, valid precision: 0.873200, valid loss: 95.673299
epoch: 2171, train precision: 0.998622, train loss: 10.612579, valid precision: 0.880000, valid loss: 93.460553
epoch: 2172, train precision: 0.998911, train loss: 10.508885, valid precision: 0.876200, valid loss: 94.099690
epoch: 2173, train precision: 0.998556, train loss: 10.684580, valid precision: 0.875600, valid loss: 94.836160
epoch: 2174, train precision: 0.999244, train loss: 10.483408, valid precision: 0.875200, valid loss: 92.964723
epoch: 2175, train precision: 0.998600, train loss: 10.606492, valid precision: 0.874600, valid loss: 92.293014
epoch: 2176, train precision: 0.999067, train loss: 10.557919, valid precision: 0.875400, valid loss: 92.237135
epoch: 2177, train precision: 0.999178, train loss: 10.481726, valid precision: 0.874000, valid loss: 92.783806
epoch: 2178, train precision: 0.999067, train loss: 10.521913, valid precision: 0.875800, valid loss: 90.790247
epoch: 2179, train precision: 0.999044, train loss: 10.542740, valid precision: 0.877400, valid loss: 91.498214
epoch: 2180, train precision: 0.998689, train loss: 10.540981, valid precision: 0.877400, valid loss: 93.765006
epoch: 2181, train precision: 0.998622, train loss: 10.618205, valid precision: 0.875400, valid loss: 94.874597
epoch: 2182, train precision: 0.998578, train loss: 10.626952, valid precision: 0.874800, valid loss: 94.630418
epoch: 2183, train precision: 0.998978, train loss: 10.537370, valid precision: 0.876800, valid loss: 95.444080
epoch: 2184, train precision: 0.998644, train loss: 10.597332, valid precision: 0.871800, valid loss: 96.094380
epoch: 2185, train precision: 0.998689, train loss: 10.579321, valid precision: 0.873400, valid loss: 95.385233
epoch: 2186, train precision: 0.998578, train loss: 10.583296, valid precision: 0.874600, valid loss: 95.474575
epoch: 2187, train precision: 0.999000, train loss: 10.466172, valid precision: 0.875200, valid loss: 92.899822
epoch: 2188, train precision: 0.999178, train loss: 10.485405, valid precision: 0.873600, valid loss: 94.661515
epoch: 2189, train precision: 0.999222, train loss: 10.495913, valid precision: 0.873800, valid loss: 94.184530
epoch: 2190, train precision: 0.998644, train loss: 10.631809, valid precision: 0.878000, valid loss: 94.743176
epoch: 2191, train precision: 0.999333, train loss: 10.378578, valid precision: 0.875800, valid loss: 95.466579
epoch: 2192, train precision: 0.999156, train loss: 10.435254, valid precision: 0.869600, valid loss: 95.311409
epoch: 2193, train precision: 0.998533, train loss: 10.594759, valid precision: 0.870600, valid loss: 97.768671
epoch: 2194, train precision: 0.999000, train loss: 10.530281, valid precision: 0.874000, valid loss: 97.064567
epoch: 2195, train precision: 0.999067, train loss: 10.504636, valid precision: 0.873200, valid loss: 95.588616
epoch: 2196, train precision: 0.998889, train loss: 10.570005, valid precision: 0.874200, valid loss: 95.430445
epoch: 2197, train precision: 0.999289, train loss: 10.432462, valid precision: 0.873000, valid loss: 96.833087
epoch: 2198, train precision: 0.998956, train loss: 10.488161, valid precision: 0.870000, valid loss: 96.883316
epoch: 2199, train precision: 0.999022, train loss: 10.476199, valid precision: 0.872600, valid loss: 96.512230
epoch: 2200, train precision: 0.999133, train loss: 10.441307, valid precision: 0.877000, valid loss: 95.514195
epoch: 2201, train precision: 0.999244, train loss: 10.383170, valid precision: 0.874000, valid loss: 94.775585
epoch: 2202, train precision: 0.999356, train loss: 10.432433, valid precision: 0.873800, valid loss: 93.255943
epoch: 2203, train precision: 0.999267, train loss: 10.412602, valid precision: 0.876400, valid loss: 94.397918
epoch: 2204, train precision: 0.998578, train loss: 10.598436, valid precision: 0.874600, valid loss: 94.385218
epoch: 2205, train precision: 0.999089, train loss: 10.476033, valid precision: 0.873400, valid loss: 93.019394
epoch: 2206, train precision: 0.998311, train loss: 10.670124, valid precision: 0.875800, valid loss: 93.133494
epoch: 2207, train precision: 0.999333, train loss: 10.409007, valid precision: 0.875800, valid loss: 92.838491
epoch: 2208, train precision: 0.999089, train loss: 10.502961, valid precision: 0.877000, valid loss: 95.785248
epoch: 2209, train precision: 0.998889, train loss: 10.541530, valid precision: 0.873000, valid loss: 93.363493
epoch: 2210, train precision: 0.998956, train loss: 10.564675, valid precision: 0.874800, valid loss: 93.712786
epoch: 2211, train precision: 0.998800, train loss: 10.545005, valid precision: 0.875800, valid loss: 91.230310
epoch: 2212, train precision: 0.998800, train loss: 10.595645, valid precision: 0.880000, valid loss: 90.601697
epoch: 2213, train precision: 0.998578, train loss: 10.668157, valid precision: 0.878600, valid loss: 91.779918
epoch: 2214, train precision: 0.998644, train loss: 10.659256, valid precision: 0.875200, valid loss: 93.506407
epoch: 2215, train precision: 0.999000, train loss: 10.492097, valid precision: 0.873000, valid loss: 95.041219
epoch: 2216, train precision: 0.999067, train loss: 10.460174, valid precision: 0.876400, valid loss: 94.391215
epoch: 2217, train precision: 0.998756, train loss: 10.538297, valid precision: 0.870200, valid loss: 94.635550
epoch: 2218, train precision: 0.998978, train loss: 10.526385, valid precision: 0.873200, valid loss: 92.907128
epoch: 2219, train precision: 0.998733, train loss: 10.566379, valid precision: 0.874200, valid loss: 92.666653
epoch: 2220, train precision: 0.999044, train loss: 10.484458, valid precision: 0.872400, valid loss: 93.397191
epoch: 2221, train precision: 0.998622, train loss: 10.588374, valid precision: 0.872200, valid loss: 96.326840
epoch: 2222, train precision: 0.999067, train loss: 10.521834, valid precision: 0.871800, valid loss: 95.735392
epoch: 2223, train precision: 0.999244, train loss: 10.426647, valid precision: 0.871400, valid loss: 94.353628
epoch: 2224, train precision: 0.998800, train loss: 10.576673, valid precision: 0.869200, valid loss: 96.443835
epoch: 2225, train precision: 0.999067, train loss: 10.470679, valid precision: 0.872200, valid loss: 94.442000
epoch: 2226, train precision: 0.999000, train loss: 10.498724, valid precision: 0.871600, valid loss: 96.626924
epoch: 2227, train precision: 0.998911, train loss: 10.525212, valid precision: 0.870000, valid loss: 95.885593
epoch: 2228, train precision: 0.999178, train loss: 10.436228, valid precision: 0.872000, valid loss: 95.185996
epoch: 2229, train precision: 0.998822, train loss: 10.573722, valid precision: 0.871000, valid loss: 95.831409
epoch: 2230, train precision: 0.999311, train loss: 10.419132, valid precision: 0.875800, valid loss: 94.413268
epoch: 2231, train precision: 0.998689, train loss: 10.595148, valid precision: 0.871800, valid loss: 94.446836
epoch: 2232, train precision: 0.998622, train loss: 10.630846, valid precision: 0.870400, valid loss: 100.394196
epoch: 2233, train precision: 0.999244, train loss: 10.440371, valid precision: 0.875400, valid loss: 96.043910
epoch: 2234, train precision: 0.998844, train loss: 10.587755, valid precision: 0.874200, valid loss: 95.834596
epoch: 2235, train precision: 0.999222, train loss: 10.369132, valid precision: 0.874200, valid loss: 95.812333
epoch: 2236, train precision: 0.999044, train loss: 10.480975, valid precision: 0.870200, valid loss: 96.666467
epoch: 2237, train precision: 0.998822, train loss: 10.566332, valid precision: 0.873400, valid loss: 96.007956
epoch: 2238, train precision: 0.998978, train loss: 10.512607, valid precision: 0.879800, valid loss: 93.944144
epoch: 2239, train precision: 0.998978, train loss: 10.521311, valid precision: 0.876000, valid loss: 94.964468
epoch: 2240, train precision: 0.998889, train loss: 10.557963, valid precision: 0.876600, valid loss: 93.593496
epoch: 2241, train precision: 0.998733, train loss: 10.605481, valid precision: 0.875400, valid loss: 92.122648
epoch: 2242, train precision: 0.999156, train loss: 10.432977, valid precision: 0.879800, valid loss: 90.855756
epoch: 2243, train precision: 0.998711, train loss: 10.616394, valid precision: 0.876600, valid loss: 92.992330
epoch: 2244, train precision: 0.999267, train loss: 10.419915, valid precision: 0.874800, valid loss: 93.339807
epoch: 2245, train precision: 0.998822, train loss: 10.591615, valid precision: 0.873400, valid loss: 95.330644
epoch: 2246, train precision: 0.999000, train loss: 10.520600, valid precision: 0.874400, valid loss: 94.146881
epoch: 2247, train precision: 0.998356, train loss: 10.689470, valid precision: 0.875800, valid loss: 95.412248
epoch: 2248, train precision: 0.998711, train loss: 10.528617, valid precision: 0.876600, valid loss: 96.505183
epoch: 2249, train precision: 0.998956, train loss: 10.516920, valid precision: 0.874800, valid loss: 97.393961
epoch: 2250, train precision: 0.999067, train loss: 10.468032, valid precision: 0.874600, valid loss: 97.497453
epoch: 2251, train precision: 0.998956, train loss: 10.480942, valid precision: 0.875600, valid loss: 96.045746
epoch: 2252, train precision: 0.998978, train loss: 10.514641, valid precision: 0.876600, valid loss: 94.789431
epoch: 2253, train precision: 0.998578, train loss: 10.561347, valid precision: 0.875000, valid loss: 95.161955
epoch: 2254, train precision: 0.999022, train loss: 10.469666, valid precision: 0.874800, valid loss: 94.671664
epoch: 2255, train precision: 0.999244, train loss: 10.523889, valid precision: 0.871200, valid loss: 91.940984
epoch: 2256, train precision: 0.998578, train loss: 10.626941, valid precision: 0.872800, valid loss: 96.577292
epoch: 2257, train precision: 0.999022, train loss: 10.508903, valid precision: 0.875200, valid loss: 94.109561
epoch: 2258, train precision: 0.999333, train loss: 10.438323, valid precision: 0.872600, valid loss: 95.423486
epoch: 2259, train precision: 0.999089, train loss: 10.466066, valid precision: 0.872000, valid loss: 94.648465
epoch: 2260, train precision: 0.998956, train loss: 10.543241, valid precision: 0.877200, valid loss: 93.858732
epoch: 2261, train precision: 0.998822, train loss: 10.518881, valid precision: 0.877000, valid loss: 94.214561
epoch: 2262, train precision: 0.998978, train loss: 10.526327, valid precision: 0.876800, valid loss: 92.909709
epoch: 2263, train precision: 0.998733, train loss: 10.602141, valid precision: 0.872200, valid loss: 94.788027
epoch: 2264, train precision: 0.999089, train loss: 10.490812, valid precision: 0.877200, valid loss: 93.219969
epoch: 2265, train precision: 0.999000, train loss: 10.500055, valid precision: 0.879400, valid loss: 92.806302
epoch: 2266, train precision: 0.999022, train loss: 10.501728, valid precision: 0.875600, valid loss: 93.204722
epoch: 2267, train precision: 0.999156, train loss: 10.421712, valid precision: 0.879400, valid loss: 93.272957
epoch: 2268, train precision: 0.998533, train loss: 10.598591, valid precision: 0.878600, valid loss: 93.773676
epoch: 2269, train precision: 0.999000, train loss: 10.500457, valid precision: 0.877800, valid loss: 92.626190
epoch: 2270, train precision: 0.998956, train loss: 10.508708, valid precision: 0.880000, valid loss: 93.650437
epoch: 2271, train precision: 0.999133, train loss: 10.495524, valid precision: 0.875000, valid loss: 94.123381
epoch: 2272, train precision: 0.998800, train loss: 10.535462, valid precision: 0.876200, valid loss: 93.444302
epoch: 2273, train precision: 0.998889, train loss: 10.511435, valid precision: 0.881400, valid loss: 93.921012
epoch: 2274, train precision: 0.998911, train loss: 10.573470, valid precision: 0.876000, valid loss: 92.314202
epoch: 2275, train precision: 0.998867, train loss: 10.552287, valid precision: 0.874200, valid loss: 93.710222
epoch: 2276, train precision: 0.999067, train loss: 10.436380, valid precision: 0.878400, valid loss: 93.325148
epoch: 2277, train precision: 0.999111, train loss: 10.508400, valid precision: 0.875800, valid loss: 93.997740
epoch: 2278, train precision: 0.999044, train loss: 10.457162, valid precision: 0.877400, valid loss: 93.417815
epoch: 2279, train precision: 0.998400, train loss: 10.677241, valid precision: 0.872600, valid loss: 95.610801
epoch: 2280, train precision: 0.998378, train loss: 10.675353, valid precision: 0.875200, valid loss: 93.930172
epoch: 2281, train precision: 0.999178, train loss: 10.485280, valid precision: 0.876400, valid loss: 93.819958
epoch: 2282, train precision: 0.999111, train loss: 10.469207, valid precision: 0.873800, valid loss: 92.862594
epoch: 2283, train precision: 0.999267, train loss: 10.404894, valid precision: 0.873200, valid loss: 92.190208
epoch: 2284, train precision: 0.999333, train loss: 10.409698, valid precision: 0.873600, valid loss: 94.621582
epoch: 2285, train precision: 0.999156, train loss: 10.451042, valid precision: 0.872200, valid loss: 96.801706
epoch: 2286, train precision: 0.999089, train loss: 10.439996, valid precision: 0.876400, valid loss: 93.709273
epoch: 2287, train precision: 0.998756, train loss: 10.580760, valid precision: 0.874400, valid loss: 94.524260
epoch: 2288, train precision: 0.999111, train loss: 10.443763, valid precision: 0.876200, valid loss: 95.991971
epoch: 2289, train precision: 0.999000, train loss: 10.468338, valid precision: 0.878800, valid loss: 95.914642
epoch: 2290, train precision: 0.999311, train loss: 10.418875, valid precision: 0.875200, valid loss: 93.997093
epoch: 2291, train precision: 0.998956, train loss: 10.459205, valid precision: 0.873200, valid loss: 95.293402
epoch: 2292, train precision: 0.999022, train loss: 10.437567, valid precision: 0.873400, valid loss: 96.592586
epoch: 2293, train precision: 0.999067, train loss: 10.426645, valid precision: 0.871200, valid loss: 95.199403
epoch: 2294, train precision: 0.998822, train loss: 10.536402, valid precision: 0.870000, valid loss: 98.009945
epoch: 2295, train precision: 0.998689, train loss: 10.565007, valid precision: 0.877400, valid loss: 95.470352
epoch: 2296, train precision: 0.998711, train loss: 10.599510, valid precision: 0.877000, valid loss: 94.138024
epoch: 2297, train precision: 0.998511, train loss: 10.680074, valid precision: 0.875000, valid loss: 93.349097
epoch: 2298, train precision: 0.998933, train loss: 10.496604, valid precision: 0.875400, valid loss: 93.799406
epoch: 2299, train precision: 0.999022, train loss: 10.509032, valid precision: 0.870400, valid loss: 95.267713
epoch: 2300, train precision: 0.999111, train loss: 10.433171, valid precision: 0.874400, valid loss: 93.788331
epoch: 2301, train precision: 0.998911, train loss: 10.463675, valid precision: 0.875400, valid loss: 93.490467
epoch: 2302, train precision: 0.999044, train loss: 10.487121, valid precision: 0.868800, valid loss: 94.894786
epoch: 2303, train precision: 0.999044, train loss: 10.489630, valid precision: 0.876600, valid loss: 90.495583
epoch: 2304, train precision: 0.999111, train loss: 10.512192, valid precision: 0.873000, valid loss: 95.560523
epoch: 2305, train precision: 0.999289, train loss: 10.451821, valid precision: 0.872000, valid loss: 93.731408
epoch: 2306, train precision: 0.999133, train loss: 10.395380, valid precision: 0.871600, valid loss: 97.624716
epoch: 2307, train precision: 0.998867, train loss: 10.562100, valid precision: 0.874200, valid loss: 95.393319
epoch: 2308, train precision: 0.999156, train loss: 10.395576, valid precision: 0.876400, valid loss: 94.954337
epoch: 2309, train precision: 0.998800, train loss: 10.553514, valid precision: 0.876800, valid loss: 93.826763
epoch: 2310, train precision: 0.999000, train loss: 10.428481, valid precision: 0.876600, valid loss: 94.217814
epoch: 2311, train precision: 0.999022, train loss: 10.471004, valid precision: 0.870800, valid loss: 96.723600
epoch: 2312, train precision: 0.998733, train loss: 10.541364, valid precision: 0.875400, valid loss: 92.858256
epoch: 2313, train precision: 0.999178, train loss: 10.402965, valid precision: 0.871600, valid loss: 95.161307
epoch: 2314, train precision: 0.999044, train loss: 10.458211, valid precision: 0.873600, valid loss: 95.006287
epoch: 2315, train precision: 0.998556, train loss: 10.599232, valid precision: 0.870200, valid loss: 95.681129
epoch: 2316, train precision: 0.999000, train loss: 10.516071, valid precision: 0.879200, valid loss: 93.059015
epoch: 2317, train precision: 0.998800, train loss: 10.471375, valid precision: 0.878200, valid loss: 92.398729
epoch: 2318, train precision: 0.999044, train loss: 10.448499, valid precision: 0.876800, valid loss: 91.680003
epoch: 2319, train precision: 0.998978, train loss: 10.500609, valid precision: 0.875000, valid loss: 93.184463
epoch: 2320, train precision: 0.998622, train loss: 10.535674, valid precision: 0.877600, valid loss: 94.974669
epoch: 2321, train precision: 0.998978, train loss: 10.481937, valid precision: 0.874200, valid loss: 95.958730
epoch: 2322, train precision: 0.998978, train loss: 10.535422, valid precision: 0.873400, valid loss: 93.294363
epoch: 2323, train precision: 0.998667, train loss: 10.552584, valid precision: 0.876400, valid loss: 95.897167
epoch: 2324, train precision: 0.999133, train loss: 10.445523, valid precision: 0.872400, valid loss: 94.695432
epoch: 2325, train precision: 0.998578, train loss: 10.590525, valid precision: 0.875000, valid loss: 93.170557
epoch: 2326, train precision: 0.998822, train loss: 10.580615, valid precision: 0.877000, valid loss: 93.411197
epoch: 2327, train precision: 0.999200, train loss: 10.460600, valid precision: 0.875400, valid loss: 93.028767
epoch: 2328, train precision: 0.999067, train loss: 10.461949, valid precision: 0.876800, valid loss: 95.340566
epoch: 2329, train precision: 0.999333, train loss: 10.325387, valid precision: 0.873800, valid loss: 96.379364
epoch: 2330, train precision: 0.999089, train loss: 10.503373, valid precision: 0.874200, valid loss: 92.950126
epoch: 2331, train precision: 0.999022, train loss: 10.471207, valid precision: 0.873200, valid loss: 93.544889
epoch: 2332, train precision: 0.998844, train loss: 10.550719, valid precision: 0.876400, valid loss: 92.723700
epoch: 2333, train precision: 0.999267, train loss: 10.426589, valid precision: 0.873800, valid loss: 91.931025
epoch: 2334, train precision: 0.998978, train loss: 10.458433, valid precision: 0.875000, valid loss: 89.779846
epoch: 2335, train precision: 0.999178, train loss: 10.408824, valid precision: 0.876200, valid loss: 91.893625
epoch: 2336, train precision: 0.998800, train loss: 10.493680, valid precision: 0.873600, valid loss: 91.749008
epoch: 2337, train precision: 0.998978, train loss: 10.445618, valid precision: 0.876400, valid loss: 91.364971
epoch: 2338, train precision: 0.998911, train loss: 10.495631, valid precision: 0.876400, valid loss: 91.823973
epoch: 2339, train precision: 0.998800, train loss: 10.572828, valid precision: 0.871200, valid loss: 93.772109
epoch: 2340, train precision: 0.998867, train loss: 10.561632, valid precision: 0.876000, valid loss: 91.816963
epoch: 2341, train precision: 0.998489, train loss: 10.690595, valid precision: 0.872400, valid loss: 91.825678
epoch: 2342, train precision: 0.999244, train loss: 10.414181, valid precision: 0.874800, valid loss: 90.022421
epoch: 2343, train precision: 0.999044, train loss: 10.511987, valid precision: 0.878600, valid loss: 92.406435
epoch: 2344, train precision: 0.998756, train loss: 10.553880, valid precision: 0.876200, valid loss: 93.453905
epoch: 2345, train precision: 0.999022, train loss: 10.477470, valid precision: 0.878200, valid loss: 90.400568
epoch: 2346, train precision: 0.999311, train loss: 10.420340, valid precision: 0.876000, valid loss: 93.025778
epoch: 2347, train precision: 0.998844, train loss: 10.582532, valid precision: 0.873400, valid loss: 93.524163
epoch: 2348, train precision: 0.998667, train loss: 10.571027, valid precision: 0.875000, valid loss: 91.999067
epoch: 2349, train precision: 0.998800, train loss: 10.529843, valid precision: 0.873800, valid loss: 94.492780
epoch: 2350, train precision: 0.999089, train loss: 10.467320, valid precision: 0.877200, valid loss: 90.966187
epoch: 2351, train precision: 0.998733, train loss: 10.575318, valid precision: 0.877400, valid loss: 92.836649
epoch: 2352, train precision: 0.998844, train loss: 10.486726, valid precision: 0.878400, valid loss: 89.775751
epoch: 2353, train precision: 0.999178, train loss: 10.427806, valid precision: 0.877800, valid loss: 91.207523
epoch: 2354, train precision: 0.998600, train loss: 10.575986, valid precision: 0.875600, valid loss: 91.787281
epoch: 2355, train precision: 0.998978, train loss: 10.486421, valid precision: 0.873800, valid loss: 90.544739
epoch: 2356, train precision: 0.999000, train loss: 10.452602, valid precision: 0.872200, valid loss: 91.945546
epoch: 2357, train precision: 0.999022, train loss: 10.479154, valid precision: 0.875800, valid loss: 93.210776
epoch: 2358, train precision: 0.999067, train loss: 10.451168, valid precision: 0.871800, valid loss: 92.098792
epoch: 2359, train precision: 0.998644, train loss: 10.522618, valid precision: 0.870000, valid loss: 89.171959
epoch: 2360, train precision: 0.998956, train loss: 10.537617, valid precision: 0.869200, valid loss: 92.697409
epoch: 2361, train precision: 0.999289, train loss: 10.450614, valid precision: 0.871800, valid loss: 91.505691
epoch: 2362, train precision: 0.999000, train loss: 10.438114, valid precision: 0.878200, valid loss: 90.414017
epoch: 2363, train precision: 0.998489, train loss: 10.610052, valid precision: 0.878600, valid loss: 91.515670
epoch: 2364, train precision: 0.999022, train loss: 10.426206, valid precision: 0.874400, valid loss: 92.594757
epoch: 2365, train precision: 0.999333, train loss: 10.396321, valid precision: 0.878800, valid loss: 90.399386
epoch: 2366, train precision: 0.998867, train loss: 10.518051, valid precision: 0.876800, valid loss: 91.804980
epoch: 2367, train precision: 0.998289, train loss: 10.707440, valid precision: 0.877800, valid loss: 91.174867
epoch: 2368, train precision: 0.998711, train loss: 10.566406, valid precision: 0.873800, valid loss: 91.670855
epoch: 2369, train precision: 0.999178, train loss: 10.420781, valid precision: 0.876000, valid loss: 89.604767
epoch: 2370, train precision: 0.998556, train loss: 10.610734, valid precision: 0.874000, valid loss: 95.090360
epoch: 2371, train precision: 0.999111, train loss: 10.513782, valid precision: 0.875400, valid loss: 95.114241
epoch: 2372, train precision: 0.998733, train loss: 10.533717, valid precision: 0.876000, valid loss: 91.567604
epoch: 2373, train precision: 0.998978, train loss: 10.476222, valid precision: 0.876800, valid loss: 91.381221
epoch: 2374, train precision: 0.998978, train loss: 10.561152, valid precision: 0.882000, valid loss: 91.710915
epoch: 2375, train precision: 0.999200, train loss: 10.432156, valid precision: 0.876200, valid loss: 94.480804
epoch: 2376, train precision: 0.998667, train loss: 10.567694, valid precision: 0.877200, valid loss: 94.658508
epoch: 2377, train precision: 0.998800, train loss: 10.512381, valid precision: 0.874800, valid loss: 94.341516
epoch: 2378, train precision: 0.999067, train loss: 10.466715, valid precision: 0.878400, valid loss: 93.441360
epoch: 2379, train precision: 0.999044, train loss: 10.473269, valid precision: 0.878000, valid loss: 92.350904
epoch: 2380, train precision: 0.999022, train loss: 10.455888, valid precision: 0.878200, valid loss: 91.482786
epoch: 2381, train precision: 0.999022, train loss: 10.411277, valid precision: 0.878600, valid loss: 89.495630
epoch: 2382, train precision: 0.998889, train loss: 10.517226, valid precision: 0.875800, valid loss: 91.624189
epoch: 2383, train precision: 0.999044, train loss: 10.435874, valid precision: 0.878600, valid loss: 88.490820
epoch: 2384, train precision: 0.998800, train loss: 10.579494, valid precision: 0.876600, valid loss: 92.604003
epoch: 2385, train precision: 0.999000, train loss: 10.455336, valid precision: 0.876200, valid loss: 91.950738
epoch: 2386, train precision: 0.998733, train loss: 10.535918, valid precision: 0.876000, valid loss: 92.300620
epoch: 2387, train precision: 0.999267, train loss: 10.354229, valid precision: 0.880200, valid loss: 90.410745
epoch: 2388, train precision: 0.998778, train loss: 10.518630, valid precision: 0.875800, valid loss: 92.387066
epoch: 2389, train precision: 0.999156, train loss: 10.470150, valid precision: 0.876800, valid loss: 91.721996
epoch: 2390, train precision: 0.998889, train loss: 10.485473, valid precision: 0.880000, valid loss: 91.635801
epoch: 2391, train precision: 0.998867, train loss: 10.539326, valid precision: 0.877000, valid loss: 91.350026
epoch: 2392, train precision: 0.998800, train loss: 10.516258, valid precision: 0.879800, valid loss: 88.482723
epoch: 2393, train precision: 0.999067, train loss: 10.464909, valid precision: 0.877600, valid loss: 89.296110
epoch: 2394, train precision: 0.999067, train loss: 10.412217, valid precision: 0.877800, valid loss: 89.900839
epoch: 2395, train precision: 0.999222, train loss: 10.401030, valid precision: 0.875800, valid loss: 91.764187
epoch: 2396, train precision: 0.998933, train loss: 10.488016, valid precision: 0.877200, valid loss: 91.473165
epoch: 2397, train precision: 0.998933, train loss: 10.495127, valid precision: 0.876200, valid loss: 93.595803
epoch: 2398, train precision: 0.999133, train loss: 10.412826, valid precision: 0.878200, valid loss: 91.405748
epoch: 2399, train precision: 0.999022, train loss: 10.437250, valid precision: 0.878800, valid loss: 93.102669
epoch: 2400, train precision: 0.998844, train loss: 10.531954, valid precision: 0.874200, valid loss: 94.652986
epoch: 2401, train precision: 0.999067, train loss: 10.470441, valid precision: 0.877800, valid loss: 92.562166
epoch: 2402, train precision: 0.998867, train loss: 10.517112, valid precision: 0.874800, valid loss: 92.494849
epoch: 2403, train precision: 0.999222, train loss: 10.426100, valid precision: 0.879400, valid loss: 93.852073
epoch: 2404, train precision: 0.999000, train loss: 10.531080, valid precision: 0.873400, valid loss: 91.807283
epoch: 2405, train precision: 0.998978, train loss: 10.504472, valid precision: 0.874800, valid loss: 91.728513
epoch: 2406, train precision: 0.998844, train loss: 10.581949, valid precision: 0.873600, valid loss: 93.686378
epoch: 2407, train precision: 0.999044, train loss: 10.397953, valid precision: 0.878600, valid loss: 92.977208
epoch: 2408, train precision: 0.998511, train loss: 10.650486, valid precision: 0.874000, valid loss: 94.367346
epoch: 2409, train precision: 0.998911, train loss: 10.476512, valid precision: 0.877200, valid loss: 92.329432
epoch: 2410, train precision: 0.999111, train loss: 10.416344, valid precision: 0.881200, valid loss: 90.689508
epoch: 2411, train precision: 0.999089, train loss: 10.405036, valid precision: 0.880200, valid loss: 93.366174
epoch: 2412, train precision: 0.998467, train loss: 10.556495, valid precision: 0.876200, valid loss: 91.696570
epoch: 2413, train precision: 0.999311, train loss: 10.429357, valid precision: 0.876600, valid loss: 91.769435
epoch: 2414, train precision: 0.999356, train loss: 10.383525, valid precision: 0.874800, valid loss: 94.069704
epoch: 2415, train precision: 0.998489, train loss: 10.643431, valid precision: 0.878000, valid loss: 94.980277
epoch: 2416, train precision: 0.999156, train loss: 10.395169, valid precision: 0.880200, valid loss: 91.676808
epoch: 2417, train precision: 0.998778, train loss: 10.525512, valid precision: 0.875600, valid loss: 97.170501
epoch: 2418, train precision: 0.998956, train loss: 10.455135, valid precision: 0.876200, valid loss: 94.465969
epoch: 2419, train precision: 0.998822, train loss: 10.470158, valid precision: 0.875200, valid loss: 96.924413
epoch: 2420, train precision: 0.999022, train loss: 10.446087, valid precision: 0.873800, valid loss: 92.656104
epoch: 2421, train precision: 0.999222, train loss: 10.396170, valid precision: 0.876400, valid loss: 95.329571
epoch: 2422, train precision: 0.998533, train loss: 10.625098, valid precision: 0.876200, valid loss: 95.559632
epoch: 2423, train precision: 0.998889, train loss: 10.512038, valid precision: 0.875800, valid loss: 92.149462
epoch: 2424, train precision: 0.999089, train loss: 10.408742, valid precision: 0.879600, valid loss: 93.519692
epoch: 2425, train precision: 0.998689, train loss: 10.558383, valid precision: 0.870400, valid loss: 92.311842
epoch: 2426, train precision: 0.998800, train loss: 10.527421, valid precision: 0.877600, valid loss: 92.212293
epoch: 2427, train precision: 0.999311, train loss: 10.430318, valid precision: 0.874000, valid loss: 93.726660
epoch: 2428, train precision: 0.999289, train loss: 10.406633, valid precision: 0.875800, valid loss: 95.513727
epoch: 2429, train precision: 0.999178, train loss: 10.453807, valid precision: 0.879000, valid loss: 91.882214
epoch: 2430, train precision: 0.999000, train loss: 10.529125, valid precision: 0.875800, valid loss: 93.026790
epoch: 2431, train precision: 0.998467, train loss: 10.551554, valid precision: 0.877600, valid loss: 93.612496
epoch: 2432, train precision: 0.998978, train loss: 10.477812, valid precision: 0.880800, valid loss: 90.700166
epoch: 2433, train precision: 0.998800, train loss: 10.460186, valid precision: 0.875800, valid loss: 92.316921
epoch: 2434, train precision: 0.999133, train loss: 10.441774, valid precision: 0.878600, valid loss: 91.239973
epoch: 2435, train precision: 0.998978, train loss: 10.484962, valid precision: 0.878000, valid loss: 92.633709
epoch: 2436, train precision: 0.998844, train loss: 10.497426, valid precision: 0.878000, valid loss: 92.451328
epoch: 2437, train precision: 0.998956, train loss: 10.491954, valid precision: 0.880000, valid loss: 92.403545
epoch: 2438, train precision: 0.999022, train loss: 10.474929, valid precision: 0.874400, valid loss: 94.226242
epoch: 2439, train precision: 0.999022, train loss: 10.451903, valid precision: 0.873000, valid loss: 95.780731
epoch: 2440, train precision: 0.999044, train loss: 10.414101, valid precision: 0.873000, valid loss: 93.160168
epoch: 2441, train precision: 0.998844, train loss: 10.537943, valid precision: 0.873600, valid loss: 92.981221
epoch: 2442, train precision: 0.998889, train loss: 10.458866, valid precision: 0.877200, valid loss: 93.294254
epoch: 2443, train precision: 0.999133, train loss: 10.404273, valid precision: 0.876600, valid loss: 95.946936
epoch: 2444, train precision: 0.998889, train loss: 10.467632, valid precision: 0.874600, valid loss: 95.653926
epoch: 2445, train precision: 0.999044, train loss: 10.423014, valid precision: 0.873600, valid loss: 94.858373
epoch: 2446, train precision: 0.998800, train loss: 10.555754, valid precision: 0.874600, valid loss: 95.832409
epoch: 2447, train precision: 0.999289, train loss: 10.392859, valid precision: 0.876200, valid loss: 95.355621
epoch: 2448, train precision: 0.998844, train loss: 10.491095, valid precision: 0.874200, valid loss: 96.745318
epoch: 2449, train precision: 0.998800, train loss: 10.506379, valid precision: 0.877400, valid loss: 94.200692
epoch: 2450, train precision: 0.999089, train loss: 10.396287, valid precision: 0.874600, valid loss: 96.921293
epoch: 2451, train precision: 0.998956, train loss: 10.454142, valid precision: 0.870200, valid loss: 95.214134
epoch: 2452, train precision: 0.998822, train loss: 10.524419, valid precision: 0.872800, valid loss: 95.457436
epoch: 2453, train precision: 0.998844, train loss: 10.513756, valid precision: 0.868000, valid loss: 95.825971
epoch: 2454, train precision: 0.998844, train loss: 10.502234, valid precision: 0.875200, valid loss: 93.290802
epoch: 2455, train precision: 0.998800, train loss: 10.581742, valid precision: 0.877000, valid loss: 92.276536
epoch: 2456, train precision: 0.998711, train loss: 10.549490, valid precision: 0.875000, valid loss: 93.755060
epoch: 2457, train precision: 0.998733, train loss: 10.487890, valid precision: 0.874200, valid loss: 96.062136
epoch: 2458, train precision: 0.999089, train loss: 10.439648, valid precision: 0.870800, valid loss: 97.681309
epoch: 2459, train precision: 0.998956, train loss: 10.443917, valid precision: 0.871400, valid loss: 96.416325
epoch: 2460, train precision: 0.998822, train loss: 10.488207, valid precision: 0.870000, valid loss: 94.755909
epoch: 2461, train precision: 0.998778, train loss: 10.552274, valid precision: 0.874200, valid loss: 95.875630
epoch: 2462, train precision: 0.999422, train loss: 10.342588, valid precision: 0.876400, valid loss: 96.323232
epoch: 2463, train precision: 0.998778, train loss: 10.569483, valid precision: 0.871800, valid loss: 97.603844
epoch: 2464, train precision: 0.999111, train loss: 10.405899, valid precision: 0.874000, valid loss: 95.637597
epoch: 2465, train precision: 0.998978, train loss: 10.487088, valid precision: 0.872000, valid loss: 95.938212
epoch: 2466, train precision: 0.998778, train loss: 10.521018, valid precision: 0.873200, valid loss: 93.432581
epoch: 2467, train precision: 0.998889, train loss: 10.480555, valid precision: 0.872600, valid loss: 96.585373
epoch: 2468, train precision: 0.999111, train loss: 10.441481, valid precision: 0.876000, valid loss: 96.151936
epoch: 2469, train precision: 0.999178, train loss: 10.419047, valid precision: 0.874800, valid loss: 96.202143
epoch: 2470, train precision: 0.998956, train loss: 10.470669, valid precision: 0.878800, valid loss: 96.655063
epoch: 2471, train precision: 0.998733, train loss: 10.527969, valid precision: 0.876600, valid loss: 96.703111
epoch: 2472, train precision: 0.999422, train loss: 10.346660, valid precision: 0.880200, valid loss: 92.820922
epoch: 2473, train precision: 0.998844, train loss: 10.469148, valid precision: 0.875000, valid loss: 94.932375
epoch: 2474, train precision: 0.999000, train loss: 10.517245, valid precision: 0.877600, valid loss: 95.996668
epoch: 2475, train precision: 0.999133, train loss: 10.398988, valid precision: 0.875400, valid loss: 94.225103
epoch: 2476, train precision: 0.999000, train loss: 10.448248, valid precision: 0.873800, valid loss: 95.299672
epoch: 2477, train precision: 0.999244, train loss: 10.402887, valid precision: 0.876400, valid loss: 95.600556
epoch: 2478, train precision: 0.998533, train loss: 10.531242, valid precision: 0.874200, valid loss: 95.990977
epoch: 2479, train precision: 0.999489, train loss: 10.330383, valid precision: 0.873800, valid loss: 94.652774
epoch: 2480, train precision: 0.999133, train loss: 10.435419, valid precision: 0.875200, valid loss: 97.717696
epoch: 2481, train precision: 0.998978, train loss: 10.462356, valid precision: 0.870800, valid loss: 97.008396
epoch: 2482, train precision: 0.999244, train loss: 10.399597, valid precision: 0.874600, valid loss: 99.952492
epoch: 2483, train precision: 0.998911, train loss: 10.495972, valid precision: 0.875600, valid loss: 97.924190
epoch: 2484, train precision: 0.999067, train loss: 10.421494, valid precision: 0.877800, valid loss: 95.863752
epoch: 2485, train precision: 0.999311, train loss: 10.371277, valid precision: 0.874800, valid loss: 95.183274
epoch: 2486, train precision: 0.998733, train loss: 10.579142, valid precision: 0.873600, valid loss: 98.085622
epoch: 2487, train precision: 0.998933, train loss: 10.432144, valid precision: 0.872600, valid loss: 95.448178
epoch: 2488, train precision: 0.999289, train loss: 10.380966, valid precision: 0.873400, valid loss: 97.265479
epoch: 2489, train precision: 0.999022, train loss: 10.371378, valid precision: 0.874600, valid loss: 98.040599
epoch: 2490, train precision: 0.999022, train loss: 10.445973, valid precision: 0.874200, valid loss: 99.367436
epoch: 2491, train precision: 0.998978, train loss: 10.463853, valid precision: 0.874800, valid loss: 96.360479
epoch: 2492, train precision: 0.998778, train loss: 10.582683, valid precision: 0.874000, valid loss: 98.480215
epoch: 2493, train precision: 0.998800, train loss: 10.462548, valid precision: 0.871200, valid loss: 98.348189
epoch: 2494, train precision: 0.998867, train loss: 10.517063, valid precision: 0.870600, valid loss: 94.904921
epoch: 2495, train precision: 0.999044, train loss: 10.386931, valid precision: 0.876000, valid loss: 97.015897
epoch: 2496, train precision: 0.998711, train loss: 10.540841, valid precision: 0.872600, valid loss: 96.508039
epoch: 2497, train precision: 0.999200, train loss: 10.391880, valid precision: 0.875400, valid loss: 95.181214
epoch: 2498, train precision: 0.999133, train loss: 10.406762, valid precision: 0.871000, valid loss: 97.598742
epoch: 2499, train precision: 0.999044, train loss: 10.444907, valid precision: 0.872000, valid loss: 96.127493
epoch: 2500, train precision: 0.999022, train loss: 10.444819, valid precision: 0.871600, valid loss: 94.445922
epoch: 2501, train precision: 0.999000, train loss: 10.463989, valid precision: 0.873400, valid loss: 96.208518
epoch: 2502, train precision: 0.999200, train loss: 10.399222, valid precision: 0.877000, valid loss: 95.746707
epoch: 2503, train precision: 0.999222, train loss: 10.379614, valid precision: 0.873400, valid loss: 96.589726
epoch: 2504, train precision: 0.999222, train loss: 10.396312, valid precision: 0.871400, valid loss: 94.787509
epoch: 2505, train precision: 0.999111, train loss: 10.389522, valid precision: 0.874800, valid loss: 95.294964
epoch: 2506, train precision: 0.998489, train loss: 10.568733, valid precision: 0.878000, valid loss: 94.944189
epoch: 2507, train precision: 0.999133, train loss: 10.410030, valid precision: 0.880400, valid loss: 90.888449
epoch: 2508, train precision: 0.999156, train loss: 10.408563, valid precision: 0.874600, valid loss: 93.577918
epoch: 2509, train precision: 0.999067, train loss: 10.517244, valid precision: 0.874200, valid loss: 96.177196
epoch: 2510, train precision: 0.999133, train loss: 10.431321, valid precision: 0.870400, valid loss: 95.810939
epoch: 2511, train precision: 0.998600, train loss: 10.532448, valid precision: 0.872000, valid loss: 96.671291
epoch: 2512, train precision: 0.999133, train loss: 10.373214, valid precision: 0.871800, valid loss: 94.973970
epoch: 2513, train precision: 0.998822, train loss: 10.506556, valid precision: 0.872000, valid loss: 95.128527
epoch: 2514, train precision: 0.998733, train loss: 10.505544, valid precision: 0.878400, valid loss: 94.044243
epoch: 2515, train precision: 0.998911, train loss: 10.513584, valid precision: 0.875600, valid loss: 94.787959
epoch: 2516, train precision: 0.998756, train loss: 10.492093, valid precision: 0.876600, valid loss: 95.095313
epoch: 2517, train precision: 0.998889, train loss: 10.425877, valid precision: 0.876400, valid loss: 94.975513
epoch: 2518, train precision: 0.999222, train loss: 10.411067, valid precision: 0.873400, valid loss: 95.066538
epoch: 2519, train precision: 0.998867, train loss: 10.506538, valid precision: 0.872600, valid loss: 96.206254
epoch: 2520, train precision: 0.999111, train loss: 10.377737, valid precision: 0.877000, valid loss: 94.934276
epoch: 2521, train precision: 0.998756, train loss: 10.499100, valid precision: 0.872200, valid loss: 97.742601
epoch: 2522, train precision: 0.998267, train loss: 10.638012, valid precision: 0.872600, valid loss: 96.003765
epoch: 2523, train precision: 0.998867, train loss: 10.431412, valid precision: 0.876600, valid loss: 97.649465
epoch: 2524, train precision: 0.999111, train loss: 10.399527, valid precision: 0.872800, valid loss: 96.802407
epoch: 2525, train precision: 0.999000, train loss: 10.445415, valid precision: 0.872200, valid loss: 97.082659
epoch: 2526, train precision: 0.998756, train loss: 10.483214, valid precision: 0.874200, valid loss: 98.472328
epoch: 2527, train precision: 0.999044, train loss: 10.444480, valid precision: 0.873600, valid loss: 97.223959
epoch: 2528, train precision: 0.998444, train loss: 10.602673, valid precision: 0.870600, valid loss: 100.356093
epoch: 2529, train precision: 0.998956, train loss: 10.457922, valid precision: 0.872800, valid loss: 97.790394
epoch: 2530, train precision: 0.999156, train loss: 10.466857, valid precision: 0.874400, valid loss: 95.037717
epoch: 2531, train precision: 0.999089, train loss: 10.401703, valid precision: 0.872600, valid loss: 95.793235
epoch: 2532, train precision: 0.998889, train loss: 10.521913, valid precision: 0.870600, valid loss: 98.443396
epoch: 2533, train precision: 0.998978, train loss: 10.422556, valid precision: 0.874400, valid loss: 96.344815
epoch: 2534, train precision: 0.998933, train loss: 10.410551, valid precision: 0.876200, valid loss: 96.026545
epoch: 2535, train precision: 0.999178, train loss: 10.375341, valid precision: 0.875200, valid loss: 95.431506
epoch: 2536, train precision: 0.999133, train loss: 10.420599, valid precision: 0.877200, valid loss: 95.478197
epoch: 2537, train precision: 0.998933, train loss: 10.431874, valid precision: 0.875000, valid loss: 95.425043
epoch: 2538, train precision: 0.999111, train loss: 10.460694, valid precision: 0.877000, valid loss: 95.496072
epoch: 2539, train precision: 0.999489, train loss: 10.371955, valid precision: 0.874800, valid loss: 93.801063
epoch: 2540, train precision: 0.999200, train loss: 10.397624, valid precision: 0.875200, valid loss: 95.000418
epoch: 2541, train precision: 0.998822, train loss: 10.427316, valid precision: 0.873200, valid loss: 94.291036
epoch: 2542, train precision: 0.998933, train loss: 10.454252, valid precision: 0.873800, valid loss: 94.669913
epoch: 2543, train precision: 0.998800, train loss: 10.507228, valid precision: 0.874600, valid loss: 93.424316
epoch: 2544, train precision: 0.998422, train loss: 10.566609, valid precision: 0.877200, valid loss: 93.873056
epoch: 2545, train precision: 0.998778, train loss: 10.539885, valid precision: 0.877400, valid loss: 93.278506
epoch: 2546, train precision: 0.999022, train loss: 10.425948, valid precision: 0.879000, valid loss: 94.414851
epoch: 2547, train precision: 0.998956, train loss: 10.452387, valid precision: 0.878600, valid loss: 95.382475
epoch: 2548, train precision: 0.999067, train loss: 10.450657, valid precision: 0.875200, valid loss: 94.512460
epoch: 2549, train precision: 0.998844, train loss: 10.506802, valid precision: 0.877800, valid loss: 94.100021
epoch: 2550, train precision: 0.999022, train loss: 10.438987, valid precision: 0.877400, valid loss: 94.857756
epoch: 2551, train precision: 0.998933, train loss: 10.440706, valid precision: 0.876400, valid loss: 96.891769
epoch: 2552, train precision: 0.998644, train loss: 10.556451, valid precision: 0.872000, valid loss: 98.015819
epoch: 2553, train precision: 0.999089, train loss: 10.443523, valid precision: 0.876000, valid loss: 96.960424
epoch: 2554, train precision: 0.998933, train loss: 10.464559, valid precision: 0.873000, valid loss: 97.902915
epoch: 2555, train precision: 0.999000, train loss: 10.447832, valid precision: 0.872600, valid loss: 98.401617
epoch: 2556, train precision: 0.999178, train loss: 10.344983, valid precision: 0.871200, valid loss: 98.802935
epoch: 2557, train precision: 0.998711, train loss: 10.450742, valid precision: 0.877400, valid loss: 98.992092
epoch: 2558, train precision: 0.998733, train loss: 10.505640, valid precision: 0.869600, valid loss: 95.913102
epoch: 2559, train precision: 0.998822, train loss: 10.570851, valid precision: 0.875600, valid loss: 96.930284
epoch: 2560, train precision: 0.999044, train loss: 10.436752, valid precision: 0.874800, valid loss: 95.402033
epoch: 2561, train precision: 0.999222, train loss: 10.375905, valid precision: 0.874600, valid loss: 96.952440
epoch: 2562, train precision: 0.998956, train loss: 10.446372, valid precision: 0.871800, valid loss: 95.253377
epoch: 2563, train precision: 0.998578, train loss: 10.591949, valid precision: 0.873000, valid loss: 95.567494
epoch: 2564, train precision: 0.999111, train loss: 10.384630, valid precision: 0.874200, valid loss: 94.257792
epoch: 2565, train precision: 0.998978, train loss: 10.444072, valid precision: 0.876400, valid loss: 93.206116
epoch: 2566, train precision: 0.999178, train loss: 10.395810, valid precision: 0.875400, valid loss: 93.399037
epoch: 2567, train precision: 0.998778, train loss: 10.517287, valid precision: 0.875000, valid loss: 94.114683
epoch: 2568, train precision: 0.999089, train loss: 10.458070, valid precision: 0.871800, valid loss: 96.804659
epoch: 2569, train precision: 0.998667, train loss: 10.518868, valid precision: 0.869400, valid loss: 98.187122
epoch: 2570, train precision: 0.999311, train loss: 10.360326, valid precision: 0.871600, valid loss: 98.633079
epoch: 2571, train precision: 0.998889, train loss: 10.419060, valid precision: 0.873400, valid loss: 99.125539
epoch: 2572, train precision: 0.998844, train loss: 10.466189, valid precision: 0.872800, valid loss: 97.605718
epoch: 2573, train precision: 0.999156, train loss: 10.381701, valid precision: 0.876800, valid loss: 95.630944
epoch: 2574, train precision: 0.999067, train loss: 10.397235, valid precision: 0.875200, valid loss: 97.549774
epoch: 2575, train precision: 0.999533, train loss: 10.321012, valid precision: 0.874600, valid loss: 96.279942
epoch: 2576, train precision: 0.999156, train loss: 10.361245, valid precision: 0.875800, valid loss: 97.204375
epoch: 2577, train precision: 0.999067, train loss: 10.422026, valid precision: 0.875000, valid loss: 100.121363
epoch: 2578, train precision: 0.998800, train loss: 10.484639, valid precision: 0.871000, valid loss: 98.775858
epoch: 2579, train precision: 0.999222, train loss: 10.406985, valid precision: 0.870600, valid loss: 95.959479
epoch: 2580, train precision: 0.998667, train loss: 10.463220, valid precision: 0.875000, valid loss: 96.065970
epoch: 2581, train precision: 0.999444, train loss: 10.310033, valid precision: 0.874000, valid loss: 95.817185
epoch: 2582, train precision: 0.998756, train loss: 10.514813, valid precision: 0.873600, valid loss: 98.423759
epoch: 2583, train precision: 0.999133, train loss: 10.409720, valid precision: 0.873200, valid loss: 96.823876
epoch: 2584, train precision: 0.999044, train loss: 10.408116, valid precision: 0.875800, valid loss: 97.117685
epoch: 2585, train precision: 0.999156, train loss: 10.357279, valid precision: 0.873600, valid loss: 97.590193
epoch: 2586, train precision: 0.998733, train loss: 10.562193, valid precision: 0.868000, valid loss: 98.562456
epoch: 2587, train precision: 0.999022, train loss: 10.404361, valid precision: 0.875600, valid loss: 96.437232
epoch: 2588, train precision: 0.998756, train loss: 10.476772, valid precision: 0.870200, valid loss: 97.849329
epoch: 2589, train precision: 0.999067, train loss: 10.416880, valid precision: 0.875000, valid loss: 99.609751
epoch: 2590, train precision: 0.999089, train loss: 10.420229, valid precision: 0.871400, valid loss: 97.644375
epoch: 2591, train precision: 0.998978, train loss: 10.427315, valid precision: 0.875200, valid loss: 97.520045
epoch: 2592, train precision: 0.999156, train loss: 10.387400, valid precision: 0.871000, valid loss: 97.269843
epoch: 2593, train precision: 0.999178, train loss: 10.461451, valid precision: 0.870600, valid loss: 95.601331
epoch: 2594, train precision: 0.998822, train loss: 10.463574, valid precision: 0.877200, valid loss: 95.330829
epoch: 2595, train precision: 0.999178, train loss: 10.379096, valid precision: 0.875400, valid loss: 95.534236
epoch: 2596, train precision: 0.998867, train loss: 10.487627, valid precision: 0.875200, valid loss: 98.370738
epoch: 2597, train precision: 0.999044, train loss: 10.444936, valid precision: 0.870400, valid loss: 97.317165
epoch: 2598, train precision: 0.998800, train loss: 10.482291, valid precision: 0.874400, valid loss: 97.742890
epoch: 2599, train precision: 0.998489, train loss: 10.617997, valid precision: 0.870400, valid loss: 97.144255
epoch: 2600, train precision: 0.999067, train loss: 10.391834, valid precision: 0.878000, valid loss: 95.135690
epoch: 2601, train precision: 0.999133, train loss: 10.412376, valid precision: 0.874600, valid loss: 95.294495
epoch: 2602, train precision: 0.998911, train loss: 10.410315, valid precision: 0.876000, valid loss: 93.381075
epoch: 2603, train precision: 0.999200, train loss: 10.423254, valid precision: 0.874400, valid loss: 93.635921
epoch: 2604, train precision: 0.999200, train loss: 10.427093, valid precision: 0.875000, valid loss: 91.409707
epoch: 2605, train precision: 0.999133, train loss: 10.432416, valid precision: 0.878600, valid loss: 92.052682
epoch: 2606, train precision: 0.998956, train loss: 10.460005, valid precision: 0.877000, valid loss: 93.443769
epoch: 2607, train precision: 0.998933, train loss: 10.500050, valid precision: 0.876800, valid loss: 92.855940
epoch: 2608, train precision: 0.999000, train loss: 10.364947, valid precision: 0.871800, valid loss: 95.050896
epoch: 2609, train precision: 0.998911, train loss: 10.537643, valid precision: 0.871600, valid loss: 94.596816
epoch: 2610, train precision: 0.998689, train loss: 10.577627, valid precision: 0.872800, valid loss: 96.360889
epoch: 2611, train precision: 0.999044, train loss: 10.358191, valid precision: 0.875000, valid loss: 94.986718
epoch: 2612, train precision: 0.998333, train loss: 10.665303, valid precision: 0.872800, valid loss: 99.434362
epoch: 2613, train precision: 0.999222, train loss: 10.382940, valid precision: 0.875000, valid loss: 94.925511
epoch: 2614, train precision: 0.998911, train loss: 10.424697, valid precision: 0.874400, valid loss: 93.242184
epoch: 2615, train precision: 0.999311, train loss: 10.355950, valid precision: 0.878200, valid loss: 92.413545
epoch: 2616, train precision: 0.999133, train loss: 10.396864, valid precision: 0.875800, valid loss: 93.593777
epoch: 2617, train precision: 0.999111, train loss: 10.380118, valid precision: 0.875000, valid loss: 96.278124
epoch: 2618, train precision: 0.998889, train loss: 10.490099, valid precision: 0.872200, valid loss: 96.279470
epoch: 2619, train precision: 0.999111, train loss: 10.390004, valid precision: 0.871200, valid loss: 95.915221
epoch: 2620, train precision: 0.998511, train loss: 10.596273, valid precision: 0.873600, valid loss: 95.004442
epoch: 2621, train precision: 0.998956, train loss: 10.416674, valid precision: 0.874000, valid loss: 91.156639
epoch: 2622, train precision: 0.999067, train loss: 10.422684, valid precision: 0.874000, valid loss: 95.069576
epoch: 2623, train precision: 0.998844, train loss: 10.439963, valid precision: 0.875400, valid loss: 94.824990
epoch: 2624, train precision: 0.999044, train loss: 10.465530, valid precision: 0.879800, valid loss: 94.205477
epoch: 2625, train precision: 0.999311, train loss: 10.372957, valid precision: 0.875800, valid loss: 93.731720
epoch: 2626, train precision: 0.998889, train loss: 10.446287, valid precision: 0.872800, valid loss: 95.826730
epoch: 2627, train precision: 0.998867, train loss: 10.480718, valid precision: 0.874000, valid loss: 95.363507
epoch: 2628, train precision: 0.998978, train loss: 10.456539, valid precision: 0.875000, valid loss: 94.811243
epoch: 2629, train precision: 0.999067, train loss: 10.383255, valid precision: 0.869200, valid loss: 95.275028
epoch: 2630, train precision: 0.999178, train loss: 10.402211, valid precision: 0.873800, valid loss: 98.022057
epoch: 2631, train precision: 0.999222, train loss: 10.370341, valid precision: 0.878600, valid loss: 94.029274
epoch: 2632, train precision: 0.999222, train loss: 10.355841, valid precision: 0.879800, valid loss: 96.746353
epoch: 2633, train precision: 0.998533, train loss: 10.512279, valid precision: 0.874000, valid loss: 96.655189
epoch: 2634, train precision: 0.999000, train loss: 10.408494, valid precision: 0.876800, valid loss: 95.560383
epoch: 2635, train precision: 0.998644, train loss: 10.483225, valid precision: 0.876200, valid loss: 94.680737
epoch: 2636, train precision: 0.999067, train loss: 10.442164, valid precision: 0.875800, valid loss: 91.505456
epoch: 2637, train precision: 0.998844, train loss: 10.508671, valid precision: 0.875800, valid loss: 94.159365
epoch: 2638, train precision: 0.999022, train loss: 10.435079, valid precision: 0.873200, valid loss: 93.324992
epoch: 2639, train precision: 0.999133, train loss: 10.380118, valid precision: 0.877400, valid loss: 93.532120
epoch: 2640, train precision: 0.999200, train loss: 10.321087, valid precision: 0.876200, valid loss: 92.582657
epoch: 2641, train precision: 0.999267, train loss: 10.376853, valid precision: 0.875200, valid loss: 91.917969
epoch: 2642, train precision: 0.999111, train loss: 10.343449, valid precision: 0.876200, valid loss: 92.585081
epoch: 2643, train precision: 0.998933, train loss: 10.412887, valid precision: 0.875400, valid loss: 92.661237
epoch: 2644, train precision: 0.998889, train loss: 10.459185, valid precision: 0.874400, valid loss: 96.254012
epoch: 2645, train precision: 0.998844, train loss: 10.539992, valid precision: 0.873200, valid loss: 94.927849
epoch: 2646, train precision: 0.999200, train loss: 10.380406, valid precision: 0.873400, valid loss: 96.483330
epoch: 2647, train precision: 0.998844, train loss: 10.482213, valid precision: 0.870600, valid loss: 97.744335
epoch: 2648, train precision: 0.998867, train loss: 10.538053, valid precision: 0.870200, valid loss: 97.066839
epoch: 2649, train precision: 0.998889, train loss: 10.422653, valid precision: 0.871000, valid loss: 95.952904
epoch: 2650, train precision: 0.999022, train loss: 10.482545, valid precision: 0.872400, valid loss: 95.892848
epoch: 2651, train precision: 0.999022, train loss: 10.423092, valid precision: 0.876000, valid loss: 94.091282
epoch: 2652, train precision: 0.998800, train loss: 10.498459, valid precision: 0.874200, valid loss: 93.875185
epoch: 2653, train precision: 0.999067, train loss: 10.405399, valid precision: 0.871200, valid loss: 96.486951
epoch: 2654, train precision: 0.998933, train loss: 10.375115, valid precision: 0.874800, valid loss: 96.107488
epoch: 2655, train precision: 0.999333, train loss: 10.348919, valid precision: 0.874400, valid loss: 94.721219
epoch: 2656, train precision: 0.998533, train loss: 10.502252, valid precision: 0.872600, valid loss: 95.840017
epoch: 2657, train precision: 0.998800, train loss: 10.482858, valid precision: 0.874200, valid loss: 96.157637
epoch: 2658, train precision: 0.999156, train loss: 10.417871, valid precision: 0.884000, valid loss: 92.632112
epoch: 2659, train precision: 0.998844, train loss: 10.402736, valid precision: 0.874800, valid loss: 96.966697
epoch: 2660, train precision: 0.998778, train loss: 10.544337, valid precision: 0.877600, valid loss: 93.241910
epoch: 2661, train precision: 0.999200, train loss: 10.387171, valid precision: 0.877200, valid loss: 93.948892
epoch: 2662, train precision: 0.998978, train loss: 10.399591, valid precision: 0.874800, valid loss: 94.888300
epoch: 2663, train precision: 0.999000, train loss: 10.442462, valid precision: 0.874800, valid loss: 96.059540
epoch: 2664, train precision: 0.998778, train loss: 10.511947, valid precision: 0.876200, valid loss: 92.964421
epoch: 2665, train precision: 0.998889, train loss: 10.421140, valid precision: 0.872000, valid loss: 95.310811
epoch: 2666, train precision: 0.998822, train loss: 10.550487, valid precision: 0.873200, valid loss: 96.728482
epoch: 2667, train precision: 0.998489, train loss: 10.560667, valid precision: 0.876400, valid loss: 93.416584
epoch: 2668, train precision: 0.998911, train loss: 10.435597, valid precision: 0.876000, valid loss: 95.065893
epoch: 2669, train precision: 0.999133, train loss: 10.369595, valid precision: 0.875200, valid loss: 95.433886
epoch: 2670, train precision: 0.999133, train loss: 10.402360, valid precision: 0.871000, valid loss: 96.967043
epoch: 2671, train precision: 0.998800, train loss: 10.489932, valid precision: 0.877800, valid loss: 96.759856
epoch: 2672, train precision: 0.998533, train loss: 10.581482, valid precision: 0.870600, valid loss: 99.415585
epoch: 2673, train precision: 0.998889, train loss: 10.473625, valid precision: 0.875200, valid loss: 97.434848
epoch: 2674, train precision: 0.998911, train loss: 10.417605, valid precision: 0.872800, valid loss: 95.306602
epoch: 2675, train precision: 0.998911, train loss: 10.439712, valid precision: 0.877200, valid loss: 94.086940
epoch: 2676, train precision: 0.999000, train loss: 10.382521, valid precision: 0.875000, valid loss: 96.465516
epoch: 2677, train precision: 0.998956, train loss: 10.423968, valid precision: 0.872600, valid loss: 95.236583
epoch: 2678, train precision: 0.998778, train loss: 10.507175, valid precision: 0.877400, valid loss: 93.695344
epoch: 2679, train precision: 0.999111, train loss: 10.378887, valid precision: 0.879600, valid loss: 92.609097
epoch: 2680, train precision: 0.998733, train loss: 10.470479, valid precision: 0.875000, valid loss: 93.860160
epoch: 2681, train precision: 0.999089, train loss: 10.366333, valid precision: 0.875400, valid loss: 97.511134
epoch: 2682, train precision: 0.999244, train loss: 10.371025, valid precision: 0.875000, valid loss: 94.495259
epoch: 2683, train precision: 0.998822, train loss: 10.514788, valid precision: 0.878200, valid loss: 91.398497
epoch: 2684, train precision: 0.999178, train loss: 10.388087, valid precision: 0.873600, valid loss: 95.494467
epoch: 2685, train precision: 0.999111, train loss: 10.382531, valid precision: 0.877000, valid loss: 94.743265
epoch: 2686, train precision: 0.998911, train loss: 10.410170, valid precision: 0.881400, valid loss: 93.572984
epoch: 2687, train precision: 0.998733, train loss: 10.494136, valid precision: 0.875000, valid loss: 95.460530
epoch: 2688, train precision: 0.998911, train loss: 10.444594, valid precision: 0.873200, valid loss: 94.722200
epoch: 2689, train precision: 0.999067, train loss: 10.393274, valid precision: 0.876600, valid loss: 94.434562
epoch: 2690, train precision: 0.999000, train loss: 10.361752, valid precision: 0.872400, valid loss: 96.164876
epoch: 2691, train precision: 0.999289, train loss: 10.328538, valid precision: 0.876600, valid loss: 94.334813
epoch: 2692, train precision: 0.999022, train loss: 10.418689, valid precision: 0.872400, valid loss: 94.912170
epoch: 2693, train precision: 0.998800, train loss: 10.488809, valid precision: 0.871400, valid loss: 95.036372
epoch: 2694, train precision: 0.999067, train loss: 10.368141, valid precision: 0.871600, valid loss: 93.703222
epoch: 2695, train precision: 0.998956, train loss: 10.433491, valid precision: 0.875200, valid loss: 93.277011
epoch: 2696, train precision: 0.998956, train loss: 10.371063, valid precision: 0.877200, valid loss: 92.661833
epoch: 2697, train precision: 0.999156, train loss: 10.375913, valid precision: 0.873400, valid loss: 93.975246
epoch: 2698, train precision: 0.999156, train loss: 10.348492, valid precision: 0.873200, valid loss: 95.031358
epoch: 2699, train precision: 0.999133, train loss: 10.343334, valid precision: 0.877600, valid loss: 93.278925
epoch: 2700, train precision: 0.998667, train loss: 10.531029, valid precision: 0.872800, valid loss: 92.188833
epoch: 2701, train precision: 0.999178, train loss: 10.350362, valid precision: 0.875800, valid loss: 93.413381
epoch: 2702, train precision: 0.998667, train loss: 10.514213, valid precision: 0.875800, valid loss: 95.713998
epoch: 2703, train precision: 0.998933, train loss: 10.424480, valid precision: 0.871000, valid loss: 94.192074
epoch: 2704, train precision: 0.998489, train loss: 10.534948, valid precision: 0.871600, valid loss: 94.438912
epoch: 2705, train precision: 0.998911, train loss: 10.445089, valid precision: 0.874800, valid loss: 93.166707
epoch: 2706, train precision: 0.999089, train loss: 10.391519, valid precision: 0.878200, valid loss: 93.670493
epoch: 2707, train precision: 0.999133, train loss: 10.332825, valid precision: 0.873400, valid loss: 93.209247
epoch: 2708, train precision: 0.999111, train loss: 10.351958, valid precision: 0.876600, valid loss: 93.564211
epoch: 2709, train precision: 0.998511, train loss: 10.524098, valid precision: 0.877600, valid loss: 93.685693
epoch: 2710, train precision: 0.998733, train loss: 10.514956, valid precision: 0.877800, valid loss: 94.105758
epoch: 2711, train precision: 0.998978, train loss: 10.359550, valid precision: 0.877600, valid loss: 93.886320
epoch: 2712, train precision: 0.999044, train loss: 10.395671, valid precision: 0.873600, valid loss: 94.777694
epoch: 2713, train precision: 0.998933, train loss: 10.382086, valid precision: 0.877400, valid loss: 93.367425
epoch: 2714, train precision: 0.999067, train loss: 10.400307, valid precision: 0.875000, valid loss: 92.670272
epoch: 2715, train precision: 0.999289, train loss: 10.365407, valid precision: 0.877600, valid loss: 92.941169
epoch: 2716, train precision: 0.998533, train loss: 10.530049, valid precision: 0.874200, valid loss: 93.174993
epoch: 2717, train precision: 0.998889, train loss: 10.479643, valid precision: 0.874600, valid loss: 94.084292
epoch: 2718, train precision: 0.998267, train loss: 10.667736, valid precision: 0.871600, valid loss: 96.863593
epoch: 2719, train precision: 0.998733, train loss: 10.462755, valid precision: 0.874800, valid loss: 96.144624
epoch: 2720, train precision: 0.998800, train loss: 10.443397, valid precision: 0.877200, valid loss: 95.001134
epoch: 2721, train precision: 0.999133, train loss: 10.380086, valid precision: 0.877400, valid loss: 94.946170
epoch: 2722, train precision: 0.999222, train loss: 10.375894, valid precision: 0.873200, valid loss: 96.377864
epoch: 2723, train precision: 0.999044, train loss: 10.382731, valid precision: 0.875000, valid loss: 94.727567
epoch: 2724, train precision: 0.999133, train loss: 10.373028, valid precision: 0.875000, valid loss: 93.438173
epoch: 2725, train precision: 0.998911, train loss: 10.478154, valid precision: 0.875400, valid loss: 95.087510
epoch: 2726, train precision: 0.998689, train loss: 10.520003, valid precision: 0.880000, valid loss: 93.133712
epoch: 2727, train precision: 0.999200, train loss: 10.371589, valid precision: 0.875000, valid loss: 94.104684
epoch: 2728, train precision: 0.999022, train loss: 10.408890, valid precision: 0.879000, valid loss: 92.639959
epoch: 2729, train precision: 0.999156, train loss: 10.316190, valid precision: 0.879600, valid loss: 95.251626
epoch: 2730, train precision: 0.998689, train loss: 10.556874, valid precision: 0.876200, valid loss: 93.574432
epoch: 2731, train precision: 0.998933, train loss: 10.441301, valid precision: 0.872400, valid loss: 93.778897
epoch: 2732, train precision: 0.999356, train loss: 10.359071, valid precision: 0.879000, valid loss: 90.929263
epoch: 2733, train precision: 0.999222, train loss: 10.378933, valid precision: 0.876200, valid loss: 93.848419
epoch: 2734, train precision: 0.998844, train loss: 10.472528, valid precision: 0.875800, valid loss: 95.505456
epoch: 2735, train precision: 0.998422, train loss: 10.566840, valid precision: 0.873000, valid loss: 96.021777
epoch: 2736, train precision: 0.999111, train loss: 10.376839, valid precision: 0.875400, valid loss: 94.693463
epoch: 2737, train precision: 0.998867, train loss: 10.433487, valid precision: 0.874000, valid loss: 96.003378
epoch: 2738, train precision: 0.999311, train loss: 10.330841, valid precision: 0.874600, valid loss: 93.654690
epoch: 2739, train precision: 0.998578, train loss: 10.535029, valid precision: 0.875400, valid loss: 96.092385
epoch: 2740, train precision: 0.999333, train loss: 10.300620, valid precision: 0.873200, valid loss: 94.409514
epoch: 2741, train precision: 0.999267, train loss: 10.322830, valid precision: 0.878600, valid loss: 93.108845
epoch: 2742, train precision: 0.998667, train loss: 10.500235, valid precision: 0.875000, valid loss: 97.283161
epoch: 2743, train precision: 0.999133, train loss: 10.327896, valid precision: 0.872200, valid loss: 97.195296
epoch: 2744, train precision: 0.998600, train loss: 10.535834, valid precision: 0.874000, valid loss: 95.268583
epoch: 2745, train precision: 0.999022, train loss: 10.359762, valid precision: 0.879000, valid loss: 94.680436
epoch: 2746, train precision: 0.999156, train loss: 10.351636, valid precision: 0.875200, valid loss: 93.807691
epoch: 2747, train precision: 0.999000, train loss: 10.402361, valid precision: 0.876000, valid loss: 94.021742
epoch: 2748, train precision: 0.998933, train loss: 10.422220, valid precision: 0.871400, valid loss: 93.272397
epoch: 2749, train precision: 0.999289, train loss: 10.307014, valid precision: 0.874000, valid loss: 94.342797
epoch: 2750, train precision: 0.999222, train loss: 10.320686, valid precision: 0.878800, valid loss: 93.738096
epoch: 2751, train precision: 0.999200, train loss: 10.379617, valid precision: 0.871800, valid loss: 93.083353
epoch: 2752, train precision: 0.999067, train loss: 10.360404, valid precision: 0.874400, valid loss: 95.219659
epoch: 2753, train precision: 0.998911, train loss: 10.400020, valid precision: 0.872000, valid loss: 96.577774
epoch: 2754, train precision: 0.998933, train loss: 10.443781, valid precision: 0.874800, valid loss: 94.748129
epoch: 2755, train precision: 0.998889, train loss: 10.448879, valid precision: 0.874000, valid loss: 95.402904
epoch: 2756, train precision: 0.998778, train loss: 10.507382, valid precision: 0.874400, valid loss: 96.089148
epoch: 2757, train precision: 0.999067, train loss: 10.366957, valid precision: 0.872400, valid loss: 95.672694
epoch: 2758, train precision: 0.999022, train loss: 10.384212, valid precision: 0.873600, valid loss: 98.340129
epoch: 2759, train precision: 0.999133, train loss: 10.354483, valid precision: 0.873600, valid loss: 97.151293
epoch: 2760, train precision: 0.998622, train loss: 10.575778, valid precision: 0.873800, valid loss: 98.532436
epoch: 2761, train precision: 0.998778, train loss: 10.525755, valid precision: 0.875600, valid loss: 96.152514
epoch: 2762, train precision: 0.998889, train loss: 10.446412, valid precision: 0.875200, valid loss: 97.065998
epoch: 2763, train precision: 0.998889, train loss: 10.439815, valid precision: 0.879200, valid loss: 96.731097
epoch: 2764, train precision: 0.999356, train loss: 10.294542, valid precision: 0.877600, valid loss: 96.330740
epoch: 2765, train precision: 0.998911, train loss: 10.417336, valid precision: 0.875800, valid loss: 95.216965
epoch: 2766, train precision: 0.999000, train loss: 10.415636, valid precision: 0.872600, valid loss: 95.019607
epoch: 2767, train precision: 0.999156, train loss: 10.369296, valid precision: 0.870000, valid loss: 96.493271
epoch: 2768, train precision: 0.998933, train loss: 10.394515, valid precision: 0.872000, valid loss: 94.075338
epoch: 2769, train precision: 0.998889, train loss: 10.456634, valid precision: 0.872600, valid loss: 96.896909
epoch: 2770, train precision: 0.999044, train loss: 10.383422, valid precision: 0.872000, valid loss: 96.700858
epoch: 2771, train precision: 0.999133, train loss: 10.303834, valid precision: 0.875200, valid loss: 97.224012
epoch: 2772, train precision: 0.998822, train loss: 10.476520, valid precision: 0.872600, valid loss: 96.901517
epoch: 2773, train precision: 0.999067, train loss: 10.358540, valid precision: 0.880400, valid loss: 95.917948
epoch: 2774, train precision: 0.998511, train loss: 10.539597, valid precision: 0.871400, valid loss: 94.809548
epoch: 2775, train precision: 0.999156, train loss: 10.347649, valid precision: 0.874600, valid loss: 97.217689
epoch: 2776, train precision: 0.998933, train loss: 10.469766, valid precision: 0.871800, valid loss: 96.766312
epoch: 2777, train precision: 0.999422, train loss: 10.295197, valid precision: 0.870600, valid loss: 95.420997
epoch: 2778, train precision: 0.999200, train loss: 10.374052, valid precision: 0.871800, valid loss: 95.873235
epoch: 2779, train precision: 0.999267, train loss: 10.331583, valid precision: 0.872200, valid loss: 97.128844
epoch: 2780, train precision: 0.999267, train loss: 10.315388, valid precision: 0.875200, valid loss: 97.130916
epoch: 2781, train precision: 0.998956, train loss: 10.356467, valid precision: 0.871400, valid loss: 95.810727
epoch: 2782, train precision: 0.999044, train loss: 10.361843, valid precision: 0.876200, valid loss: 93.056890
epoch: 2783, train precision: 0.998867, train loss: 10.411732, valid precision: 0.870800, valid loss: 96.494985
epoch: 2784, train precision: 0.999022, train loss: 10.363066, valid precision: 0.874000, valid loss: 95.588503
epoch: 2785, train precision: 0.998556, train loss: 10.535424, valid precision: 0.873400, valid loss: 98.272612
epoch: 2786, train precision: 0.999022, train loss: 10.383433, valid precision: 0.870800, valid loss: 97.064937
epoch: 2787, train precision: 0.999289, train loss: 10.300427, valid precision: 0.873000, valid loss: 98.398670
epoch: 2788, train precision: 0.998778, train loss: 10.437428, valid precision: 0.870200, valid loss: 97.475862
epoch: 2789, train precision: 0.998644, train loss: 10.500808, valid precision: 0.874200, valid loss: 96.756885
epoch: 2790, train precision: 0.999067, train loss: 10.345596, valid precision: 0.872600, valid loss: 97.393469
epoch: 2791, train precision: 0.998689, train loss: 10.531780, valid precision: 0.871000, valid loss: 97.245150
epoch: 2792, train precision: 0.998733, train loss: 10.485465, valid precision: 0.874200, valid loss: 94.859027
epoch: 2793, train precision: 0.999111, train loss: 10.333194, valid precision: 0.870400, valid loss: 96.990396
epoch: 2794, train precision: 0.999111, train loss: 10.365285, valid precision: 0.869600, valid loss: 98.693908
epoch: 2795, train precision: 0.999000, train loss: 10.418664, valid precision: 0.872400, valid loss: 95.389513
epoch: 2796, train precision: 0.998822, train loss: 10.491183, valid precision: 0.869400, valid loss: 97.545427
epoch: 2797, train precision: 0.999422, train loss: 10.335768, valid precision: 0.873200, valid loss: 95.887402
epoch: 2798, train precision: 0.998711, train loss: 10.517677, valid precision: 0.871000, valid loss: 97.193522
epoch: 2799, train precision: 0.998622, train loss: 10.525840, valid precision: 0.869800, valid loss: 97.141891
epoch: 2800, train precision: 0.998956, train loss: 10.404147, valid precision: 0.869800, valid loss: 96.163283
epoch: 2801, train precision: 0.998800, train loss: 10.461254, valid precision: 0.871600, valid loss: 95.713915
epoch: 2802, train precision: 0.998933, train loss: 10.399937, valid precision: 0.872400, valid loss: 95.064777
epoch: 2803, train precision: 0.999200, train loss: 10.359664, valid precision: 0.873200, valid loss: 98.665330
epoch: 2804, train precision: 0.998711, train loss: 10.483669, valid precision: 0.868000, valid loss: 100.489324
epoch: 2805, train precision: 0.999244, train loss: 10.356821, valid precision: 0.871200, valid loss: 97.139310
epoch: 2806, train precision: 0.999044, train loss: 10.385931, valid precision: 0.876400, valid loss: 96.536685
epoch: 2807, train precision: 0.999222, train loss: 10.314940, valid precision: 0.874200, valid loss: 96.713738
epoch: 2808, train precision: 0.999156, train loss: 10.412096, valid precision: 0.870600, valid loss: 99.033613
epoch: 2809, train precision: 0.998933, train loss: 10.406764, valid precision: 0.870400, valid loss: 100.268419
epoch: 2810, train precision: 0.999000, train loss: 10.385346, valid precision: 0.871400, valid loss: 98.582538
epoch: 2811, train precision: 0.998889, train loss: 10.481264, valid precision: 0.870000, valid loss: 96.668173
epoch: 2812, train precision: 0.999200, train loss: 10.322454, valid precision: 0.872200, valid loss: 95.872300
epoch: 2813, train precision: 0.999000, train loss: 10.403139, valid precision: 0.870400, valid loss: 96.314624
epoch: 2814, train precision: 0.999156, train loss: 10.326124, valid precision: 0.871600, valid loss: 96.864264
epoch: 2815, train precision: 0.998911, train loss: 10.444087, valid precision: 0.869200, valid loss: 96.126958
epoch: 2816, train precision: 0.998889, train loss: 10.433493, valid precision: 0.872200, valid loss: 97.491950
epoch: 2817, train precision: 0.999044, train loss: 10.448803, valid precision: 0.869000, valid loss: 98.051290
epoch: 2818, train precision: 0.998756, train loss: 10.447296, valid precision: 0.869000, valid loss: 96.139934
epoch: 2819, train precision: 0.998756, train loss: 10.481359, valid precision: 0.873600, valid loss: 94.581339
epoch: 2820, train precision: 0.999156, train loss: 10.331355, valid precision: 0.874400, valid loss: 96.714613
epoch: 2821, train precision: 0.999111, train loss: 10.317011, valid precision: 0.871400, valid loss: 98.279017
epoch: 2822, train precision: 0.998844, train loss: 10.391638, valid precision: 0.872600, valid loss: 98.168512
epoch: 2823, train precision: 0.998444, train loss: 10.560994, valid precision: 0.874200, valid loss: 96.154070
epoch: 2824, train precision: 0.998644, train loss: 10.504656, valid precision: 0.873800, valid loss: 96.607316
epoch: 2825, train precision: 0.999067, train loss: 10.434892, valid precision: 0.872600, valid loss: 97.062712
epoch: 2826, train precision: 0.998933, train loss: 10.449897, valid precision: 0.871400, valid loss: 97.877534
epoch: 2827, train precision: 0.998933, train loss: 10.323955, valid precision: 0.875000, valid loss: 97.110294
epoch: 2828, train precision: 0.998689, train loss: 10.531249, valid precision: 0.873000, valid loss: 95.221638
epoch: 2829, train precision: 0.999178, train loss: 10.345836, valid precision: 0.876200, valid loss: 93.546266
epoch: 2830, train precision: 0.999111, train loss: 10.374970, valid precision: 0.873600, valid loss: 95.528928
epoch: 2831, train precision: 0.999067, train loss: 10.404031, valid precision: 0.873200, valid loss: 97.712639
epoch: 2832, train precision: 0.999000, train loss: 10.356519, valid precision: 0.876400, valid loss: 94.866102
epoch: 2833, train precision: 0.999200, train loss: 10.319137, valid precision: 0.870600, valid loss: 96.865986
epoch: 2834, train precision: 0.998956, train loss: 10.381878, valid precision: 0.871600, valid loss: 94.815100
epoch: 2835, train precision: 0.999178, train loss: 10.341333, valid precision: 0.872600, valid loss: 95.398593
epoch: 2836, train precision: 0.999111, train loss: 10.402622, valid precision: 0.874600, valid loss: 95.637990
epoch: 2837, train precision: 0.998867, train loss: 10.426035, valid precision: 0.873800, valid loss: 92.808025
epoch: 2838, train precision: 0.998978, train loss: 10.359811, valid precision: 0.875200, valid loss: 92.499611
epoch: 2839, train precision: 0.998800, train loss: 10.459277, valid precision: 0.876200, valid loss: 95.411552
epoch: 2840, train precision: 0.999133, train loss: 10.354963, valid precision: 0.876600, valid loss: 94.777115
epoch: 2841, train precision: 0.998844, train loss: 10.441973, valid precision: 0.869600, valid loss: 97.312690
epoch: 2842, train precision: 0.998733, train loss: 10.469549, valid precision: 0.870000, valid loss: 98.037083
epoch: 2843, train precision: 0.999178, train loss: 10.379719, valid precision: 0.877200, valid loss: 95.549768
epoch: 2844, train precision: 0.998778, train loss: 10.427179, valid precision: 0.878400, valid loss: 96.776276
epoch: 2845, train precision: 0.998778, train loss: 10.414765, valid precision: 0.875600, valid loss: 95.379240
epoch: 2846, train precision: 0.998778, train loss: 10.430605, valid precision: 0.877400, valid loss: 94.958467
epoch: 2847, train precision: 0.998844, train loss: 10.488201, valid precision: 0.874600, valid loss: 94.292548
epoch: 2848, train precision: 0.998911, train loss: 10.406391, valid precision: 0.878000, valid loss: 96.257598
epoch: 2849, train precision: 0.999089, train loss: 10.339287, valid precision: 0.875000, valid loss: 96.867510
epoch: 2850, train precision: 0.999267, train loss: 10.344823, valid precision: 0.873800, valid loss: 97.654564
epoch: 2851, train precision: 0.999022, train loss: 10.374768, valid precision: 0.877000, valid loss: 95.165641
epoch: 2852, train precision: 0.999044, train loss: 10.342591, valid precision: 0.872600, valid loss: 97.483767
epoch: 2853, train precision: 0.998667, train loss: 10.485272, valid precision: 0.874000, valid loss: 99.021640
epoch: 2854, train precision: 0.999222, train loss: 10.317360, valid precision: 0.874200, valid loss: 97.535151
epoch: 2855, train precision: 0.998933, train loss: 10.387198, valid precision: 0.872600, valid loss: 99.078522
epoch: 2856, train precision: 0.999111, train loss: 10.343031, valid precision: 0.872600, valid loss: 97.394791
epoch: 2857, train precision: 0.999067, train loss: 10.367781, valid precision: 0.874000, valid loss: 97.867522
epoch: 2858, train precision: 0.999222, train loss: 10.307216, valid precision: 0.876200, valid loss: 96.904028
epoch: 2859, train precision: 0.998578, train loss: 10.561989, valid precision: 0.874200, valid loss: 98.176193
epoch: 2860, train precision: 0.998778, train loss: 10.424532, valid precision: 0.870400, valid loss: 102.050602
epoch: 2861, train precision: 0.998822, train loss: 10.358879, valid precision: 0.876200, valid loss: 95.867099
epoch: 2862, train precision: 0.999200, train loss: 10.290601, valid precision: 0.873800, valid loss: 96.136434
epoch: 2863, train precision: 0.999067, train loss: 10.292976, valid precision: 0.877800, valid loss: 97.689054
epoch: 2864, train precision: 0.999356, train loss: 10.292148, valid precision: 0.875600, valid loss: 96.659306
epoch: 2865, train precision: 0.999000, train loss: 10.341040, valid precision: 0.879400, valid loss: 98.312757
epoch: 2866, train precision: 0.998733, train loss: 10.468383, valid precision: 0.874800, valid loss: 98.897651
epoch: 2867, train precision: 0.999244, train loss: 10.360507, valid precision: 0.873800, valid loss: 97.425280
epoch: 2868, train precision: 0.999067, train loss: 10.384978, valid precision: 0.873000, valid loss: 99.287628
epoch: 2869, train precision: 0.998889, train loss: 10.421276, valid precision: 0.874400, valid loss: 97.392361
epoch: 2870, train precision: 0.999200, train loss: 10.323907, valid precision: 0.870200, valid loss: 95.803285
epoch: 2871, train precision: 0.998800, train loss: 10.407829, valid precision: 0.874800, valid loss: 95.842594
epoch: 2872, train precision: 0.999111, train loss: 10.382188, valid precision: 0.873000, valid loss: 96.224786
epoch: 2873, train precision: 0.999000, train loss: 10.394205, valid precision: 0.871600, valid loss: 98.875947
epoch: 2874, train precision: 0.999333, train loss: 10.287467, valid precision: 0.871600, valid loss: 96.283611
epoch: 2875, train precision: 0.999000, train loss: 10.360739, valid precision: 0.869600, valid loss: 98.740257
epoch: 2876, train precision: 0.998511, train loss: 10.475011, valid precision: 0.873000, valid loss: 98.466390
epoch: 2877, train precision: 0.999022, train loss: 10.358250, valid precision: 0.869800, valid loss: 98.694081
epoch: 2878, train precision: 0.998711, train loss: 10.509284, valid precision: 0.866400, valid loss: 98.975398
epoch: 2879, train precision: 0.998667, train loss: 10.458535, valid precision: 0.873200, valid loss: 97.528921
epoch: 2880, train precision: 0.999178, train loss: 10.344641, valid precision: 0.875400, valid loss: 97.399620
epoch: 2881, train precision: 0.998844, train loss: 10.382474, valid precision: 0.873200, valid loss: 96.378068
epoch: 2882, train precision: 0.999067, train loss: 10.340726, valid precision: 0.873400, valid loss: 97.775911
epoch: 2883, train precision: 0.999022, train loss: 10.383788, valid precision: 0.873200, valid loss: 96.683070
epoch: 2884, train precision: 0.999222, train loss: 10.305865, valid precision: 0.876200, valid loss: 96.140011
epoch: 2885, train precision: 0.999200, train loss: 10.277227, valid precision: 0.873600, valid loss: 100.303223
epoch: 2886, train precision: 0.998667, train loss: 10.440113, valid precision: 0.870800, valid loss: 98.869224
epoch: 2887, train precision: 0.998578, train loss: 10.473600, valid precision: 0.871000, valid loss: 96.586122
epoch: 2888, train precision: 0.998800, train loss: 10.414762, valid precision: 0.868400, valid loss: 100.477191
epoch: 2889, train precision: 0.998756, train loss: 10.456666, valid precision: 0.870800, valid loss: 98.713816
epoch: 2890, train precision: 0.999178, train loss: 10.323785, valid precision: 0.874200, valid loss: 99.717537
epoch: 2891, train precision: 0.999000, train loss: 10.378616, valid precision: 0.876400, valid loss: 97.399809
epoch: 2892, train precision: 0.998933, train loss: 10.344224, valid precision: 0.868600, valid loss: 98.730967
epoch: 2893, train precision: 0.998911, train loss: 10.396820, valid precision: 0.872600, valid loss: 96.951593
epoch: 2894, train precision: 0.998978, train loss: 10.378335, valid precision: 0.873000, valid loss: 99.598750
epoch: 2895, train precision: 0.998822, train loss: 10.417027, valid precision: 0.874600, valid loss: 97.775968
epoch: 2896, train precision: 0.998756, train loss: 10.385574, valid precision: 0.873600, valid loss: 98.166066
epoch: 2897, train precision: 0.998556, train loss: 10.481214, valid precision: 0.877200, valid loss: 98.507337
epoch: 2898, train precision: 0.998978, train loss: 10.388177, valid precision: 0.875200, valid loss: 99.856252
epoch: 2899, train precision: 0.999133, train loss: 10.359224, valid precision: 0.869200, valid loss: 100.941082
epoch: 2900, train precision: 0.998622, train loss: 10.556045, valid precision: 0.872400, valid loss: 99.865331
epoch: 2901, train precision: 0.999289, train loss: 10.272502, valid precision: 0.873200, valid loss: 99.418507
epoch: 2902, train precision: 0.999089, train loss: 10.321489, valid precision: 0.869200, valid loss: 100.219731
epoch: 2903, train precision: 0.999178, train loss: 10.336221, valid precision: 0.868400, valid loss: 102.038615
epoch: 2904, train precision: 0.998978, train loss: 10.370868, valid precision: 0.874200, valid loss: 99.500574
epoch: 2905, train precision: 0.998378, train loss: 10.509644, valid precision: 0.871000, valid loss: 100.032234
epoch: 2906, train precision: 0.998933, train loss: 10.392276, valid precision: 0.871200, valid loss: 100.637439
epoch: 2907, train precision: 0.998978, train loss: 10.328379, valid precision: 0.874200, valid loss: 100.240332
epoch: 2908, train precision: 0.999000, train loss: 10.343422, valid precision: 0.865800, valid loss: 100.234693
epoch: 2909, train precision: 0.999133, train loss: 10.269373, valid precision: 0.871800, valid loss: 97.779189
epoch: 2910, train precision: 0.999111, train loss: 10.332682, valid precision: 0.872000, valid loss: 98.057218
epoch: 2911, train precision: 0.999067, train loss: 10.334795, valid precision: 0.871200, valid loss: 97.421982
epoch: 2912, train precision: 0.998867, train loss: 10.361145, valid precision: 0.874800, valid loss: 98.341663
epoch: 2913, train precision: 0.999222, train loss: 10.274012, valid precision: 0.870400, valid loss: 99.946353
epoch: 2914, train precision: 0.998578, train loss: 10.480708, valid precision: 0.872600, valid loss: 99.435853
epoch: 2915, train precision: 0.999000, train loss: 10.385176, valid precision: 0.873000, valid loss: 96.635341
epoch: 2916, train precision: 0.999067, train loss: 10.308431, valid precision: 0.876000, valid loss: 96.550555
epoch: 2917, train precision: 0.999022, train loss: 10.347413, valid precision: 0.874000, valid loss: 96.913258
epoch: 2918, train precision: 0.999267, train loss: 10.310789, valid precision: 0.873800, valid loss: 98.179777
epoch: 2919, train precision: 0.999200, train loss: 10.372833, valid precision: 0.870200, valid loss: 98.414021
epoch: 2920, train precision: 0.999133, train loss: 10.371673, valid precision: 0.874000, valid loss: 99.526459
epoch: 2921, train precision: 0.999133, train loss: 10.283383, valid precision: 0.868200, valid loss: 100.023082
epoch: 2922, train precision: 0.999222, train loss: 10.324367, valid precision: 0.868200, valid loss: 100.630954
epoch: 2923, train precision: 0.998867, train loss: 10.386584, valid precision: 0.871200, valid loss: 101.082546
epoch: 2924, train precision: 0.998956, train loss: 10.369103, valid precision: 0.873000, valid loss: 97.758155
epoch: 2925, train precision: 0.999022, train loss: 10.371961, valid precision: 0.871800, valid loss: 95.644053
epoch: 2926, train precision: 0.998978, train loss: 10.394577, valid precision: 0.868800, valid loss: 99.126863
epoch: 2927, train precision: 0.998800, train loss: 10.388666, valid precision: 0.872800, valid loss: 95.908449
epoch: 2928, train precision: 0.999378, train loss: 10.240755, valid precision: 0.874200, valid loss: 98.492337
epoch: 2929, train precision: 0.999178, train loss: 10.323324, valid precision: 0.874200, valid loss: 95.807560
epoch: 2930, train precision: 0.998889, train loss: 10.411537, valid precision: 0.873600, valid loss: 99.007193
epoch: 2931, train precision: 0.998978, train loss: 10.353543, valid precision: 0.874200, valid loss: 95.675875
epoch: 2932, train precision: 0.998867, train loss: 10.416261, valid precision: 0.874000, valid loss: 97.209551
epoch: 2933, train precision: 0.998733, train loss: 10.430926, valid precision: 0.870200, valid loss: 97.445326
epoch: 2934, train precision: 0.999000, train loss: 10.365242, valid precision: 0.874600, valid loss: 96.167133
epoch: 2935, train precision: 0.999178, train loss: 10.318625, valid precision: 0.874000, valid loss: 96.085123
epoch: 2936, train precision: 0.998733, train loss: 10.452556, valid precision: 0.871800, valid loss: 100.141466
epoch: 2937, train precision: 0.998644, train loss: 10.488389, valid precision: 0.872800, valid loss: 96.895749
epoch: 2938, train precision: 0.998956, train loss: 10.409489, valid precision: 0.872800, valid loss: 98.798889
epoch: 2939, train precision: 0.999311, train loss: 10.286701, valid precision: 0.871200, valid loss: 99.552058
epoch: 2940, train precision: 0.998933, train loss: 10.398934, valid precision: 0.872000, valid loss: 98.793783
epoch: 2941, train precision: 0.999222, train loss: 10.305300, valid precision: 0.872600, valid loss: 96.399518
epoch: 2942, train precision: 0.999067, train loss: 10.364078, valid precision: 0.873200, valid loss: 96.726294
epoch: 2943, train precision: 0.998578, train loss: 10.524110, valid precision: 0.868800, valid loss: 99.355902
epoch: 2944, train precision: 0.998889, train loss: 10.386944, valid precision: 0.868200, valid loss: 99.055177
epoch: 2945, train precision: 0.998933, train loss: 10.389724, valid precision: 0.871800, valid loss: 96.909147
epoch: 2946, train precision: 0.998689, train loss: 10.381815, valid precision: 0.868000, valid loss: 100.375277
epoch: 2947, train precision: 0.998644, train loss: 10.446305, valid precision: 0.871400, valid loss: 99.422372
epoch: 2948, train precision: 0.999267, train loss: 10.279315, valid precision: 0.870400, valid loss: 99.013314
epoch: 2949, train precision: 0.999022, train loss: 10.331083, valid precision: 0.871000, valid loss: 99.190717
epoch: 2950, train precision: 0.998778, train loss: 10.443652, valid precision: 0.873200, valid loss: 99.143303
epoch: 2951, train precision: 0.999089, train loss: 10.375519, valid precision: 0.871200, valid loss: 97.180463
epoch: 2952, train precision: 0.998933, train loss: 10.406512, valid precision: 0.874200, valid loss: 97.854596
epoch: 2953, train precision: 0.999067, train loss: 10.333533, valid precision: 0.873400, valid loss: 99.606301
epoch: 2954, train precision: 0.998933, train loss: 10.365650, valid precision: 0.870800, valid loss: 100.815444
epoch: 2955, train precision: 0.998822, train loss: 10.520530, valid precision: 0.876800, valid loss: 99.047770
epoch: 2956, train precision: 0.999267, train loss: 10.313666, valid precision: 0.875600, valid loss: 96.210842
epoch: 2957, train precision: 0.999000, train loss: 10.469123, valid precision: 0.872200, valid loss: 96.176663
epoch: 2958, train precision: 0.999133, train loss: 10.283231, valid precision: 0.877400, valid loss: 96.126256
epoch: 2959, train precision: 0.998933, train loss: 10.359138, valid precision: 0.873000, valid loss: 97.544545
epoch: 2960, train precision: 0.998911, train loss: 10.405701, valid precision: 0.869800, valid loss: 99.455974
epoch: 2961, train precision: 0.998689, train loss: 10.479689, valid precision: 0.877400, valid loss: 96.518952
epoch: 2962, train precision: 0.998822, train loss: 10.461928, valid precision: 0.872000, valid loss: 95.558644
epoch: 2963, train precision: 0.998978, train loss: 10.384755, valid precision: 0.875200, valid loss: 95.555724
epoch: 2964, train precision: 0.998889, train loss: 10.386730, valid precision: 0.874000, valid loss: 95.387721
epoch: 2965, train precision: 0.999267, train loss: 10.290474, valid precision: 0.875600, valid loss: 94.951142
epoch: 2966, train precision: 0.999089, train loss: 10.317674, valid precision: 0.876800, valid loss: 97.837709
epoch: 2967, train precision: 0.998756, train loss: 10.388813, valid precision: 0.874400, valid loss: 98.780999
epoch: 2968, train precision: 0.999222, train loss: 10.313264, valid precision: 0.878000, valid loss: 93.708216
epoch: 2969, train precision: 0.999000, train loss: 10.385008, valid precision: 0.876200, valid loss: 95.409257
epoch: 2970, train precision: 0.999222, train loss: 10.273816, valid precision: 0.871800, valid loss: 95.848223
epoch: 2971, train precision: 0.999022, train loss: 10.389933, valid precision: 0.876600, valid loss: 93.798918
epoch: 2972, train precision: 0.999289, train loss: 10.257616, valid precision: 0.874200, valid loss: 95.486337
epoch: 2973, train precision: 0.999022, train loss: 10.408060, valid precision: 0.872400, valid loss: 94.899971
epoch: 2974, train precision: 0.999244, train loss: 10.315403, valid precision: 0.876000, valid loss: 95.979151
epoch: 2975, train precision: 0.999067, train loss: 10.395568, valid precision: 0.877200, valid loss: 96.575427
epoch: 2976, train precision: 0.998822, train loss: 10.453371, valid precision: 0.870200, valid loss: 96.866017
epoch: 2977, train precision: 0.999222, train loss: 10.292170, valid precision: 0.875200, valid loss: 95.062471
epoch: 2978, train precision: 0.998911, train loss: 10.342820, valid precision: 0.874600, valid loss: 95.286174
epoch: 2979, train precision: 0.999111, train loss: 10.386191, valid precision: 0.876000, valid loss: 96.402334
epoch: 2980, train precision: 0.999289, train loss: 10.273235, valid precision: 0.877000, valid loss: 95.395174
epoch: 2981, train precision: 0.999111, train loss: 10.396669, valid precision: 0.875400, valid loss: 94.836983
epoch: 2982, train precision: 0.999044, train loss: 10.398337, valid precision: 0.873200, valid loss: 99.705247
epoch: 2983, train precision: 0.999200, train loss: 10.272186, valid precision: 0.873000, valid loss: 96.771178
epoch: 2984, train precision: 0.999222, train loss: 10.312472, valid precision: 0.873400, valid loss: 98.123132
epoch: 2985, train precision: 0.998822, train loss: 10.412910, valid precision: 0.874800, valid loss: 95.814696
epoch: 2986, train precision: 0.998756, train loss: 10.417806, valid precision: 0.873800, valid loss: 100.409192
epoch: 2987, train precision: 0.999356, train loss: 10.250500, valid precision: 0.872400, valid loss: 97.768496
epoch: 2988, train precision: 0.999178, train loss: 10.314101, valid precision: 0.875400, valid loss: 95.979981
epoch: 2989, train precision: 0.998800, train loss: 10.368790, valid precision: 0.871800, valid loss: 96.946871
epoch: 2990, train precision: 0.999244, train loss: 10.245506, valid precision: 0.868200, valid loss: 98.938102
epoch: 2991, train precision: 0.999244, train loss: 10.255464, valid precision: 0.871600, valid loss: 100.026906
epoch: 2992, train precision: 0.998578, train loss: 10.458696, valid precision: 0.869800, valid loss: 100.486239
epoch: 2993, train precision: 0.999111, train loss: 10.342607, valid precision: 0.872200, valid loss: 97.807850
epoch: 2994, train precision: 0.998622, train loss: 10.469830, valid precision: 0.869000, valid loss: 100.121167
epoch: 2995, train precision: 0.998867, train loss: 10.452297, valid precision: 0.873600, valid loss: 94.704212
epoch: 2996, train precision: 0.998778, train loss: 10.436497, valid precision: 0.873000, valid loss: 100.417923
epoch: 2997, train precision: 0.998467, train loss: 10.473733, valid precision: 0.871800, valid loss: 98.674582
epoch: 2998, train precision: 0.999133, train loss: 10.257928, valid precision: 0.874200, valid loss: 97.297703
epoch: 2999, train precision: 0.998867, train loss: 10.437822, valid precision: 0.878600, valid loss: 96.858636
epoch: 3000, train precision: 0.999200, train loss: 10.318547, valid precision: 0.875800, valid loss: 96.857849
epoch: 3001, train precision: 0.999222, train loss: 10.301828, valid precision: 0.876600, valid loss: 98.475905
epoch: 3002, train precision: 0.998422, train loss: 10.491764, valid precision: 0.875200, valid loss: 101.155871
epoch: 3003, train precision: 0.999244, train loss: 10.299825, valid precision: 0.876000, valid loss: 97.371662
epoch: 3004, train precision: 0.999067, train loss: 10.340021, valid precision: 0.872200, valid loss: 98.388018
epoch: 3005, train precision: 0.999067, train loss: 10.320083, valid precision: 0.872200, valid loss: 100.932980
epoch: 3006, train precision: 0.999244, train loss: 10.300725, valid precision: 0.875800, valid loss: 98.345181
epoch: 3007, train precision: 0.999311, train loss: 10.268964, valid precision: 0.874600, valid loss: 98.143027
epoch: 3008, train precision: 0.998689, train loss: 10.421427, valid precision: 0.873400, valid loss: 96.989324
epoch: 3009, train precision: 0.999022, train loss: 10.348320, valid precision: 0.878800, valid loss: 93.967874
epoch: 3010, train precision: 0.998778, train loss: 10.373241, valid precision: 0.874800, valid loss: 98.990088
epoch: 3011, train precision: 0.998911, train loss: 10.425618, valid precision: 0.869200, valid loss: 97.736660
epoch: 3012, train precision: 0.998889, train loss: 10.354789, valid precision: 0.871000, valid loss: 98.576638
epoch: 3013, train precision: 0.999156, train loss: 10.271645, valid precision: 0.873800, valid loss: 97.696822
epoch: 3014, train precision: 0.999089, train loss: 10.346197, valid precision: 0.876400, valid loss: 98.481038
epoch: 3015, train precision: 0.999000, train loss: 10.325363, valid precision: 0.873800, valid loss: 99.201165
epoch: 3016, train precision: 0.998800, train loss: 10.434158, valid precision: 0.875400, valid loss: 96.470835
epoch: 3017, train precision: 0.998667, train loss: 10.448436, valid precision: 0.872000, valid loss: 97.467203
epoch: 3018, train precision: 0.999178, train loss: 10.319533, valid precision: 0.874600, valid loss: 98.639286
epoch: 3019, train precision: 0.998889, train loss: 10.405159, valid precision: 0.873600, valid loss: 97.292630
epoch: 3020, train precision: 0.998933, train loss: 10.339586, valid precision: 0.871400, valid loss: 99.075417
epoch: 3021, train precision: 0.999178, train loss: 10.294611, valid precision: 0.871600, valid loss: 98.522085
epoch: 3022, train precision: 0.998778, train loss: 10.318285, valid precision: 0.870000, valid loss: 99.842317
epoch: 3023, train precision: 0.998956, train loss: 10.417704, valid precision: 0.875800, valid loss: 99.218834
epoch: 3024, train precision: 0.999156, train loss: 10.336310, valid precision: 0.873800, valid loss: 97.373327
epoch: 3025, train precision: 0.999089, train loss: 10.383725, valid precision: 0.869200, valid loss: 99.368348
epoch: 3026, train precision: 0.999067, train loss: 10.299577, valid precision: 0.873400, valid loss: 100.675051
epoch: 3027, train precision: 0.998889, train loss: 10.364857, valid precision: 0.868600, valid loss: 101.339060
epoch: 3028, train precision: 0.999111, train loss: 10.287763, valid precision: 0.871000, valid loss: 99.735105
epoch: 3029, train precision: 0.998822, train loss: 10.391375, valid precision: 0.873400, valid loss: 100.510393
epoch: 3030, train precision: 0.999111, train loss: 10.292592, valid precision: 0.875000, valid loss: 99.353644
epoch: 3031, train precision: 0.999267, train loss: 10.288252, valid precision: 0.874600, valid loss: 99.544902
epoch: 3032, train precision: 0.999089, train loss: 10.313969, valid precision: 0.873400, valid loss: 99.341964
epoch: 3033, train precision: 0.998822, train loss: 10.417972, valid precision: 0.870800, valid loss: 99.312003
epoch: 3034, train precision: 0.998822, train loss: 10.350959, valid precision: 0.873400, valid loss: 98.381010
epoch: 3035, train precision: 0.999044, train loss: 10.350676, valid precision: 0.872200, valid loss: 97.801529
epoch: 3036, train precision: 0.999400, train loss: 10.291851, valid precision: 0.871800, valid loss: 95.903673
epoch: 3037, train precision: 0.998978, train loss: 10.382442, valid precision: 0.872800, valid loss: 97.394638
epoch: 3038, train precision: 0.998822, train loss: 10.372449, valid precision: 0.873600, valid loss: 96.732361
epoch: 3039, train precision: 0.998844, train loss: 10.405078, valid precision: 0.871800, valid loss: 97.846173
epoch: 3040, train precision: 0.998889, train loss: 10.447949, valid precision: 0.874400, valid loss: 98.278035
epoch: 3041, train precision: 0.998978, train loss: 10.333862, valid precision: 0.877600, valid loss: 97.096926
epoch: 3042, train precision: 0.998822, train loss: 10.471997, valid precision: 0.879200, valid loss: 97.778400
epoch: 3043, train precision: 0.999089, train loss: 10.305647, valid precision: 0.875000, valid loss: 100.765335
epoch: 3044, train precision: 0.998889, train loss: 10.336480, valid precision: 0.875600, valid loss: 100.109300
epoch: 3045, train precision: 0.999022, train loss: 10.310945, valid precision: 0.879600, valid loss: 100.136774
epoch: 3046, train precision: 0.998978, train loss: 10.433115, valid precision: 0.873200, valid loss: 98.807513
epoch: 3047, train precision: 0.999022, train loss: 10.314392, valid precision: 0.873400, valid loss: 99.013157
epoch: 3048, train precision: 0.998956, train loss: 10.326305, valid precision: 0.874200, valid loss: 100.838857
epoch: 3049, train precision: 0.998933, train loss: 10.370180, valid precision: 0.871200, valid loss: 99.053209
epoch: 3050, train precision: 0.999267, train loss: 10.264964, valid precision: 0.872600, valid loss: 99.478807
epoch: 3051, train precision: 0.998933, train loss: 10.403106, valid precision: 0.872600, valid loss: 99.468403
epoch: 3052, train precision: 0.999244, train loss: 10.277154, valid precision: 0.871600, valid loss: 98.125909
epoch: 3053, train precision: 0.999200, train loss: 10.333778, valid precision: 0.870800, valid loss: 97.800303
epoch: 3054, train precision: 0.998889, train loss: 10.360983, valid precision: 0.872400, valid loss: 100.019773
epoch: 3055, train precision: 0.998933, train loss: 10.444357, valid precision: 0.872000, valid loss: 97.080207
epoch: 3056, train precision: 0.999178, train loss: 10.325138, valid precision: 0.872000, valid loss: 98.136436
epoch: 3057, train precision: 0.999133, train loss: 10.299091, valid precision: 0.877200, valid loss: 97.014223
epoch: 3058, train precision: 0.999044, train loss: 10.330241, valid precision: 0.871400, valid loss: 98.137840
epoch: 3059, train precision: 0.999178, train loss: 10.273578, valid precision: 0.872800, valid loss: 97.841257
epoch: 3060, train precision: 0.998956, train loss: 10.343659, valid precision: 0.871800, valid loss: 101.125633
epoch: 3061, train precision: 0.999333, train loss: 10.223935, valid precision: 0.876200, valid loss: 100.008383
epoch: 3062, train precision: 0.999444, train loss: 10.185027, valid precision: 0.873600, valid loss: 100.218736
epoch: 3063, train precision: 0.998867, train loss: 10.360593, valid precision: 0.871000, valid loss: 98.765478
epoch: 3064, train precision: 0.999133, train loss: 10.285573, valid precision: 0.872800, valid loss: 98.945061
epoch: 3065, train precision: 0.999067, train loss: 10.319007, valid precision: 0.874000, valid loss: 100.876834
epoch: 3066, train precision: 0.998933, train loss: 10.389657, valid precision: 0.869600, valid loss: 99.049062
epoch: 3067, train precision: 0.998911, train loss: 10.396974, valid precision: 0.872800, valid loss: 98.607613
epoch: 3068, train precision: 0.999089, train loss: 10.306090, valid precision: 0.873000, valid loss: 97.773608
epoch: 3069, train precision: 0.998867, train loss: 10.369010, valid precision: 0.870800, valid loss: 99.458375
epoch: 3070, train precision: 0.998889, train loss: 10.391702, valid precision: 0.870200, valid loss: 99.745814
epoch: 3071, train precision: 0.999200, train loss: 10.330095, valid precision: 0.873400, valid loss: 99.273772
epoch: 3072, train precision: 0.999111, train loss: 10.303984, valid precision: 0.871200, valid loss: 99.313972
epoch: 3073, train precision: 0.998978, train loss: 10.384864, valid precision: 0.867600, valid loss: 100.774192
epoch: 3074, train precision: 0.998756, train loss: 10.425426, valid precision: 0.867200, valid loss: 99.269321
epoch: 3075, train precision: 0.999222, train loss: 10.241341, valid precision: 0.873200, valid loss: 97.016351
epoch: 3076, train precision: 0.999200, train loss: 10.321261, valid precision: 0.869000, valid loss: 98.036332
epoch: 3077, train precision: 0.999111, train loss: 10.344187, valid precision: 0.865400, valid loss: 100.669050
epoch: 3078, train precision: 0.999089, train loss: 10.272390, valid precision: 0.869800, valid loss: 99.341481
epoch: 3079, train precision: 0.998578, train loss: 10.431207, valid precision: 0.873800, valid loss: 101.320025
epoch: 3080, train precision: 0.998933, train loss: 10.346240, valid precision: 0.874600, valid loss: 97.552170
epoch: 3081, train precision: 0.998911, train loss: 10.416270, valid precision: 0.872600, valid loss: 99.428324
epoch: 3082, train precision: 0.999111, train loss: 10.263718, valid precision: 0.873200, valid loss: 99.352362
epoch: 3083, train precision: 0.999133, train loss: 10.306695, valid precision: 0.875200, valid loss: 99.253608
epoch: 3084, train precision: 0.999022, train loss: 10.326451, valid precision: 0.876600, valid loss: 100.217405
epoch: 3085, train precision: 0.999178, train loss: 10.292771, valid precision: 0.872000, valid loss: 98.645365
epoch: 3086, train precision: 0.999156, train loss: 10.278375, valid precision: 0.873000, valid loss: 98.450053
epoch: 3087, train precision: 0.999067, train loss: 10.305305, valid precision: 0.872800, valid loss: 97.511069
epoch: 3088, train precision: 0.998933, train loss: 10.337189, valid precision: 0.869600, valid loss: 98.607107
epoch: 3089, train precision: 0.998778, train loss: 10.339092, valid precision: 0.874200, valid loss: 98.500081
epoch: 3090, train precision: 0.998978, train loss: 10.317373, valid precision: 0.870000, valid loss: 100.570219
epoch: 3091, train precision: 0.998778, train loss: 10.337377, valid precision: 0.874600, valid loss: 101.096248
epoch: 3092, train precision: 0.998889, train loss: 10.420237, valid precision: 0.870600, valid loss: 99.134421
epoch: 3093, train precision: 0.999111, train loss: 10.291380, valid precision: 0.872600, valid loss: 98.117823
epoch: 3094, train precision: 0.999156, train loss: 10.256672, valid precision: 0.870800, valid loss: 99.931193
epoch: 3095, train precision: 0.998733, train loss: 10.435056, valid precision: 0.870800, valid loss: 101.058389
epoch: 3096, train precision: 0.998556, train loss: 10.493973, valid precision: 0.872200, valid loss: 99.170379
epoch: 3097, train precision: 0.999044, train loss: 10.297168, valid precision: 0.872200, valid loss: 98.640945
epoch: 3098, train precision: 0.998978, train loss: 10.356620, valid precision: 0.872200, valid loss: 95.999355
epoch: 3099, train precision: 0.998978, train loss: 10.375344, valid precision: 0.871400, valid loss: 96.876752
